"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–µ–º
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —É–ª—å—Ç–∏–º–∞—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –û–ù–ö
"""

import logging
import os
import json
import time
import re
from typing import Dict, Any, List, Optional
from pathlib import Path
from ultimate_document_analyzer import UltimateDocumentAnalyzer, DocumentType, PageType, SeverityLevel

logger = logging.getLogger(__name__)


class EnhancedNormControlAnalyzer:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –û–ù–ö"""
    
    def __init__(self):
        self.document_analyzer = UltimateDocumentAnalyzer()
        self.normative_requirements = self._load_normative_requirements()
        self.onk_checklist = self._load_onk_checklist()
        self.ntd_list = self._load_ntd_list()
    
    def _load_normative_requirements(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π"""
        return {
            'gost_21_501_2018': {
                'name': '–ì–û–°–¢ 21.501-2018 –ü—Ä–∞–≤–∏–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ-—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —á–µ—Ä—Ç–µ–∂–µ–π',
                'requirements': [
                    '–ù–∞–ª–∏—á–∏–µ —à—Ç–∞–º–ø–∞ —á–µ—Ä—Ç–µ–∂–∞',
                    '–£–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞',
                    '–ù–∞–ª–∏—á–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤',
                    '–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –ª–∏–Ω–∏–π',
                    '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Å–ª–æ–≤–Ω—ã—Ö –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–π'
                ]
            },
            'gost_r_21_101_2020': {
                'name': '–ì–û–°–¢ –† 21.101-2020 –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–µ–∫—Ç–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏',
                'requirements': [
                    '–ù–∞–ª–∏—á–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–µ–∫—Ç–µ',
                    '–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Ç–∏—Ç—É–ª—å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞',
                    '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞',
                    '–ù–∞–ª–∏—á–∏–µ –æ–±—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö'
                ]
            },
            'sp_48_13330_2019': {
                'name': '–°–ü 48.13330.2019 –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞',
                'requirements': [
                    '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–¥–∏–π –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                    '–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏',
                    '–ù–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤'
                ]
            }
        }
    
    def _load_onk_checklist(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫-–ª–∏—Å—Ç–∞ –û–ù–ö"""
        return {
            'title': '–ß–µ–∫-–ª–∏—Å—Ç –ø–µ—Ä–µ–¥ –ù–ö –ü–¢–ò',
            'sections': {
                'document_structure': [
                    '–ù–∞–ª–∏—á–∏–µ —Ç–∏—Ç—É–ª—å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞',
                    '–ù–∞–ª–∏—á–∏–µ –æ–±—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö',
                    '–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è –ª–∏—Å—Ç–æ–≤',
                    '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–∞—Ä–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞'
                ],
                'drawing_requirements': [
                    '–ù–∞–ª–∏—á–∏–µ —à—Ç–∞–º–ø–∞ –Ω–∞ –∫–∞–∂–¥–æ–º –ª–∏—Å—Ç–µ',
                    '–£–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞',
                    '–ù–∞–ª–∏—á–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤',
                    '–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –ª–∏–Ω–∏–π',
                    '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Å–ª–æ–≤–Ω—ã—Ö –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–π'
                ],
                'technical_requirements': [
                    '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
                    '–ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å—á–µ—Ç–æ–≤',
                    '–ù–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Å–µ—á–µ–Ω–∏–π',
                    '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º'
                ],
                'quality_requirements': [
                    '–ß–µ—Ç–∫–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π',
                    '–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞',
                    '–ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è',
                    '–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ—à–∏–±–æ–∫'
                ]
            }
        }
    
    def _load_ntd_list(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ—á–Ω—è –ù–¢–î –ø–æ –º–∞—Ä–∫–∞–º"""
        return {
            'title': '–ü–µ—Ä–µ—á–µ–Ω—å –ù–¢–î –¥–ª—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –≤–Ω—É—Ç—Ä–∏ –û–ù–ö –ø–æ –º–∞—Ä–∫–∞–º',
            'marks': {
                '–ê–†': {
                    'name': '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è',
                    'ntd_list': [
                        '–ì–û–°–¢ 21.501-2018',
                        '–ì–û–°–¢ –† 21.101-2020',
                        '–°–ü 48.13330.2019',
                        '–°–ü 70.13330.2012'
                    ],
                    'requirements': [
                        '–ü–ª–∞–Ω—ã —ç—Ç–∞–∂–µ–π',
                        '–§–∞—Å–∞–¥—ã',
                        '–†–∞–∑—Ä–µ–∑—ã',
                        '–î–µ—Ç–∞–ª–∏',
                        '–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏'
                    ]
                },
                '–ö–ñ': {
                    'name': '–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è',
                    'ntd_list': [
                        '–ì–û–°–¢ 21.501-2018',
                        '–ì–û–°–¢ –† 21.101-2020',
                        '–°–ü 16.13330.2017',
                        '–°–ü 20.13330.2016'
                    ],
                    'requirements': [
                        '–ü–ª–∞–Ω—ã –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π',
                        '–°—Ö–µ–º—ã –∞—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è',
                        '–î–µ—Ç–∞–ª–∏ —É–∑–ª–æ–≤',
                        '–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤'
                    ]
                },
                '–ö–ú': {
                    'name': '–ú–µ—Ç–∞–ª–ª–æ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏',
                    'ntd_list': [
                        '–ì–û–°–¢ 21.501-2018',
                        '–ì–û–°–¢ –† 21.101-2020',
                        '–°–ü 16.13330.2017',
                        '–ì–û–°–¢ 23118-2012'
                    ],
                    'requirements': [
                        '–ü–ª–∞–Ω—ã –º–µ—Ç–∞–ª–ª–æ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π',
                        '–°—Ö–µ–º—ã —É–∑–ª–æ–≤',
                        '–î–µ—Ç–∞–ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π',
                        '–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏'
                    ]
                }
            }
        }
    
    def analyze_document_for_normcontrol(self, file_path: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è"""
        start_time = time.time()
        
        try:
            # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            doc_analysis = self.document_analyzer.analyze_document(file_path)
            
            if not doc_analysis['success']:
                return {
                    'success': False,
                    'error': doc_analysis['error'],
                    'analysis_time': time.time() - start_time
                }
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Ä–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            mark = doc_analysis['filename_analysis'].get('mark', 'Unknown')
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –¥–ª—è –º–∞—Ä–∫–∏
            mark_requirements = self.ntd_list['marks'].get(mark, {})
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –û–ù–ö
            onk_compliance = self._check_onk_compliance(doc_analysis, mark_requirements)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–µ
            normcontrol_report = self._generate_normcontrol_report(
                doc_analysis, 
                onk_compliance, 
                mark_requirements
            )
            
            result = {
                'success': True,
                'file_path': file_path,
                'file_name': Path(file_path).name,
                'analysis_time': time.time() - start_time,
                'document_analysis': doc_analysis,
                'mark_requirements': mark_requirements,
                'onk_compliance': onk_compliance,
                'normcontrol_report': normcontrol_report
            }
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è {file_path}: {e}")
            return {
                'success': False,
                'error': str(e),
                'file_path': file_path,
                'analysis_time': time.time() - start_time
            }
    
    def _check_onk_compliance(self, doc_analysis: Dict[str, Any], mark_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –û–ù–ö"""
        compliance = {
            'overall_score': 0.0,
            'sections': {},
            'total_issues': 0,
            'critical_issues': 0,
            'warning_issues': 0,
            'info_issues': 0,
            'recommendations': []
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
        structure_score = self._check_document_structure(doc_analysis)
        compliance['sections']['document_structure'] = structure_score
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ —á–µ—Ä—Ç–µ–∂–∞–º
        drawing_score = self._check_drawing_requirements(doc_analysis)
        compliance['sections']['drawing_requirements'] = drawing_score
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        technical_score = self._check_technical_requirements(doc_analysis, mark_requirements)
        compliance['sections']['technical_requirements'] = technical_score
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫–∞—á–µ—Å—Ç–≤–∞
        quality_score = self._check_quality_requirements(doc_analysis)
        compliance['sections']['quality_requirements'] = quality_score
        
        # –†–∞—Å—á–µ—Ç –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏
        section_scores = [score['score'] for score in compliance['sections'].values()]
        compliance['overall_score'] = sum(section_scores) / len(section_scores) if section_scores else 0.0
        
        # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–æ–±–ª–µ–º
        for section in compliance['sections'].values():
            compliance['total_issues'] += section['issues_count']
            compliance['critical_issues'] += section['critical_issues']
            compliance['warning_issues'] += section['warning_issues']
            compliance['info_issues'] += section['info_issues']
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        compliance['recommendations'] = self._generate_compliance_recommendations(compliance)
        
        return compliance
    
    def _check_document_structure(self, doc_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        score = 0.0
        issues = []
        critical_issues = 0
        warning_issues = 0
        info_issues = 0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–∏—Ç—É–ª—å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞
        pages = doc_analysis.get('pages_analysis', [])
        has_title_page = any(page['page_type'] == PageType.TITLE_PAGE for page in pages)
        
        if has_title_page:
            score += 25
        else:
            issues.append({
                'type': 'missing_title_page',
                'severity': 'critical',
                'description': '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ –† 21.101-2020'
            })
            critical_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        has_general_data = any(page['page_type'] == PageType.GENERAL_DATA_PAGE for page in pages)
        
        if has_general_data:
            score += 25
        else:
            issues.append({
                'type': 'missing_general_data',
                'severity': 'critical',
                'description': '–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å –ª–∏—Å—Ç –æ–±—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö'
            })
            critical_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–∏
        page_numbers = [page['page_number'] for page in pages]
        if page_numbers == list(range(1, len(pages) + 1)):
            score += 25
        else:
            issues.append({
                'type': 'incorrect_numbering',
                'severity': 'warning',
                'description': '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü',
                'recommendation': '–ò—Å–ø—Ä–∞–≤–∏—Ç—å –Ω—É–º–µ—Ä–∞—Ü–∏—é —Å—Ç—Ä–∞–Ω–∏—Ü'
            })
            warning_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–∞—Ä–∫–∏
        filename_analysis = doc_analysis.get('filename_analysis', {})
        mark = filename_analysis.get('mark')
        if mark:
            score += 25
        else:
            issues.append({
                'type': 'missing_mark',
                'severity': 'warning',
                'description': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –º–∞—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞',
                'recommendation': '–£–∫–∞–∑–∞—Ç—å –º–∞—Ä–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞'
            })
            warning_issues += 1
        
        return {
            'score': score,
            'issues': issues,
            'issues_count': len(issues),
            'critical_issues': critical_issues,
            'warning_issues': warning_issues,
            'info_issues': info_issues
        }
    
    def _check_drawing_requirements(self, doc_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ —á–µ—Ä—Ç–µ–∂–∞–º"""
        score = 0.0
        issues = []
        critical_issues = 0
        warning_issues = 0
        info_issues = 0
        
        pages = doc_analysis.get('pages_analysis', [])
        drawing_pages = [page for page in pages if page['page_type'] == PageType.DRAWING_PAGE]
        
        if not drawing_pages:
            issues.append({
                'type': 'no_drawing_pages',
                'severity': 'critical',
                'description': '–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —á–µ—Ä—Ç–µ–∂–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å —á–µ—Ä—Ç–µ–∂–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º'
            })
            critical_issues += 1
            return {
                'score': 0.0,
                'issues': issues,
                'issues_count': len(issues),
                'critical_issues': critical_issues,
                'warning_issues': warning_issues,
                'info_issues': info_issues
            }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —à—Ç–∞–º–ø–æ–≤
        pages_with_stamps = sum(1 for page in drawing_pages if page['stamp_info'].has_stamp)
        stamp_percentage = (pages_with_stamps / len(drawing_pages)) * 100
        
        if stamp_percentage >= 90:
            score += 30
        elif stamp_percentage >= 50:
            score += 15
            issues.append({
                'type': 'incomplete_stamps',
                'severity': 'warning',
                'description': f'–®—Ç–∞–º–ø—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ {stamp_percentage:.1f}% —Å—Ç—Ä–∞–Ω–∏—Ü',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å —à—Ç–∞–º–ø—ã –Ω–∞ –≤—Å–µ —á–µ—Ä—Ç–µ–∂–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã'
            })
            warning_issues += 1
        else:
            issues.append({
                'type': 'missing_stamps',
                'severity': 'critical',
                'description': f'–®—Ç–∞–º–ø—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–∞ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å—Ç—Ä–∞–Ω–∏—Ü ({stamp_percentage:.1f}%)',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å —à—Ç–∞–º–ø—ã —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ 21.501-2018'
            })
            critical_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞—Å—à—Ç–∞–±–æ–≤
        pages_with_scale = sum(1 for page in drawing_pages if page['stamp_info'].scale)
        scale_percentage = (pages_with_scale / len(drawing_pages)) * 100
        
        if scale_percentage >= 90:
            score += 30
        elif scale_percentage >= 50:
            score += 15
            issues.append({
                'type': 'incomplete_scales',
                'severity': 'warning',
                'description': f'–ú–∞—Å—à—Ç–∞–±—ã —É–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–∞ {scale_percentage:.1f}% —Å—Ç—Ä–∞–Ω–∏—Ü',
                'recommendation': '–£–∫–∞–∑–∞—Ç—å –º–∞—Å—à—Ç–∞–± –Ω–∞ –≤—Å–µ—Ö —á–µ—Ä—Ç–µ–∂–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö'
            })
            warning_issues += 1
        else:
            issues.append({
                'type': 'missing_scales',
                'severity': 'critical',
                'description': f'–ú–∞—Å—à—Ç–∞–±—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–∞ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å—Ç—Ä–∞–Ω–∏—Ü ({scale_percentage:.1f}%)',
                'recommendation': '–£–∫–∞–∑–∞—Ç—å –º–∞—Å—à—Ç–∞–± —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ 21.501-2018'
            })
            critical_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
        pages_with_dimensions = sum(1 for page in drawing_pages if page['drawing_elements'])
        dimension_percentage = (pages_with_dimensions / len(drawing_pages)) * 100
        
        if dimension_percentage >= 70:
            score += 25
        elif dimension_percentage >= 30:
            score += 10
            issues.append({
                'type': 'insufficient_dimensions',
                'severity': 'info',
                'description': f'–†–∞–∑–º–µ—Ä—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ {dimension_percentage:.1f}% —Å—Ç—Ä–∞–Ω–∏—Ü',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å —Ä–∞–∑–º–µ—Ä—ã –Ω–∞ —á–µ—Ä—Ç–µ–∂–∏'
            })
            info_issues += 1
        else:
            issues.append({
                'type': 'missing_dimensions',
                'severity': 'warning',
                'description': f'–†–∞–∑–º–µ—Ä—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–∞ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å—Ç—Ä–∞–Ω–∏—Ü ({dimension_percentage:.1f}%)',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å —Ä–∞–∑–º–µ—Ä—ã —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ 21.501-2018'
            })
            warning_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è
        avg_confidence = sum(page['confidence_score'] for page in drawing_pages) / len(drawing_pages)
        if avg_confidence >= 0.8:
            score += 15
        elif avg_confidence >= 0.6:
            score += 8
            issues.append({
                'type': 'low_quality',
                'severity': 'info',
                'description': f'–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.1%})',
                'recommendation': '–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —á–µ—Ä—Ç–µ–∂–µ–π'
            })
            info_issues += 1
        else:
            issues.append({
                'type': 'poor_quality',
                'severity': 'warning',
                'description': f'–ü–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.1%})',
                'recommendation': '–ü–µ—Ä–µ–æ—Ñ–æ—Ä–º–∏—Ç—å —á–µ—Ä—Ç–µ–∂–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º'
            })
            warning_issues += 1
        
        return {
            'score': score,
            'issues': issues,
            'issues_count': len(issues),
            'critical_issues': critical_issues,
            'warning_issues': warning_issues,
            'info_issues': info_issues
        }
    
    def _check_technical_requirements(self, doc_analysis: Dict[str, Any], mark_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π"""
        score = 0.0
        issues = []
        critical_issues = 0
        warning_issues = 0
        info_issues = 0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–∞—Ä–∫–µ
        filename_analysis = doc_analysis.get('filename_analysis', {})
        mark = filename_analysis.get('mark')
        
        if mark and mark in self.ntd_list['marks']:
            score += 40
            required_ntd = self.ntd_list['marks'][mark]['ntd_list']
            issues.append({
                'type': 'ntd_reference',
                'severity': 'info',
                'description': f'–ü—Ä–∏–º–µ–Ω—è–µ–º—ã–µ –ù–¢–î: {", ".join(required_ntd)}',
                'recommendation': '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É–∫–∞–∑–∞–Ω–Ω—ã–º –ù–¢–î'
            })
            info_issues += 1
        else:
            issues.append({
                'type': 'unknown_mark',
                'severity': 'warning',
                'description': f'–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–∞—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {mark}',
                'recommendation': '–£—Ç–æ—á–Ω–∏—Ç—å –º–∞—Ä–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞'
            })
            warning_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        pages = doc_analysis.get('pages_analysis', [])
        total_elements = sum(len(page['drawing_elements']) for page in pages)
        
        if total_elements > 0:
            score += 30
        else:
            issues.append({
                'type': 'no_technical_elements',
                'severity': 'warning',
                'description': '–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å —Ä–∞–∑–º–µ—Ä—ã, –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏'
            })
            warning_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –º–∞—Ä–∫–∏
        if mark_requirements:
            required_sections = mark_requirements.get('requirements', [])
            if required_sections:
                score += 30
                issues.append({
                    'type': 'mark_requirements',
                    'severity': 'info',
                    'description': f'–¢—Ä–µ–±—É–µ–º—ã–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è –º–∞—Ä–∫–∏ {mark}: {", ".join(required_sections)}',
                    'recommendation': '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö —Ç—Ä–µ–±—É–µ–º—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤'
                })
                info_issues += 1
        
        return {
            'score': score,
            'issues': issues,
            'issues_count': len(issues),
            'critical_issues': critical_issues,
            'warning_issues': warning_issues,
            'info_issues': info_issues
        }
    
    def _check_quality_requirements(self, doc_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫–∞—á–µ—Å—Ç–≤–∞"""
        score = 0.0
        issues = []
        critical_issues = 0
        warning_issues = 0
        info_issues = 0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        overall_analysis = doc_analysis.get('overall_analysis', {})
        compliance_score = overall_analysis.get('compliance_score', 0)
        
        if compliance_score >= 90:
            score += 40
        elif compliance_score >= 70:
            score += 25
            issues.append({
                'type': 'moderate_quality',
                'severity': 'info',
                'description': f'–£–º–µ—Ä–µ–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {compliance_score:.1f}%)',
                'recommendation': '–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è'
            })
            info_issues += 1
        else:
            issues.append({
                'type': 'low_quality',
                'severity': 'warning',
                'description': f'–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {compliance_score:.1f}%)',
                'recommendation': '–ü–µ—Ä–µ–æ—Ñ–æ—Ä–º–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º'
            })
            warning_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ä–µ–¥–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        avg_confidence = overall_analysis.get('average_confidence', 0)
        
        if avg_confidence >= 0.8:
            score += 30
        elif avg_confidence >= 0.6:
            score += 15
            issues.append({
                'type': 'moderate_confidence',
                'severity': 'info',
                'description': f'–£–º–µ—Ä–µ–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞ ({avg_confidence:.1%})',
                'recommendation': '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞'
            })
            info_issues += 1
        else:
            issues.append({
                'type': 'low_confidence',
                'severity': 'warning',
                'description': f'–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞ ({avg_confidence:.1%})',
                'recommendation': '–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞'
            })
            warning_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–±–ª–µ–º
        total_issues = overall_analysis.get('total_issues', 0)
        
        if total_issues == 0:
            score += 30
        elif total_issues <= 5:
            score += 20
            issues.append({
                'type': 'few_issues',
                'severity': 'info',
                'description': f'–ù–∞–π–¥–µ–Ω–æ {total_issues} –ø—Ä–æ–±–ª–µ–º',
                'recommendation': '–ò—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã'
            })
            info_issues += 1
        else:
            issues.append({
                'type': 'many_issues',
                'severity': 'warning',
                'description': f'–ù–∞–π–¥–µ–Ω–æ –º–Ω–æ–≥–æ –ø—Ä–æ–±–ª–µ–º: {total_issues}',
                'recommendation': '–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã'
            })
            warning_issues += 1
        
        return {
            'score': score,
            'issues': issues,
            'issues_count': len(issues),
            'critical_issues': critical_issues,
            'warning_issues': warning_issues,
            'info_issues': info_issues
        }
    
    def _generate_compliance_recommendations(self, compliance: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—é"""
        recommendations = []
        
        if compliance['critical_issues'] > 0:
            recommendations.append('–£—Å—Ç—Ä–∞–Ω–∏—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ')
        
        if compliance['warning_issues'] > 0:
            recommendations.append('–ò—Å–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –≤ –∫—Ä–∞—Ç—á–∞–π—à–∏–µ —Å—Ä–æ–∫–∏')
        
        if compliance['overall_score'] < 70:
            recommendations.append('–ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–ª–Ω—É—é –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞')
        elif compliance['overall_score'] < 85:
            recommendations.append('–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞')
        
        if compliance['sections']['document_structure']['score'] < 80:
            recommendations.append('–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞')
        
        if compliance['sections']['drawing_requirements']['score'] < 80:
            recommendations.append('–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —á–µ—Ä—Ç–µ–∂–∞–º')
        
        if compliance['sections']['technical_requirements']['score'] < 80:
            recommendations.append('–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è')
        
        if compliance['sections']['quality_requirements']['score'] < 80:
            recommendations.append('–ü–æ–≤—ã—Å–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞')
        
        return recommendations
    
    def _generate_normcontrol_report(self, doc_analysis: Dict[str, Any], onk_compliance: Dict[str, Any], mark_requirements: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–µ"""
        report = {
            'title': '–û—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ—Ä–∫–µ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–µ–º',
            'document_info': {
                'file_name': doc_analysis['file_name'],
                'file_size_mb': doc_analysis['file_size'] / (1024 * 1024),
                'analysis_time': doc_analysis['analysis_time'],
                'file_hash': doc_analysis['file_hash'][:16]
            },
            'document_analysis': {
                'project_number': doc_analysis['filename_analysis'].get('project_number'),
                'document_type': doc_analysis['filename_analysis']['document_type'].value,
                'mark': doc_analysis['filename_analysis'].get('mark'),
                'revision': doc_analysis['filename_analysis'].get('revision'),
                'total_pages': doc_analysis['overall_analysis']['total_pages'],
                'compliance_score': doc_analysis['overall_analysis']['compliance_score']
            },
            'onk_compliance': {
                'overall_score': onk_compliance['overall_score'],
                'total_issues': onk_compliance['total_issues'],
                'critical_issues': onk_compliance['critical_issues'],
                'warning_issues': onk_compliance['warning_issues'],
                'info_issues': onk_compliance['info_issues']
            },
            'sections_analysis': onk_compliance['sections'],
            'mark_requirements': mark_requirements,
            'recommendations': onk_compliance['recommendations'],
            'status': self._determine_status(onk_compliance),
            'generated_at': time.time()
        }
        
        return report
    
    def _determine_status(self, compliance: Dict[str, Any]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        if compliance['critical_issues'] > 0:
            return 'rejected'
        elif compliance['overall_score'] >= 90:
            return 'approved'
        elif compliance['overall_score'] >= 70:
            return 'approved_with_comments'
        else:
            return 'needs_revision'


def analyze_document_for_normcontrol(file_path: str) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è"""
    analyzer = EnhancedNormControlAnalyzer()
    return analyzer.analyze_document_for_normcontrol(file_path)


def print_normcontrol_analysis_results(result: Dict[str, Any]):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è"""
    if not result['success']:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {result.get('error', 'Unknown error')}")
        return
    
    print("=" * 80)
    print("üîç –ê–ù–ê–õ–ò–ó –ù–û–†–ú–û–ö–û–ù–¢–†–û–õ–ï–ú –° –ò–ù–¢–ï–ì–†–ê–¶–ò–ï–ô –¢–†–ï–ë–û–í–ê–ù–ò–ô –û–ù–ö")
    print("=" * 80)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ
    doc_info = result['normcontrol_report']['document_info']
    print(f"üìÑ –§–∞–π–ª: {doc_info['file_name']}")
    print(f"üìä –†–∞–∑–º–µ—Ä: {doc_info['file_size_mb']:.2f} –ú–ë")
    print(f"‚è±Ô∏è –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {doc_info['analysis_time']:.2f} —Å–µ–∫")
    print(f"üîë –•—ç—à: {doc_info['file_hash']}...")
    
    # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    doc_analysis = result['normcontrol_report']['document_analysis']
    print(f"\nüìã –ê–ù–ê–õ–ò–ó –î–û–ö–£–ú–ï–ù–¢–ê:")
    print(f"  –ü—Ä–æ–µ–∫—Ç: {doc_analysis['project_number'] or '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω'}")
    print(f"  –¢–∏–ø: {doc_analysis['document_type']}")
    print(f"  –ú–∞—Ä–∫–∞: {doc_analysis['mark'] or '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞'}")
    print(f"  –†–µ–≤–∏–∑–∏—è: {doc_analysis['revision'] or '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞'}")
    print(f"  –°—Ç—Ä–∞–Ω–∏—Ü: {doc_analysis['total_pages']}")
    print(f"  –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {doc_analysis['compliance_score']:.1f}%")
    
    # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –û–ù–ö
    onk_compliance = result['normcontrol_report']['onk_compliance']
    print(f"\nüè¢ –°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø–ú –û–ù–ö:")
    print(f"  –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {onk_compliance['overall_score']:.1f}%")
    print(f"  –í—Å–µ–≥–æ –ø—Ä–æ–±–ª–µ–º: {onk_compliance['total_issues']}")
    print(f"  –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö: {onk_compliance['critical_issues']}")
    print(f"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {onk_compliance['warning_issues']}")
    print(f"  –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö: {onk_compliance['info_issues']}")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤
    sections = result['normcontrol_report']['sections_analysis']
    print(f"\nüìä –ê–ù–ê–õ–ò–ó –†–ê–ó–î–ï–õ–û–í:")
    for section_name, section_data in sections.items():
        print(f"  {section_name}: {section_data['score']:.1f}% ({section_data['issues_count']} –ø—Ä–æ–±–ª–µ–º)")
    
    # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –º–∞—Ä–∫–∏
    mark_requirements = result['normcontrol_report']['mark_requirements']
    if mark_requirements:
        print(f"\nüìã –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ú–ê–†–ö–ò {mark_requirements.get('name', 'Unknown')}:")
        ntd_list = mark_requirements.get('ntd_list', [])
        for ntd in ntd_list:
            print(f"  - {ntd}")
        
        requirements = mark_requirements.get('requirements', [])
        if requirements:
            print(f"  –¢—Ä–µ–±—É–µ–º—ã–µ —Ä–∞–∑–¥–µ–ª—ã:")
            for req in requirements:
                print(f"    - {req}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations = result['normcontrol_report']['recommendations']
    if recommendations:
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")
    
    # –°—Ç–∞—Ç—É—Å
    status = result['normcontrol_report']['status']
    status_emoji = {
        'approved': '‚úÖ',
        'approved_with_comments': '‚ö†Ô∏è',
        'needs_revision': '‚ùå',
        'rejected': 'üö´'
    }
    print(f"\nüìã –°–¢–ê–¢–£–°: {status_emoji.get(status, '‚ùì')} {status.upper()}")


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ
    file_path = "tests/TestDocs/for_check/3401-21089-–†–î-01-220-221-–ê–†_4_0_RU_IFC (1).pdf"
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–µ–º —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –û–ù–ö...")
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
    result = analyze_document_for_normcontrol(file_path)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print_normcontrol_analysis_results(result)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if result['success']:
        output_file = f"enhanced_normcontrol_analysis_{int(time.time())}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Enum –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è JSON
            def convert_enums(obj):
                if isinstance(obj, dict):
                    return {k: convert_enums(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_enums(item) for item in obj]
                elif hasattr(obj, '__dict__'):
                    return convert_enums(obj.__dict__)
                else:
                    return obj
            
            json.dump(convert_enums(result), f, ensure_ascii=False, indent=2)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
