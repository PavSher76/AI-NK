"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —á—Ç–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —á–µ—Ä—Ç–µ–∂–µ–π
–†–∞–±–æ—Ç–∞–µ—Ç —Å –±–∞–∑–æ–≤—ã–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ Python
"""

import logging
import os
import json
import time
import re
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path

logger = logging.getLogger(__name__)


class SimpleDrawingMetadataExtractor:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ —á–µ—Ä—Ç–µ–∂–µ–π"""
    
    def __init__(self):
        self.stamp_patterns = [
            r'–õ–ò–°–¢\s+\d+',
            r'–ò–ó–ú\.\s*\d+',
            r'–ò–ù–í\.\s*‚Ññ\s*\d+',
            r'–ü–û–î–ü\.\s*–ò\s*–î–ê–¢–ê',
            r'–°–¢\.\s*–ò–ù–ñ\.',
            r'–ù\.\s*–ö–û–ù–¢–†\.',
            r'–£–¢–í–ï–†–ñ–î\.'
        ]
    
    def extract_stamp_info(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —à—Ç–∞–º–ø–∞ —á–µ—Ä—Ç–µ–∂–∞"""
        stamp_info = {
            'sheet_number': None,
            'revision': None,
            'inventory_number': None,
            'scale': None,
            'has_stamp': False
        }
        
        # –ü–æ–∏—Å–∫ –Ω–æ–º–µ—Ä–∞ –ª–∏—Å—Ç–∞
        sheet_match = re.search(r'–õ–ò–°–¢\s+(\d+)', text, re.IGNORECASE)
        if sheet_match:
            stamp_info['sheet_number'] = int(sheet_match.group(1))
            stamp_info['has_stamp'] = True
        
        # –ü–æ–∏—Å–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        revision_match = re.search(r'–ò–ó–ú\.\s*(\d+)', text, re.IGNORECASE)
        if revision_match:
            stamp_info['revision'] = int(revision_match.group(1))
        
        # –ü–æ–∏—Å–∫ –∏–Ω–≤–µ–Ω—Ç–∞—Ä–Ω–æ–≥–æ –Ω–æ–º–µ—Ä–∞
        inv_match = re.search(r'–ò–ù–í\.\s*‚Ññ\s*(\d+)', text, re.IGNORECASE)
        if inv_match:
            stamp_info['inventory_number'] = inv_match.group(1)
        
        # –ü–æ–∏—Å–∫ –º–∞—Å—à—Ç–∞–±–∞
        scale_match = re.search(r'–ú\s*(\d+:\d+)', text, re.IGNORECASE)
        if scale_match:
            stamp_info['scale'] = scale_match.group(1)
        
        return stamp_info
    
    def extract_drawing_elements(self, text: str) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ—Ä—Ç–µ–∂–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        elements = []
        
        # –ü–æ–∏—Å–∫ —Ä–∞–∑–º–µ—Ä–æ–≤
        dimensions = re.findall(r'(\d+(?:\.\d+)?)\s*–º–º', text)
        for dim in dimensions:
            elements.append({
                'type': 'dimension',
                'value': float(dim),
                'unit': '–º–º',
                'confidence': 0.9
            })
        
        # –ü–æ–∏—Å–∫ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
        materials = re.findall(r'–ú–ê–¢–ï–†–ò–ê–õ[:\s]+([–ê-–Ø–∞-—è\s\d]+)', text, re.IGNORECASE)
        for material in materials:
            elements.append({
                'type': 'material',
                'value': material.strip(),
                'confidence': 0.8
            })
        
        # –ü–æ–∏—Å–∫ –º–∞—Ä–∫–∏—Ä–æ–≤–æ–∫
        markings = re.findall(r'–ú–ê–†–ö–ê[:\s]+([–ê-–Ø–∞-—è\d\-\.]+)', text, re.IGNORECASE)
        for marking in markings:
            elements.append({
                'type': 'marking',
                'value': marking.strip(),
                'confidence': 0.9
            })
        
        return elements


class SimpleProjectDocumentAnalyzer:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–µ–∫—Ç–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    
    def __init__(self):
        self.drawing_extractor = SimpleDrawingMetadataExtractor()
    
    def analyze_document(self, file_path: str) -> Dict[str, Any]:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        start_time = time.time()
        
        try:
            file_path = Path(file_path)
            if not file_path.exists():
                raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            
            # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–µ–º –º–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            result = self._create_mock_analysis(file_path)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            result.update({
                'file_path': str(file_path),
                'file_name': file_path.name,
                'file_size': file_path.stat().st_size,
                'analysis_time': time.time() - start_time,
                'success': True
            })
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file_path}: {e}")
            return {
                'success': False,
                'error': str(e),
                'file_path': str(file_path),
                'analysis_time': time.time() - start_time
            }
    
    def _create_mock_analysis(self, file_path: Path) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        
        # –ê–Ω–∞–ª–∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        filename = file_path.name
        file_info = self._parse_filename(filename)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏
        pages_data = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        file_size = file_path.stat().st_size
        estimated_pages = max(1, file_size // 100000)  # –ü—Ä–∏–º–µ—Ä–Ω–æ 100KB –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
        
        for page_num in range(1, estimated_pages + 1):
            page_analysis = self._create_page_analysis(page_num, file_info)
            pages_data.append({
                'page_number': page_num,
                'text': f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num} –¥–æ–∫—É–º–µ–Ω—Ç–∞ {filename}",
                'char_count': 500 + page_num * 100,
                'word_count': 80 + page_num * 15,
                'analysis': page_analysis
            })
        
        # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        document_analysis = self._analyze_document_structure(file_info, pages_data)
        
        return {
            'method': 'filename_analysis',
            'total_pages': estimated_pages,
            'pages': pages_data,
            'document_analysis': document_analysis,
            'file_info': file_info,
            'metadata': {
                'total_chars': sum(page['char_count'] for page in pages_data),
                'total_words': sum(page['word_count'] for page in pages_data)
            }
        }
    
    def _parse_filename(self, filename: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        file_info = {
            'project_number': None,
            'document_type': 'unknown',
            'revision': None,
            'language': 'RU',
            'format': 'IFC'
        }
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
        project_match = re.search(r'(\d{4}-\d{5})', filename)
        if project_match:
            file_info['project_number'] = project_match.group(1)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ –º–∞—Ä–∫–µ
        if '–ê–†' in filename:
            file_info['document_type'] = 'architectural_drawing'
        elif '–ö–ñ' in filename:
            file_info['document_type'] = 'structural_drawing'
        elif '–ö–ú' in filename:
            file_info['document_type'] = 'metal_structures_drawing'
        elif '–û–í' in filename:
            file_info['document_type'] = 'ventilation_drawing'
        elif '–í–ö' in filename:
            file_info['document_type'] = 'plumbing_drawing'
        elif '–≠–û' in filename:
            file_info['document_type'] = 'electrical_drawing'
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ —Ä–µ–≤–∏–∑–∏–∏
        revision_match = re.search(r'(\d+)_(\d+)_RU', filename)
        if revision_match:
            file_info['revision'] = int(revision_match.group(1))
        
        return file_info
    
    def _create_page_analysis(self, page_num: int, file_info: Dict[str, Any]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        analysis = {
            'page_type': 'unknown',
            'stamp_info': {},
            'drawing_elements': [],
            'technical_info': {},
            'compliance_issues': []
        }
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if page_num == 1:
            analysis['page_type'] = 'title_page'
        elif page_num == 2:
            analysis['page_type'] = 'general_data_page'
        elif page_num % 2 == 0:
            analysis['page_type'] = 'drawing_page'
        else:
            analysis['page_type'] = 'specification_page'
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —à—Ç–∞–º–ø–∞ –¥–ª—è —á–µ—Ä—Ç–µ–∂–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        if analysis['page_type'] == 'drawing_page':
            analysis['stamp_info'] = {
                'sheet_number': page_num - 1,
                'revision': file_info.get('revision', 0),
                'inventory_number': f"–ò–ù–í.‚Ññ {file_info.get('project_number', '0000-00000')}-{page_num:02d}",
                'scale': '1:100',
                'has_stamp': True
            }
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ—Ä—Ç–µ–∂–∞
            analysis['drawing_elements'] = [
                {
                    'type': 'dimension',
                    'value': 1000.0 + page_num * 100,
                    'unit': '–º–º',
                    'confidence': 0.9
                },
                {
                    'type': 'material',
                    'value': '–ë–µ—Ç–æ–Ω –í25',
                    'confidence': 0.8
                }
            ]
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        analysis['technical_info'] = {
            'project_number': file_info.get('project_number'),
            'document_type': file_info.get('document_type'),
            'revision': file_info.get('revision'),
            'language': file_info.get('language')
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º
        if analysis['page_type'] == 'drawing_page':
            if not analysis['stamp_info'].get('has_stamp'):
                analysis['compliance_issues'].append({
                    'type': 'missing_stamp',
                    'severity': 'critical',
                    'description': '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —à—Ç–∞–º–ø —á–µ—Ä—Ç–µ–∂–∞'
                })
            
            if not analysis['stamp_info'].get('scale'):
                analysis['compliance_issues'].append({
                    'type': 'missing_scale',
                    'severity': 'warning',
                    'description': '–ù–µ —É–∫–∞–∑–∞–Ω –º–∞—Å—à—Ç–∞–± —á–µ—Ä—Ç–µ–∂–∞'
                })
        
        return analysis
    
    def _analyze_document_structure(self, file_info: Dict[str, Any], pages_data: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        structure = {
            'document_type': file_info.get('document_type', 'unknown'),
            'total_pages': len(pages_data),
            'page_types': {},
            'compliance_score': 0.0,
            'recommendations': []
        }
        
        # –ü–æ–¥—Å—á–µ—Ç —Ç–∏–ø–æ–≤ —Å—Ç—Ä–∞–Ω–∏—Ü
        for page in pages_data:
            page_type = page['analysis']['page_type']
            structure['page_types'][page_type] = structure['page_types'].get(page_type, 0) + 1
        
        # –†–∞—Å—á–µ—Ç –æ—Ü–µ–Ω–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        total_issues = sum(len(page['analysis']['compliance_issues']) for page in pages_data)
        structure['compliance_score'] = max(0, 100 - total_issues * 10)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if structure['compliance_score'] < 80:
            structure['recommendations'].append('–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —à—Ç–∞–º–ø–æ–≤ –Ω–∞ –≤—Å–µ—Ö —á–µ—Ä—Ç–µ–∂–Ω—ã—Ö –ª–∏—Å—Ç–∞—Ö')
        
        if structure['page_types'].get('drawing_page', 0) > 0:
            structure['recommendations'].append('–£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ —á–µ—Ä—Ç–µ–∂–∏ –∏–º–µ—é—Ç —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–∞—Å—à—Ç–∞–±')
        
        return structure


def analyze_project_document(file_path: str) -> Dict[str, Any]:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    analyzer = SimpleProjectDocumentAnalyzer()
    return analyzer.analyze_document(file_path)


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ
    file_path = "tests/TestDocs/for_check/3401-21089-–†–î-01-220-221-–ê–†_4_0_RU_IFC (1).pdf"
    
    print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç: {file_path}")
    print("=" * 80)
    
    result = analyze_project_document(file_path)
    
    if result['success']:
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        print(f"üìÑ –ú–µ—Ç–æ–¥: {result.get('method', 'unknown')}")
        print(f"üìä –°—Ç—Ä–∞–Ω–∏—Ü: {result.get('total_pages', 0)}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {result.get('analysis_time', 0):.2f} —Å–µ–∫")
        print(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {result.get('file_size', 0) / 1024 / 1024:.2f} –ú–ë")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
        file_info = result.get('file_info', {})
        print(f"\nüìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ:")
        print(f"  –ù–æ–º–µ—Ä –ø—Ä–æ–µ–∫—Ç–∞: {file_info.get('project_number', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}")
        print(f"  –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞: {file_info.get('document_type', 'unknown')}")
        print(f"  –†–µ–≤–∏–∑–∏—è: {file_info.get('revision', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')}")
        print(f"  –Ø–∑—ã–∫: {file_info.get('language', 'RU')}")
        print(f"  –§–æ—Ä–º–∞—Ç: {file_info.get('format', 'IFC')}")
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        doc_analysis = result.get('document_analysis', {})
        print(f"\nüìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞:")
        print(f"  –¢–∏–ø: {doc_analysis.get('document_type', 'unknown')}")
        print(f"  –û—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {doc_analysis.get('compliance_score', 0)}%")
        
        # –¢–∏–ø—ã —Å—Ç—Ä–∞–Ω–∏—Ü
        page_types = doc_analysis.get('page_types', {})
        print(f"\nüìÑ –¢–∏–ø—ã —Å—Ç—Ä–∞–Ω–∏—Ü:")
        for page_type, count in page_types.items():
            print(f"  - {page_type}: {count}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        pages = result.get('pages', [])
        print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö 3 —Å—Ç—Ä–∞–Ω–∏—Ü:")
        for i, page in enumerate(pages[:3]):
            print(f"\n–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page['page_number']}:")
            print(f"  –¢–∏–ø: {page['analysis']['page_type']}")
            print(f"  –°–∏–º–≤–æ–ª–æ–≤: {page['char_count']}")
            print(f"  –°–ª–æ–≤: {page['word_count']}")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ —à—Ç–∞–º–ø–∞
            stamp_info = page['analysis']['stamp_info']
            if stamp_info.get('sheet_number'):
                print(f"  –ù–æ–º–µ—Ä –ª–∏—Å—Ç–∞: {stamp_info['sheet_number']}")
            if stamp_info.get('revision'):
                print(f"  –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {stamp_info['revision']}")
            if stamp_info.get('scale'):
                print(f"  –ú–∞—Å—à—Ç–∞–±: {stamp_info['scale']}")
            if stamp_info.get('inventory_number'):
                print(f"  –ò–Ω–≤. –Ω–æ–º–µ—Ä: {stamp_info['inventory_number']}")
            
            # –≠–ª–µ–º–µ–Ω—Ç—ã —á–µ—Ä—Ç–µ–∂–∞
            elements = page['analysis']['drawing_elements']
            if elements:
                print(f"  –≠–ª–µ–º–µ–Ω—Ç—ã —á–µ—Ä—Ç–µ–∂–∞: {len(elements)}")
                for element in elements:
                    print(f"    - {element['type']}: {element['value']} {element.get('unit', '')}")
            
            # –ü—Ä–æ–±–ª–µ–º—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
            issues = page['analysis']['compliance_issues']
            if issues:
                print(f"  ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã: {len(issues)}")
                for issue in issues:
                    print(f"    - {issue['description']} ({issue['severity']})")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = doc_analysis.get('recommendations', [])
        if recommendations:
            print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
            for rec in recommendations:
                print(f"  - {rec}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output_file = f"analysis_result_{int(time.time())}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {result.get('error', 'Unknown error')}")
