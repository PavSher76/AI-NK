import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from models.data_models import DocumentInspectionResult, PageResult, Finding, FindingType, SeverityLevel
from database.connection import DatabaseConnection
from utils.memory_utils import check_memory_pressure, cleanup_memory

logger = logging.getLogger(__name__)

class HierarchicalCheckService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, db_connection: DatabaseConnection):
        self.db_connection = db_connection
    
    async def perform_hierarchical_check(self, document_id: int) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            logger.info(f"üöÄ [HIERARCHICAL] Starting hierarchical check for document {document_id}")
            logger.info(f"üìä [HIERARCHICAL] Memory usage before check: {check_memory_pressure()}")
            start_time = datetime.now()
            
            # –≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            logger.info(f"üìÑ [HIERARCHICAL] Stage 1: Quick first page analysis")
            stage1_start = datetime.now()
            first_page_info = await self.analyze_first_page(document_id)
            stage1_time = (datetime.now() - stage1_start).total_seconds()
            logger.info(f"üìÑ [HIERARCHICAL] Stage 1 completed in {stage1_time:.2f}s")
            logger.info(f"üìÑ [HIERARCHICAL] Stage 1 result: {first_page_info.get('project_info', {}).get('project_name', 'Unknown')}")
            
            # –≠—Ç–∞–ø 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º
            logger.info(f"üìã [HIERARCHICAL] Stage 2: Full document norm compliance check")
            stage2_start = datetime.now()
            norm_compliance_results = await self.check_norm_compliance(document_id, first_page_info)
            stage2_time = (datetime.now() - stage2_start).total_seconds()
            logger.info(f"üìã [HIERARCHICAL] Stage 2 completed in {stage2_time:.2f}s")
            logger.info(f"üìã [HIERARCHICAL] Stage 2 findings: {norm_compliance_results.get('total_findings', 0)} total, {norm_compliance_results.get('critical_findings', 0)} critical")
            
            # –≠—Ç–∞–ø 3: –í—ã—è–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
            logger.info(f"üìë [HIERARCHICAL] Stage 3: Document sections identification and organization")
            stage3_start = datetime.now()
            section_analysis = await self.analyze_document_sections(document_id, first_page_info)
            stage3_time = (datetime.now() - stage3_start).total_seconds()
            logger.info(f"üìë [HIERARCHICAL] Stage 3 completed in {stage3_time:.2f}s")
            logger.info(f"üìë [HIERARCHICAL] Stage 3 sections identified: {len(section_analysis.get('sections', []))}")
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—â–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            total_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                "document_id": document_id,
                "check_type": "hierarchical",
                "execution_time": total_time,
                "stages": {
                    "first_page_analysis": first_page_info,
                    "norm_compliance": norm_compliance_results,
                    "section_analysis": section_analysis
                },
                "summary": {
                    "project_info": first_page_info.get("project_info", {}),
                    "total_findings": norm_compliance_results.get("total_findings", 0),
                    "sections_identified": len(section_analysis.get("sections", [])),
                    "overall_status": self.determine_overall_status(norm_compliance_results)
                }
            }
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            save_start = datetime.now()
            await self.save_hierarchical_check_result(document_id, result)
            save_time = (datetime.now() - save_start).total_seconds()
            logger.info(f"üíæ [HIERARCHICAL] Results saved in {save_time:.2f}s")
            
            logger.info(f"‚úÖ [HIERARCHICAL] Hierarchical check completed for document {document_id} in {total_time:.2f}s")
            logger.info(f"üìä [HIERARCHICAL] Memory usage after check: {check_memory_pressure()}")
            logger.info(f"üìà [HIERARCHICAL] Performance summary:")
            logger.info(f"   - Stage 1 (First page): {stage1_time:.2f}s")
            logger.info(f"   - Stage 2 (Norm compliance): {stage2_time:.2f}s")
            logger.info(f"   - Stage 3 (Sections): {stage3_time:.2f}s")
            logger.info(f"   - Save results: {save_time:.2f}s")
            logger.info(f"   - Total time: {total_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [HIERARCHICAL] Hierarchical check failed for document {document_id}: {e}")
            return {
                "status": "error",
                "error": str(e),
                "document_id": document_id
            }
    
    async def analyze_first_page(self, document_id: int) -> Dict[str, Any]:
        """–≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        try:
            logger.info(f"üìÑ [FIRST_PAGE] Analyzing first page for document {document_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
            logger.debug(f"üìÑ [FIRST_PAGE] Fetching first page content for document {document_id}")
            first_page = self.get_first_page_content(document_id)
            if not first_page:
                logger.error(f"üìÑ [FIRST_PAGE] First page not found for document {document_id}")
                return {"error": "First page not found"}
            
            logger.debug(f"üìÑ [FIRST_PAGE] First page content length: {len(first_page.get('content', ''))} characters")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            logger.debug(f"üìÑ [FIRST_PAGE] Extracting project info from content")
            project_info = await self.extract_project_info(first_page.get("content", ""))
            logger.debug(f"üìÑ [FIRST_PAGE] Extracting document metadata from content")
            document_metadata = await self.extract_document_metadata(first_page.get("content", ""))
            
            analysis_result = {
                "page_number": 1,
                "content_length": len(first_page.get("content", "")),
                "project_info": project_info,
                "document_metadata": document_metadata,
                "analysis_timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"üìÑ [FIRST_PAGE] Project info extracted: {project_info.get('project_name', 'Unknown')} - {project_info.get('project_stage', 'Unknown')}")
            logger.info(f"üìÑ [FIRST_PAGE] Document metadata: {document_metadata.get('document_mark', 'Unknown')} - {document_metadata.get('scale', 'Unknown')}")
            
            logger.info(f"üìÑ [FIRST_PAGE] First page analysis completed: {analysis_result.get('project_info', {}).get('project_name', 'Unknown')}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"‚ùå [FIRST_PAGE] First page analysis failed: {e}")
            return {"error": str(e)}
    
    async def extract_project_info(self, content: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–µ–∫—Ç–µ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            logger.info(f"üîç [PROJECT_INFO] Extracting project information from content")
            logger.debug(f"üîç [PROJECT_INFO] Content length: {len(content)} characters")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            project_info = {
                "project_name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–µ–∫—Ç",
                "project_stage": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç–∞–¥–∏—è",
                "project_type": "–°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π",
                "document_set": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–æ–º–ø–ª–µ–∫—Ç",
                "project_code": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —à–∏—Ñ—Ä",
                "confidence": 0.5
            }
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏
            lines = [line.strip() for line in content.split('\n') if line.strip()]
            logger.debug(f"üîç [PROJECT_INFO] Processing {len(lines)} non-empty lines")
            
            # –ü–æ–∏—Å–∫ —à–∏—Ñ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (–ø–∞—Ç—Ç–µ—Ä–Ω: –ï110-0038-–£–ö–ö.24.848-–†–î-01-02.12.032-–ê–†)
            project_code = self.extract_project_code(content)
            if project_code:
                project_info["project_code"] = project_code
                project_info["confidence"] += 0.2
                logger.info(f"üîç [PROJECT_INFO] Found project code: {project_code}")
            
            # –ü–æ–∏—Å–∫ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞
            project_name = self.extract_project_name(content, lines)
            if project_name:
                project_info["project_name"] = project_name
                project_info["confidence"] += 0.2
                logger.info(f"üîç [PROJECT_INFO] Found project name: {project_name}")
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞–¥–∏–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            project_stage = self.extract_project_stage(content)
            if project_stage:
                project_info["project_stage"] = project_stage
                project_info["confidence"] += 0.1
                logger.info(f"üîç [PROJECT_INFO] Found project stage: {project_stage}")
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Ä–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç–∞
            document_set = self.extract_document_set(content, project_code)
            if document_set:
                project_info["document_set"] = document_set
                project_info["confidence"] += 0.2
                logger.info(f"üîç [PROJECT_INFO] Found document set: {document_set}")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–æ 1.0
            project_info["confidence"] = min(project_info["confidence"], 1.0)
            
            logger.info(f"üîç [PROJECT_INFO] Final project info: {project_info}")
            return project_info
            
        except Exception as e:
            logger.error(f"‚ùå [PROJECT_INFO] Error extracting project info: {e}")
            return {"project_name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–µ–∫—Ç", "error": str(e)}
    
    def extract_project_code(self, content: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —à–∏—Ñ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
        try:
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —à–∏—Ñ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
            import re
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —à–∏—Ñ—Ä–∞ —Ç–∏–ø–∞ –ï110-0038-–£–ö–ö.24.848-–†–î-01-02.12.032-–ê–†
            patterns = [
                r'[–ê-–Ø]\d{3}-\d{4}-[–ê-–Ø]{2,3}\.\d{2}\.\d{3}-[–ê-–Ø]{2}-\d{2}-\d{2}\.\d{3}-[–ê-–Ø]{2}',
                r'[–ê-–Ø]\d{3}-\d{4}-[–ê-–Ø]{2,3}\.\d{2}\.\d{3}-[–ê-–Ø]{2}-\d{2}-\d{2}\.\d{3}-[–ê-–Ø]{2}',
                r'[–ê-–Ø]\d{3}-\d{4}-[–ê-–Ø]{2,3}\.\d{2}\.\d{3}-[–ê-–Ø]{2}-\d{2}-\d{2}\.\d{3}-[–ê-–Ø]{2}',
                r'[–ê-–Ø]\d{3}-\d{4}-[–ê-–Ø]{2,3}\.\d{2}\.\d{3}-[–ê-–Ø]{2}-\d{2}-\d{2}\.\d{3}-[–ê-–Ø]{2}'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, content)
                if matches:
                    return matches[0]
            
            # –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            lines = content.split('\n')
            for line in lines:
                if any(keyword in line.upper() for keyword in ['–ï110', '–£–ö–ö', '–†–î', '–ê–†']):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –∏–∑ —Å—Ç—Ä–æ–∫–∏
                    words = line.split()
                    for word in words:
                        if any(keyword in word.upper() for keyword in ['–ï110', '–£–ö–ö', '–†–î', '–ê–†']):
                            return word.strip()
            
            return None
            
        except Exception as e:
            logger.error(f"Error extracting project code: {e}")
            return None
    
    def extract_project_name(self, content: str, lines: List[str]) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞"""
        try:
            # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞
            keywords = ['–∫–æ–º–±–∏–Ω–∞—Ç', '—Ñ–∞–±—Ä–∏–∫–∞', '–∑–∞–≤–æ–¥', '–∫–æ–º–ø–ª–µ–∫—Å', '–æ–±—ä–µ–∫—Ç', '—Å–æ–æ—Ä—É–∂–µ–Ω–∏–µ']
            
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            project_name_parts = []
            found_keyword = False
            
            for i, line in enumerate(lines):
                line_lower = line.lower()
                line_stripped = line.strip()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                if any(keyword in line_lower for keyword in keywords):
                    found_keyword = True
                    if len(line_stripped) > 10:
                        project_name_parts.append(line_stripped)
                    
                    # –°–æ–±–∏—Ä–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å —á–∞—Å—Ç—å—é –Ω–∞–∑–≤–∞–Ω–∏—è
                    for j in range(i + 1, min(i + 5, len(lines))):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ 4 —Å—Ç—Ä–æ–∫–∏
                        next_line = lines[j].strip()
                        if len(next_line) > 5 and not next_line.isdigit():
                            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                            if any(term in next_line.lower() for term in ['–º–æ—â–Ω–æ—Å—Ç—å', '–º–ª–Ω', '–≥–æ–¥', '–º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏–µ', '—Ä–∞–π–æ–Ω', '–æ–±–ª–∞—Å—Ç—å', '—Ä—É–¥–Ω–∏–∫', '–∫–æ–º–ø–ª–µ–∫—Å', '—Å—Ç–≤–æ–ª', '–∫–æ–ø–µ—Ä']):
                                project_name_parts.append(next_line)
                            elif next_line.isupper() and len(next_line) > 10:
                                project_name_parts.append(next_line)
                            else:
                                break
                    break
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —á–∞—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏—è, –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Ö
            if project_name_parts:
                return ' '.join(project_name_parts)
            
            # –ü–æ–∏—Å–∫ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É "–ù–ê–ó–í–ê–ù–ò–ï –ü–†–û–ï–ö–¢–ê"
            for line in lines:
                if '–Ω–∞–∑–≤–∞–Ω–∏–µ' in line.lower() and '–ø—Ä–æ–µ–∫—Ç' in line.lower():
                    # –ò—â–µ–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º
                    line_index = lines.index(line)
                    if line_index + 1 < len(lines):
                        next_line = lines[line_index + 1].strip()
                        if len(next_line) > 10:
                            return next_line
            
            # –ü–æ–∏—Å–∫ –ø–æ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É (—á–∞—Å—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –ø–∏—à–µ—Ç—Å—è –∑–∞–≥–ª–∞–≤–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏)
            for line in lines:
                if line.isupper() and len(line.strip()) > 20:
                    return line.strip()
            
            return None
            
        except Exception as e:
            logger.error(f"Error extracting project name: {e}")
            return None
    
    def extract_project_stage(self, content: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞–¥–∏–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            content_lower = content.lower()
            
            if '—Ä–∞–±–æ—á–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è' in content_lower or '—Ä–∞–±–æ—á–∞—è' in content_lower:
                return "–†–∞–±–æ—á–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
            elif '–ø—Ä–æ–µ–∫—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è' in content_lower or '–ø—Ä–æ–µ–∫—Ç–Ω–∞—è' in content_lower:
                return "–ü—Ä–æ–µ–∫—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
            elif '—ç—Å–∫–∏–∑–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è' in content_lower or '—ç—Å–∫–∏–∑–Ω–∞—è' in content_lower:
                return "–≠—Å–∫–∏–∑–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
            
            return None
            
        except Exception as e:
            logger.error(f"Error extracting project stage: {e}")
            return None
    
    def extract_document_set(self, content: str, project_code: Optional[str]) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Ä–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            content_lower = content.lower()
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —à–∏—Ñ—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
            if project_code:
                if '-–ê–†' in project_code.upper():
                    return "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è"
                elif '-–ö–†' in project_code.upper():
                    return "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è"
                elif '-–û–í' in project_code.upper():
                    return "–û—Ç–æ–ø–ª–µ–Ω–∏–µ –∏ –≤–µ–Ω—Ç–∏–ª—è—Ü–∏—è"
                elif '-–í–ö' in project_code.upper():
                    return "–í–æ–¥–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ –∏ –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è"
                elif '-–≠–°' in project_code.upper():
                    return "–≠–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ"
                elif '-–°–°' in project_code.upper():
                    return "–°–µ—Ç–∏ —Å–≤—è–∑–∏"
                elif '-–ü–û–°' in project_code.upper():
                    return "–ü—Ä–æ–µ–∫—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞"
                elif '-–ü–¢' in project_code.upper():
                    return "–ü—Ä–æ–µ–∫—Ç –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç"
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ
            if '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω' in content_lower:
                return "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è"
            elif '–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω' in content_lower:
                return "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è"
            elif '–æ—Ç–æ–ø–ª–µ–Ω' in content_lower or '–≤–µ–Ω—Ç–∏–ª—è—Ü' in content_lower:
                return "–û—Ç–æ–ø–ª–µ–Ω–∏–µ –∏ –≤–µ–Ω—Ç–∏–ª—è—Ü–∏—è"
            elif '–≤–æ–¥–æ—Å–Ω–∞–±–∂–µ–Ω' in content_lower or '–∫–∞–Ω–∞–ª–∏–∑–∞—Ü' in content_lower:
                return "–í–æ–¥–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ –∏ –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è"
            elif '—ç–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω' in content_lower:
                return "–≠–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ"
            elif '—Å–≤—è–∑' in content_lower:
                return "–°–µ—Ç–∏ —Å–≤—è–∑–∏"
            elif '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü' in content_lower and '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤' in content_lower:
                return "–ü—Ä–æ–µ–∫—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞"
            elif '–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤' in content_lower and '—Ä–∞–±–æ—Ç' in content_lower:
                return "–ü—Ä–æ–µ–∫—Ç –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç"
            
            return None
            
        except Exception as e:
            logger.error(f"Error extracting document set: {e}")
            return None
    
    async def extract_document_metadata(self, content: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            metadata = {
                "document_type": "–ß–µ—Ä—Ç–µ–∂",
                "document_mark": "–ö–†",
                "document_number": "01",
                "revision": "0",
                "scale": "1:100",
                "sheet_number": "1",
                "total_sheets": "1"
            }
            
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            lines = content.split('\n')
            for line in lines:
                line_lower = line.lower()
                if "–º–∞—Å—à—Ç–∞–±" in line_lower or "1:" in line:
                    metadata["scale"] = line.strip()
                elif "–ª–∏—Å—Ç" in line_lower:
                    metadata["sheet_number"] = line.strip()
                elif "–º–∞—Ä–∫–∞" in line_lower:
                    metadata["document_mark"] = line.strip()
            
            return metadata
            
        except Exception as e:
            logger.error(f"Error extracting document metadata: {e}")
            return {"error": str(e)}
    
    async def check_norm_compliance(self, document_id: int, first_page_info: Dict[str, Any]) -> Dict[str, Any]:
        """–≠—Ç–∞–ø 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º"""
        try:
            logger.info(f"üìã [NORM_COMPLIANCE] Checking norm compliance for document {document_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–µ–∫—Ç–µ
            project_info = first_page_info.get("project_info", {})
            project_stage = project_info.get("project_stage", "–†–∞–±–æ—á–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è")
            document_set = project_info.get("document_set", "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è")
            
            logger.info(f"üìã [NORM_COMPLIANCE] Project stage: {project_stage}, Document set: {document_set}")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
            logger.debug(f"üìã [NORM_COMPLIANCE] Fetching all pages content for document {document_id}")
            pages = self.get_all_pages_content(document_id)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
            total_pages = len(set(page["page_number"] for page in pages))
            compliant_pages = 0
            findings = []
            
            logger.info(f"üìã [NORM_COMPLIANCE] Total pages to check: {total_pages}")
            
            for page_data in pages:
                page_number = page_data["page_number"]
                content = page_data["content"]
                
                logger.info(f"üìã [NORM_COMPLIANCE] Checking page {page_number}/{total_pages} (content length: {len(content)} chars)")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º
                page_start = datetime.now()
                page_findings = await self.check_page_norm_compliance(
                    content, page_number, project_stage, document_set
                )
                page_time = (datetime.now() - page_start).total_seconds()
                
                findings.extend(page_findings)
                
                if not page_findings:
                    compliant_pages += 1
                
                logger.debug(f"üìã [NORM_COMPLIANCE] Page {page_number} checked in {page_time:.2f}s, findings: {len(page_findings)}")
            
            result = {
                "project_stage": project_stage,
                "document_set": document_set,
                "total_pages": total_pages,
                "compliant_pages": compliant_pages,
                "compliance_percentage": (compliant_pages / total_pages * 100) if total_pages > 0 else 0,
                "findings": findings,
                "total_findings": len(findings),
                "critical_findings": len([f for f in findings if f.get("severity", 0) >= 4]),
                "warning_findings": len([f for f in findings if f.get("severity", 0) == 3]),
                "info_findings": len([f for f in findings if f.get("severity", 0) <= 2])
            }
            
            logger.info(f"üìã [NORM_COMPLIANCE] Norm compliance check completed: {result['total_findings']} findings")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [NORM_COMPLIANCE] Norm compliance check failed: {e}")
            return {"error": str(e)}
    
    async def check_page_norm_compliance(self, content: str, page_number: int, 
                                       project_stage: str, document_set: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º"""
        findings = []
        
        try:
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ LLM)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            if "–æ–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ" in content.lower():
                if "–º–∞—Å—à—Ç–∞–±" not in content.lower():
                    findings.append({
                        "type": "warning",
                        "severity": 3,
                        "category": "general_data",
                        "title": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –º–∞—Å—à—Ç–∞–±",
                        "description": f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —É–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞",
                        "recommendation": "–î–æ–±–∞–≤–∏—Ç—å –º–∞—Å—à—Ç–∞–± –≤ —Ä–∞–∑–¥–µ–ª '–û–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ'",
                        "page_number": page_number
                    })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–¥–∏–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            if project_stage == "–†–∞–±–æ—á–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è":
                if "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è" not in content.lower() and "–≤–µ–¥–æ–º–æ—Å—Ç—å" not in content.lower():
                    findings.append({
                        "type": "info",
                        "severity": 2,
                        "category": "working_documentation",
                        "title": "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é",
                        "description": f"–î–ª—è —Ä–∞–±–æ—á–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤–∫–ª—é—á–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number}",
                        "recommendation": "–î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –∏–∑–¥–µ–ª–∏–π",
                        "page_number": page_number
                    })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–∞—Ä–∫–µ –∫–æ–º–ø–ª–µ–∫—Ç–∞
            if document_set == "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è":
                if "–∞—Ä–º–∞—Ç—É—Ä–∞" in content.lower() and "–∫–ª–∞—Å—Å" not in content.lower():
                    findings.append({
                        "type": "warning",
                        "severity": 3,
                        "category": "structural_solutions",
                        "title": "–ù–µ —É–∫–∞–∑–∞–Ω –∫–ª–∞—Å—Å –∞—Ä–º–∞—Ç—É—Ä—ã",
                        "description": f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number} —É–∫–∞–∑–∞–Ω–∞ –∞—Ä–º–∞—Ç—É—Ä–∞ –±–µ–∑ –∫–ª–∞—Å—Å–∞",
                        "recommendation": "–£–∫–∞–∑–∞—Ç—å –∫–ª–∞—Å—Å –∞—Ä–º–∞—Ç—É—Ä—ã —Å–æ–≥–ª–∞—Å–Ω–æ –°–ü 63.13330",
                        "page_number": page_number
                    })
            
        except Exception as e:
            logger.error(f"Error checking page {page_number} norm compliance: {e}")
            findings.append({
                "type": "error",
                "severity": 5,
                "category": "system_error",
                "title": "–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã",
                "description": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}",
                "recommendation": "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É",
                "page_number": page_number
            })
        
        return findings
    
    async def analyze_document_sections(self, document_id: int, first_page_info: Dict[str, Any]) -> Dict[str, Any]:
        """–≠—Ç–∞–ø 3: –í—ã—è–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        try:
            logger.info(f"üìë [SECTIONS] Analyzing document sections for document {document_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            pages = self.get_all_pages_content(document_id)
            
            sections = []
            current_section = None
            
            for page_data in pages:
                page_number = page_data["page_number"]
                content = page_data["content"]
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                section_info = await self.identify_page_section(content, page_number)
                
                if section_info["section_type"] != current_section:
                    current_section = section_info["section_type"]
                    sections.append({
                        "section_type": current_section,
                        "start_page": page_number,
                        "end_page": page_number,
                        "pages_count": 1,
                        "section_name": section_info["section_name"],
                        "check_priority": section_info["check_priority"]
                    })
                else:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑–¥–µ–ª
                    if sections:
                        sections[-1]["end_page"] = page_number
                        sections[-1]["pages_count"] += 1
            
            result = {
                "sections": sections,
                "total_sections": len(sections),
                "section_analysis": {
                    "general_data_section": next((s for s in sections if s["section_type"] == "general_data"), None),
                    "main_content_sections": [s for s in sections if s["section_type"] == "main_content"],
                    "specification_sections": [s for s in sections if s["section_type"] == "specification"]
                }
            }
            
            logger.info(f"üìë [SECTIONS] Document sections analysis completed: {len(sections)} sections identified")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [SECTIONS] Document sections analysis failed: {e}")
            return {"error": str(e)}
    
    async def identify_page_section(self, content: str, page_number: int) -> Dict[str, Any]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            content_lower = content.lower()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ä–∞–∑–¥–µ–ª–∞
            if "–æ–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ" in content_lower or "–æ–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è" in content_lower:
                return {
                    "section_type": "general_data",
                    "section_name": "–û–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ",
                    "check_priority": "high"
                }
            elif "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è" in content_lower or "–≤–µ–¥–æ–º–æ—Å—Ç—å" in content_lower:
                return {
                    "section_type": "specification",
                    "section_name": "–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è",
                    "check_priority": "medium"
                }
            elif "—É–∑–ª—ã" in content_lower or "–¥–µ—Ç–∞–ª–∏" in content_lower:
                return {
                    "section_type": "details",
                    "section_name": "–£–∑–ª—ã –∏ –¥–µ—Ç–∞–ª–∏",
                    "check_priority": "medium"
                }
            else:
                return {
                    "section_type": "main_content",
                    "section_name": "–û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
                    "check_priority": "normal"
                }
                
        except Exception as e:
            logger.error(f"Error identifying page section: {e}")
            return {
                "section_type": "unknown",
                "section_name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–∞–∑–¥–µ–ª",
                "check_priority": "low"
            }
    
    def determine_overall_status(self, norm_compliance_results: Dict[str, Any]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        try:
            critical_findings = norm_compliance_results.get("critical_findings", 0)
            warning_findings = norm_compliance_results.get("warning_findings", 0)
            compliance_percentage = norm_compliance_results.get("compliance_percentage", 0)
            
            if critical_findings > 0:
                return "fail"
            elif warning_findings > 0 or compliance_percentage < 80:
                return "warning"
            else:
                return "pass"
                
        except Exception as e:
            logger.error(f"Error determining overall status: {e}")
            return "unknown"
    
    def get_first_page_content(self, document_id: int) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            with self.db_connection.get_db_connection().cursor() as cursor:
                cursor.execute("""
                    SELECT element_content, page_number
                    FROM checkable_elements
                    WHERE checkable_document_id = %s AND page_number = 1
                    ORDER BY id
                    LIMIT 1
                """, (document_id,))
                
                result = cursor.fetchone()
                if result:
                    return {
                        "content": result[0],  # element_content
                        "page_number": result[1]  # page_number
                    }
                return None
                
        except Exception as e:
            logger.error(f"Error getting first page content: {e}")
            return None
    
    def get_all_pages_content(self, document_id: int) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
        try:
            with self.db_connection.get_db_connection().cursor() as cursor:
                cursor.execute("""
                    SELECT element_content, page_number
                    FROM checkable_elements
                    WHERE checkable_document_id = %s
                    ORDER BY page_number, id
                """, (document_id,))
                
                pages = []
                for row in cursor.fetchall():
                    pages.append({
                        "content": row[0],  # element_content
                        "page_number": row[1]  # page_number
                    })
                
                return pages
                
        except Exception as e:
            logger.error(f"Error getting all pages content: {e}")
            return []
    
    async def save_hierarchical_check_result(self, document_id: int, result: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        try:
            def _save_result(conn):
                with conn.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO hierarchical_check_results 
                        (checkable_document_id, analysis_date, check_type, execution_time,
                         project_info, norm_compliance_summary, sections_analysis, overall_status)
                        VALUES (%s, CURRENT_TIMESTAMP, %s, %s, %s, %s, %s, %s)
                        RETURNING id
                    """, (
                        document_id,
                        result.get("check_type", "hierarchical"),
                        result.get("execution_time", 0),
                        str(result.get("stages", {}).get("first_page_analysis", {}).get("project_info", {})),
                        str(result.get("stages", {}).get("norm_compliance", {})),
                        str(result.get("stages", {}).get("section_analysis", {})),
                        result.get("summary", {}).get("overall_status", "unknown")
                    ))
                    
                    result_id = cursor.fetchone()[0]
                    logger.info(f"Saved hierarchical check result {result_id} for document {document_id}")
                    return result_id
            
            result_id = self.db_connection.execute_in_transaction(_save_result)
            return result_id
                
        except Exception as e:
            logger.error(f"Save hierarchical check result error: {e}")
            raise
