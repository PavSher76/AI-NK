import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from models.data_models import DocumentInspectionResult, PageResult, Finding, FindingType, SeverityLevel
from database.connection import DatabaseConnection
from utils.memory_utils import check_memory_pressure, cleanup_memory

logger = logging.getLogger(__name__)

class HierarchicalCheckService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, db_connection: DatabaseConnection):
        self.db_connection = db_connection
    
    async def perform_hierarchical_check(self, document_id: int) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            logger.info(f"üöÄ [HIERARCHICAL] Starting hierarchical check for document {document_id}")
            start_time = datetime.now()
            
            # –≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            logger.info(f"üìÑ [HIERARCHICAL] Stage 1: Quick first page analysis")
            first_page_info = await self.analyze_first_page(document_id)
            
            # –≠—Ç–∞–ø 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º
            logger.info(f"üìã [HIERARCHICAL] Stage 2: Full document norm compliance check")
            norm_compliance_results = await self.check_norm_compliance(document_id, first_page_info)
            
            # –≠—Ç–∞–ø 3: –í—ã—è–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
            logger.info(f"üìë [HIERARCHICAL] Stage 3: Document sections identification and organization")
            section_analysis = await self.analyze_document_sections(document_id, first_page_info)
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—â–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            total_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                "document_id": document_id,
                "check_type": "hierarchical",
                "execution_time": total_time,
                "stages": {
                    "first_page_analysis": first_page_info,
                    "norm_compliance": norm_compliance_results,
                    "section_analysis": section_analysis
                },
                "summary": {
                    "project_info": first_page_info.get("project_info", {}),
                    "total_findings": norm_compliance_results.get("total_findings", 0),
                    "sections_identified": len(section_analysis.get("sections", [])),
                    "overall_status": self.determine_overall_status(norm_compliance_results)
                }
            }
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            await self.save_hierarchical_check_result(document_id, result)
            
            logger.info(f"‚úÖ [HIERARCHICAL] Hierarchical check completed for document {document_id} in {total_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [HIERARCHICAL] Hierarchical check failed for document {document_id}: {e}")
            return {
                "status": "error",
                "error": str(e),
                "document_id": document_id
            }
    
    async def analyze_first_page(self, document_id: int) -> Dict[str, Any]:
        """–≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        try:
            logger.info(f"üìÑ [FIRST_PAGE] Analyzing first page for document {document_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
            first_page = self.get_first_page_content(document_id)
            if not first_page:
                return {"error": "First page not found"}
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            analysis_result = {
                "page_number": 1,
                "content_length": len(first_page.get("content", "")),
                "project_info": await self.extract_project_info(first_page.get("content", "")),
                "document_metadata": await self.extract_document_metadata(first_page.get("content", "")),
                "analysis_timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"üìÑ [FIRST_PAGE] First page analysis completed: {analysis_result.get('project_info', {}).get('project_name', 'Unknown')}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"‚ùå [FIRST_PAGE] First page analysis failed: {e}")
            return {"error": str(e)}
    
    async def extract_project_info(self, content: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–µ–∫—Ç–µ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–µ–∫—Ç–µ
            # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
            project_info = {
                "project_name": "–ü—Ä–æ–µ–∫—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é",
                "project_stage": "–†–∞–±–æ—á–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è",
                "project_type": "–°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π",
                "document_set": "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è",
                "confidence": 0.8
            }
            
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ LLM)
            if "–ø—Ä–æ–µ–∫—Ç" in content.lower():
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
                lines = content.split('\n')
                for line in lines:
                    if "–ø—Ä–æ–µ–∫—Ç" in line.lower() and len(line.strip()) > 10:
                        project_info["project_name"] = line.strip()
                        break
            
            if "—Ä–∞–±–æ—á–∞—è" in content.lower():
                project_info["project_stage"] = "–†–∞–±–æ—á–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
            elif "–ø—Ä–æ–µ–∫—Ç–Ω–∞—è" in content.lower():
                project_info["project_stage"] = "–ü—Ä–æ–µ–∫—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
            
            return project_info
            
        except Exception as e:
            logger.error(f"Error extracting project info: {e}")
            return {"project_name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–µ–∫—Ç", "error": str(e)}
    
    async def extract_document_metadata(self, content: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            metadata = {
                "document_type": "–ß–µ—Ä—Ç–µ–∂",
                "document_mark": "–ö–†",
                "document_number": "01",
                "revision": "0",
                "scale": "1:100",
                "sheet_number": "1",
                "total_sheets": "1"
            }
            
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            lines = content.split('\n')
            for line in lines:
                line_lower = line.lower()
                if "–º–∞—Å—à—Ç–∞–±" in line_lower or "1:" in line:
                    metadata["scale"] = line.strip()
                elif "–ª–∏—Å—Ç" in line_lower:
                    metadata["sheet_number"] = line.strip()
                elif "–º–∞—Ä–∫–∞" in line_lower:
                    metadata["document_mark"] = line.strip()
            
            return metadata
            
        except Exception as e:
            logger.error(f"Error extracting document metadata: {e}")
            return {"error": str(e)}
    
    async def check_norm_compliance(self, document_id: int, first_page_info: Dict[str, Any]) -> Dict[str, Any]:
        """–≠—Ç–∞–ø 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º"""
        try:
            logger.info(f"üìã [NORM_COMPLIANCE] Checking norm compliance for document {document_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–µ–∫—Ç–µ
            project_info = first_page_info.get("project_info", {})
            project_stage = project_info.get("project_stage", "–†–∞–±–æ—á–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è")
            document_set = project_info.get("document_set", "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
            pages = self.get_all_pages_content(document_id)
            
            findings = []
            total_pages = len(pages)
            compliant_pages = 0
            
            for page_data in pages:
                page_number = page_data["page_number"]
                content = page_data["content"]
                
                logger.info(f"üìã [NORM_COMPLIANCE] Checking page {page_number}/{total_pages}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º
                page_findings = await self.check_page_norm_compliance(
                    content, page_number, project_stage, document_set
                )
                
                findings.extend(page_findings)
                
                if not page_findings:
                    compliant_pages += 1
            
            result = {
                "project_stage": project_stage,
                "document_set": document_set,
                "total_pages": total_pages,
                "compliant_pages": compliant_pages,
                "compliance_percentage": (compliant_pages / total_pages * 100) if total_pages > 0 else 0,
                "findings": findings,
                "total_findings": len(findings),
                "critical_findings": len([f for f in findings if f.get("severity", 0) >= 4]),
                "warning_findings": len([f for f in findings if f.get("severity", 0) == 3]),
                "info_findings": len([f for f in findings if f.get("severity", 0) <= 2])
            }
            
            logger.info(f"üìã [NORM_COMPLIANCE] Norm compliance check completed: {result['total_findings']} findings")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [NORM_COMPLIANCE] Norm compliance check failed: {e}")
            return {"error": str(e)}
    
    async def check_page_norm_compliance(self, content: str, page_number: int, 
                                       project_stage: str, document_set: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º"""
        findings = []
        
        try:
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ LLM)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            if "–æ–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ" in content.lower():
                if "–º–∞—Å—à—Ç–∞–±" not in content.lower():
                    findings.append({
                        "type": "warning",
                        "severity": 3,
                        "category": "general_data",
                        "title": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –º–∞—Å—à—Ç–∞–±",
                        "description": f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —É–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞",
                        "recommendation": "–î–æ–±–∞–≤–∏—Ç—å –º–∞—Å—à—Ç–∞–± –≤ —Ä–∞–∑–¥–µ–ª '–û–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ'",
                        "page_number": page_number
                    })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–¥–∏–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            if project_stage == "–†–∞–±–æ—á–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è":
                if "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è" not in content.lower() and "–≤–µ–¥–æ–º–æ—Å—Ç—å" not in content.lower():
                    findings.append({
                        "type": "info",
                        "severity": 2,
                        "category": "working_documentation",
                        "title": "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é",
                        "description": f"–î–ª—è —Ä–∞–±–æ—á–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤–∫–ª—é—á–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number}",
                        "recommendation": "–î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –∏–∑–¥–µ–ª–∏–π",
                        "page_number": page_number
                    })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–∞—Ä–∫–µ –∫–æ–º–ø–ª–µ–∫—Ç–∞
            if document_set == "–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è":
                if "–∞—Ä–º–∞—Ç—É—Ä–∞" in content.lower() and "–∫–ª–∞—Å—Å" not in content.lower():
                    findings.append({
                        "type": "warning",
                        "severity": 3,
                        "category": "structural_solutions",
                        "title": "–ù–µ —É–∫–∞–∑–∞–Ω –∫–ª–∞—Å—Å –∞—Ä–º–∞—Ç—É—Ä—ã",
                        "description": f"–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number} —É–∫–∞–∑–∞–Ω–∞ –∞—Ä–º–∞—Ç—É—Ä–∞ –±–µ–∑ –∫–ª–∞—Å—Å–∞",
                        "recommendation": "–£–∫–∞–∑–∞—Ç—å –∫–ª–∞—Å—Å –∞—Ä–º–∞—Ç—É—Ä—ã —Å–æ–≥–ª–∞—Å–Ω–æ –°–ü 63.13330",
                        "page_number": page_number
                    })
            
        except Exception as e:
            logger.error(f"Error checking page {page_number} norm compliance: {e}")
            findings.append({
                "type": "error",
                "severity": 5,
                "category": "system_error",
                "title": "–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã",
                "description": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}",
                "recommendation": "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É",
                "page_number": page_number
            })
        
        return findings
    
    async def analyze_document_sections(self, document_id: int, first_page_info: Dict[str, Any]) -> Dict[str, Any]:
        """–≠—Ç–∞–ø 3: –í—ã—è–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        try:
            logger.info(f"üìë [SECTIONS] Analyzing document sections for document {document_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            pages = self.get_all_pages_content(document_id)
            
            sections = []
            current_section = None
            
            for page_data in pages:
                page_number = page_data["page_number"]
                content = page_data["content"]
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                section_info = await self.identify_page_section(content, page_number)
                
                if section_info["section_type"] != current_section:
                    current_section = section_info["section_type"]
                    sections.append({
                        "section_type": current_section,
                        "start_page": page_number,
                        "end_page": page_number,
                        "pages_count": 1,
                        "section_name": section_info["section_name"],
                        "check_priority": section_info["check_priority"]
                    })
                else:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑–¥–µ–ª
                    if sections:
                        sections[-1]["end_page"] = page_number
                        sections[-1]["pages_count"] += 1
            
            result = {
                "sections": sections,
                "total_sections": len(sections),
                "section_analysis": {
                    "general_data_section": next((s for s in sections if s["section_type"] == "general_data"), None),
                    "main_content_sections": [s for s in sections if s["section_type"] == "main_content"],
                    "specification_sections": [s for s in sections if s["section_type"] == "specification"]
                }
            }
            
            logger.info(f"üìë [SECTIONS] Document sections analysis completed: {len(sections)} sections identified")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [SECTIONS] Document sections analysis failed: {e}")
            return {"error": str(e)}
    
    async def identify_page_section(self, content: str, page_number: int) -> Dict[str, Any]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            content_lower = content.lower()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ä–∞–∑–¥–µ–ª–∞
            if "–æ–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ" in content_lower or "–æ–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è" in content_lower:
                return {
                    "section_type": "general_data",
                    "section_name": "–û–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ",
                    "check_priority": "high"
                }
            elif "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è" in content_lower or "–≤–µ–¥–æ–º–æ—Å—Ç—å" in content_lower:
                return {
                    "section_type": "specification",
                    "section_name": "–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è",
                    "check_priority": "medium"
                }
            elif "—É–∑–ª—ã" in content_lower or "–¥–µ—Ç–∞–ª–∏" in content_lower:
                return {
                    "section_type": "details",
                    "section_name": "–£–∑–ª—ã –∏ –¥–µ—Ç–∞–ª–∏",
                    "check_priority": "medium"
                }
            else:
                return {
                    "section_type": "main_content",
                    "section_name": "–û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
                    "check_priority": "normal"
                }
                
        except Exception as e:
            logger.error(f"Error identifying page section: {e}")
            return {
                "section_type": "unknown",
                "section_name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–∞–∑–¥–µ–ª",
                "check_priority": "low"
            }
    
    def determine_overall_status(self, norm_compliance_results: Dict[str, Any]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        try:
            critical_findings = norm_compliance_results.get("critical_findings", 0)
            warning_findings = norm_compliance_results.get("warning_findings", 0)
            compliance_percentage = norm_compliance_results.get("compliance_percentage", 0)
            
            if critical_findings > 0:
                return "fail"
            elif warning_findings > 0 or compliance_percentage < 80:
                return "warning"
            else:
                return "pass"
                
        except Exception as e:
            logger.error(f"Error determining overall status: {e}")
            return "unknown"
    
    def get_first_page_content(self, document_id: int) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            with self.db_connection.get_db_connection().cursor() as cursor:
                cursor.execute("""
                    SELECT element_content, page_number
                    FROM checkable_elements
                    WHERE checkable_document_id = %s AND page_number = 1
                    ORDER BY id
                    LIMIT 1
                """, (document_id,))
                
                result = cursor.fetchone()
                if result:
                    return {
                        "content": result["element_content"],
                        "page_number": result["page_number"]
                    }
                return None
                
        except Exception as e:
            logger.error(f"Error getting first page content: {e}")
            return None
    
    def get_all_pages_content(self, document_id: int) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
        try:
            with self.db_connection.get_db_connection().cursor() as cursor:
                cursor.execute("""
                    SELECT element_content, page_number
                    FROM checkable_elements
                    WHERE checkable_document_id = %s
                    ORDER BY page_number, id
                """, (document_id,))
                
                pages = []
                for row in cursor.fetchall():
                    pages.append({
                        "content": row["element_content"],
                        "page_number": row["page_number"]
                    })
                
                return pages
                
        except Exception as e:
            logger.error(f"Error getting all pages content: {e}")
            return []
    
    async def save_hierarchical_check_result(self, document_id: int, result: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        try:
            def _save_result(conn):
                with conn.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO hierarchical_check_results 
                        (checkable_document_id, analysis_date, check_type, execution_time,
                         project_info, norm_compliance_summary, sections_analysis, overall_status)
                        VALUES (%s, CURRENT_TIMESTAMP, %s, %s, %s, %s, %s, %s)
                        RETURNING id
                    """, (
                        document_id,
                        result.get("check_type", "hierarchical"),
                        result.get("execution_time", 0),
                        str(result.get("stages", {}).get("first_page_analysis", {}).get("project_info", {})),
                        str(result.get("stages", {}).get("norm_compliance", {})),
                        str(result.get("stages", {}).get("section_analysis", {})),
                        result.get("summary", {}).get("overall_status", "unknown")
                    ))
                    
                    result_id = cursor.fetchone()[0]
                    logger.info(f"Saved hierarchical check result {result_id} for document {document_id}")
                    return result_id
            
            result_id = self.db_connection.execute_in_transaction(_save_result)
            return result_id
                
        except Exception as e:
            logger.error(f"Save hierarchical check result error: {e}")
            raise
