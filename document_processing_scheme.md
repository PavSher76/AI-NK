# Схема обработки документов в системе AI-NK

## 1. Маршрут загрузки "Нормативного документа" (страница "Нормативные документы")

### 1.1 Фронтенд (NormativeDocuments.js)
```
Пользователь выбирает файл → Нажимает "Загрузить" → 
POST /api/upload (с FormData: file, category)
```

### 1.2 Gateway (app.py)
```
POST /api/upload → Проксирование на document-parser:8080/upload
```

### 1.3 Document Parser (main.py) - upload_document endpoint
```
1. Получение файла и категории
2. Проверка типа файла (PDF, DOCX, TXT)
3. Вычисление хеша файла
4. Проверка на дубликаты в БД
5. Сохранение файла в /app/uploads/
6. Создание записи в uploaded_documents (статус: "processing")
7. Запуск фоновой задачи process_document_async()
```

### 1.4 Фоновая обработка (process_document_async)
```
1. Обновление статуса документа на "processing"
2. Чтение файла
3. Парсинг документа (PDF/DOCX/TXT)
4. Определение категории документа
5. Вызов parser.save_normative_document()
```

### 1.5 Сохранение нормативного документа (save_normative_document)
```
1. Обновление записи в uploaded_documents
2. Сохранение извлеченных элементов в extracted_elements
3. Вызов save_to_database() для каждого элемента
```

### 1.6 Сохранение в БД (save_to_database)
```
1. Вставка элемента в extracted_elements
2. Отправка POST запроса к RAG Service /index
   - document_id
   - document_title  
   - content
   - chapter
   - section
   - page_number
```

### 1.7 RAG Service (main.py) - index endpoint
```
1. Получение данных документа
2. Вызов rag_service.chunk_document()
3. Вызов rag_service.index_chunks()
```

### 1.8 Чанкинг документа (chunk_document)
```
1. Разбиение текста на чанки (CHUNK_SIZE=500 токенов)
2. Определение типа чанка (TEXT/TABLE/FIGURE/HEADER)
3. Извлечение clause_id (п.1.2.3, статья 5, ГОСТ 12345-2020 п.4.1)
4. Создание метаданных чанка
5. Возврат списка NormChunk объектов
```

### 1.9 Индексация чанков (index_chunks)
```
1. Создание эмбеддингов для каждого чанка (BGE-M3 модель, 1024-мерные векторы)
2. Индексация в Qdrant (векторный поиск)
3. Индексация в PostgreSQL (BM25/keyword поиск)
```

### 1.10 Индексация в Qdrant (index_to_qdrant)
```
1. Проверка существования коллекции normative_documents
2. Создание коллекции если не существует (1024-мерные векторы, COSINE расстояние)
3. Создание PointStruct объектов
4. Upsert точек в коллекцию
```

### 1.11 Индексация в PostgreSQL (index_to_postgres)
```
1. Создание таблицы normative_chunks если не существует
2. Создание индексов (document_id, clause_id, chunk_type, content)
3. Вставка чанков с метаданными
4. Коммит транзакции
```

## 2. Маршрут загрузки "Проверяемого документа" (страница "Нормоконтроль")

### 2.1 Фронтенд (CheckableDocuments.js)
```
Пользователь выбирает файл → Нажимает "Загрузить" → 
POST /api/upload/checkable (с FormData: file)
```

### 2.2 Gateway (app.py)
```
POST /api/upload/checkable → Проксирование на document-parser:8080/upload/checkable
```

### 2.3 Document Parser (main.py) - upload_checkable_document endpoint
```
1. Получение файла
2. Проверка типа файла (PDF, DOCX, DWG, IFC, TXT)
3. Вычисление хеша файла
4. Проверка на дубликаты в БД
5. Парсинг документа (PDF/DOCX/DWG/IFC/TXT)
6. Определение категории документа
7. Вызов parser.save_checkable_document()
8. Автоматический запуск проверки нормоконтроля
```

### 2.4 Сохранение проверяемого документа (save_checkable_document)
```
1. Создание записи в checkable_documents
2. Сохранение извлеченных элементов в checkable_elements
3. Возврат document_id
```

### 2.5 Автоматическая проверка нормоконтроля (perform_norm_control_check)
```
1. Разбиение документа на страницы
2. Для каждой страницы:
   - Вызов perform_norm_control_check_for_page()
3. Сохранение общего результата
```

### 2.6 Проверка страницы (perform_norm_control_check_for_page)
```
1. Получение промпта из настроек (normcontrol_prompt)
2. Форматирование промпта с контекстом страницы
3. Отправка POST запроса к LLM (http://gateway:8443/v1/chat/completions)
4. Парсинг ответа LLM
5. Извлечение найденных нарушений
6. Сохранение результата в norm_control_results
```

### 2.7 LLM обработка (VLLM Adapter → Ollama)
```
1. VLLM Adapter получает запрос
2. Форматирование для Ollama API
3. Отправка к Ollama (llama3.1:8b модель)
4. Получение ответа
5. Форматирование ответа в OpenAI-совместимый формат
6. Возврат результата
```

## 3. Компоненты системы

### 3.1 Базы данных
- **PostgreSQL (norms_db)**:
  - `uploaded_documents` - нормативные документы
  - `checkable_documents` - проверяемые документы
  - `extracted_elements` - элементы нормативных документов
  - `checkable_elements` - элементы проверяемых документов
  - `norm_control_results` - результаты проверки нормоконтроля
  - `review_reports` - отчеты по проверке
  - `normative_chunks` - чанки для поиска (RAG)
  - `system_settings` - настройки системы

- **Qdrant**:
  - `normative_documents` - векторная коллекция для семантического поиска

### 3.2 Сервисы
- **Document Parser** - парсинг документов, управление настройками
- **RAG Service** - чанкинг, эмбеддинги, индексация, поиск
- **Rule Engine** - логика нормоконтроля
- **Gateway** - маршрутизация API запросов
- **VLLM Adapter** - адаптер для Ollama
- **Ollama** - локальная LLM модель

### 3.3 Модели
- **BGE-M3** - модель для создания эмбеддингов (1024-мерные векторы)
- **llama3.1:8b** - модель для анализа и генерации текста

## 4. Потоки данных

### 4.1 Нормативный документ
```
Файл → Document Parser → PostgreSQL (metadata) → RAG Service → 
Чанкинг → Эмбеддинги → Qdrant + PostgreSQL (chunks) → Готов к поиску
```

### 4.2 Проверяемый документ
```
Файл → Document Parser → PostgreSQL (metadata + content) → 
Автоматическая проверка → LLM → Результаты → PostgreSQL (results)
```

### 4.3 Поиск по нормативным документам
```
Запрос → RAG Service → Векторный поиск (Qdrant) + BM25 (PostgreSQL) → 
Объединение результатов → Фильтрация → Результаты
```

## 5. Ключевые особенности

### 5.1 Асинхронная обработка
- Нормативные документы обрабатываются в фоновом режиме
- Проверяемые документы обрабатываются синхронно с автоматической проверкой

### 5.2 Гибридный поиск
- Векторный поиск (семантический) + BM25 (ключевые слова)
- Взвешенное объединение результатов

### 5.3 Автоматическая проверка
- Проверяемые документы автоматически проходят нормоконтроль
- Постраничный анализ с использованием LLM

### 5.4 Масштабируемость
- Чанкинг документов для эффективного поиска
- Векторная индексация для быстрого семантического поиска
- Разделение метаданных и контента
