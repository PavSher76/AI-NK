# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ AI-NK

## üèóÔ∏è –û–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ    ‚îÇ   Gateway       ‚îÇ    ‚îÇ   Services      ‚îÇ    ‚îÇ   Databases     ‚îÇ
‚îÇ   (React)       ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   (API Router)  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   (Microservices)‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   (Storage)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ                       ‚îÇ                       ‚îÇ
        ‚îÇ                       ‚îÇ                       ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº                       ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User Upload   ‚îÇ    ‚îÇ   Auth & Route  ‚îÇ    ‚îÇ   Processing    ‚îÇ    ‚îÇ   PostgreSQL    ‚îÇ
‚îÇ   Interface     ‚îÇ    ‚îÇ   Requests      ‚îÇ    ‚îÇ   Pipeline      ‚îÇ    ‚îÇ   + Qdrant      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîÑ –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞

### 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant G as Gateway
    participant DP as Document Parser
    participant DB as PostgreSQL
    participant Q as Qdrant
    participant RS as RAG Service

    U->>F: –ó–∞–≥—Ä—É–∑–∫–∞ PDF/DOCX —Ñ–∞–π–ª–∞
    F->>G: POST /api/upload (multipart/form-data)
    G->>G: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    G->>DP: –ü—Ä–æ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
    DP->>DP: –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
    DP->>DP: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    DP->>DB: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ uploaded_documents
    DP->>DP: –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    DP->>DB: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    DP->>RS: –ó–∞–ø—Ä–æ—Å –Ω–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é
    RS->>RS: –ß–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    RS->>RS: –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (BGE-M3)
    RS->>Q: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤
    RS->>DB: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
    RS->>DP: –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    DP->>G: –û—Ç–≤–µ—Ç –æ–± —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
    G->>F: –î–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    F->>U: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
```

### 2. –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ö–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏

```mermaid
graph TD
    A[–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞] --> B{–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞}
    B -->|PDF| C[PDF Parser]
    B -->|DOCX| D[DOCX Parser]
    B -->|–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π| E[–û—à–∏–±–∫–∞]
    
    C --> F[–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞]
    D --> F
    F --> G[–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö]
    G --> H[–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞]
    H --> I[–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤]
    I --> J[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ uploaded_documents]
    J --> K[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ extracted_elements]
    K --> L[–ß–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞]
    L --> M[–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤]
    M --> N[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant]
    N --> O[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤]
    O --> P[–ì–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é]
```

## üè¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ä–≤–∏—Å–æ–≤

### 1. –°–µ—Ä–≤–∏—Å—ã –∏ –∏—Ö —Ä–æ–ª–∏

| –°–µ—Ä–≤–∏—Å | –ü–æ—Ä—Ç | –†–æ–ª—å | –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ |
|--------|------|------|------------------|
| **Frontend** | 443 | –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å | –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ |
| **Gateway** | 8443 | API Gateway | –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è, –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è, –ø—Ä–æ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ |
| **Document Parser** | 8001 | –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ | –ü–∞—Ä—Å–∏–Ω–≥, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, —á–∞–Ω–∫–∏–Ω–≥ |
| **RAG Service** | 8003 | –ü–æ–∏—Å–∫ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è | –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫, —ç–º–±–µ–¥–¥–∏–Ω–≥–∏, –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ |
| **Rule Engine** | 8002 | –ü—Ä–æ–≤–µ—Ä–∫–∏ | –ù–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å, –≤–∞–ª–∏–¥–∞—Ü–∏—è |
| **Calculation Service** | 8004 | –†–∞—Å—á–µ—Ç—ã | –ò–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã |
| **VLLM** | 8000 | LLM API | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤, –∞–Ω–∞–ª–∏–∑ |
| **Ollama** | 11434 | LLM Backend | –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ |
| **PostgreSQL** | 5432 | –†–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –ë–î | –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã |
| **Qdrant** | 6333 | –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î | –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ |
| **Redis** | 6379 | –ö—ç—à | –°–µ—Å—Å–∏–∏, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ |
| **Keycloak** | 8081 | –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è | –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ |

### 2. –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å–µ—Ä–≤–∏—Å–æ–≤

```mermaid
graph TB
    subgraph "Frontend Layer"
        F[Frontend - React]
    end
    
    subgraph "Gateway Layer"
        G[Gateway - API Router]
    end
    
    subgraph "Processing Layer"
        DP[Document Parser]
        RS[RAG Service]
        RE[Rule Engine]
        CS[Calculation Service]
    end
    
    subgraph "LLM Layer"
        VLLM[VLLM Adapter]
        OLL[Ollama]
    end
    
    subgraph "Storage Layer"
        PG[PostgreSQL]
        QD[Qdrant]
        RD[Redis]
    end
    
    subgraph "Auth Layer"
        KC[Keycloak]
    end
    
    F <--> G
    G <--> DP
    G <--> RS
    G <--> RE
    G <--> CS
    G <--> VLLM
    
    DP <--> PG
    DP <--> QD
    RS <--> PG
    RS <--> QD
    RS <--> RD
    RE <--> PG
    RE <--> QD
    CS <--> PG
    
    VLLM <--> OLL
    G <--> KC
    G <--> RD
```

## üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

### 1. –¢–∞–±–ª–∏—Ü—ã PostgreSQL

#### `uploaded_documents` - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
```sql
CREATE TABLE uploaded_documents (
    id SERIAL PRIMARY KEY,
    original_filename VARCHAR(255) NOT NULL,
    filename VARCHAR(255) NOT NULL,
    file_type VARCHAR(20) NOT NULL,
    file_size BIGINT NOT NULL,
    upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processing_status VARCHAR(50) DEFAULT 'pending',
    processing_error TEXT,
    document_hash VARCHAR(64) UNIQUE,
    category VARCHAR(50) DEFAULT 'other',
    document_type VARCHAR(50) DEFAULT 'normative',
    token_count INTEGER DEFAULT 0,
    file_path VARCHAR(500)
);
```

#### `extracted_elements` - –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
```sql
CREATE TABLE extracted_elements (
    id SERIAL PRIMARY KEY,
    uploaded_document_id INTEGER REFERENCES uploaded_documents(id),
    element_type VARCHAR(50) NOT NULL,
    content TEXT NOT NULL,
    page_number INTEGER,
    section VARCHAR(255),
    element_order INTEGER,
    metadata JSONB
);
```

#### `normative_chunks` - –ß–∞–Ω–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
```sql
CREATE TABLE normative_chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES uploaded_documents(id),
    chunk_id VARCHAR(255) UNIQUE NOT NULL,
    chunk_type VARCHAR(50) NOT NULL,
    content TEXT NOT NULL,
    page_number INTEGER,
    chapter VARCHAR(255),
    section VARCHAR(255),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### `norm_control_results` - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è
```sql
CREATE TABLE norm_control_results (
    id SERIAL PRIMARY KEY,
    uploaded_document_id INTEGER REFERENCES uploaded_documents(id),
    check_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status VARCHAR(50),
    findings JSONB,
    report_path VARCHAR(500),
    processing_time INTEGER
);
```

### 2. –ö–æ–ª–ª–µ–∫—Ü–∏–∏ Qdrant

#### `normative_documents` - –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
```python
# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–æ—á–∫–∏ –≤ Qdrant
{
    "id": "chunk_id_hash",  # –ß–∏—Å–ª–æ–≤–æ–π ID
    "vector": [0.1, 0.2, ...],  # 1024-–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä BGE-M3
    "payload": {
        "document_id": 123,
        "code": "–ì–û–°–¢ 21.201-2011",
        "title": "–ü–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
        "section_title": "–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∞–∑–¥–µ–ª–∞",
        "content": "–¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞",
        "chunk_type": "paragraph",
        "page": 1,
        "section": "–û–±–ª–∞—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è",
        "metadata": {
            "document_id": 123,
            "chunk_index": 1,
            "length": 150
        }
    }
}
```

## üîß –ü—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

### 1. Document Parser - –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫

```python
# document_parser/services/document_processing.py
class DocumentProcessor:
    def __init__(self):
        self.pdf_parser = PDFParser()
        self.docx_parser = DOCXParser()
        self.chunker = DocumentChunker()
    
    async def process_document(self, file_path: str, file_type: str) -> Dict:
        """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            # 1. –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            if file_type == 'pdf':
                content = await self.pdf_parser.parse(file_path)
            elif file_type == 'docx':
                content = await self.docx_parser.parse(file_path)
            else:
                raise ValueError(f"Unsupported file type: {file_type}")
            
            # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata = self.extract_metadata(file_path, content)
            
            # 3. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            structured_content = self.structure_content(content)
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            document_id = await self.save_to_database(metadata, structured_content)
            
            # 5. –ß–∞–Ω–∫–∏–Ω–≥ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
            await self.index_document(document_id, structured_content)
            
            return {"status": "success", "document_id": document_id}
            
        except Exception as e:
            logger.error(f"Document processing error: {e}")
            return {"status": "error", "error": str(e)}
    
    def structure_content(self, content: str) -> List[Dict]:
        """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        sections = []
        
        # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–¥–µ–ª—ã
        for section in self.extract_sections(content):
            elements = self.extract_elements(section)
            sections.append({
                "title": section.title,
                "elements": elements
            })
        
        return sections
    
    async def index_document(self, document_id: int, content: List[Dict]):
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ RAG —Å–∏—Å—Ç–µ–º—É"""
        # –°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤
        chunks = self.chunker.create_chunks(content, document_id)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –≤ –±–∞–∑—É
        await self.save_chunks(document_id, chunks)
        
        # –ó–∞–ø—Ä–æ—Å –Ω–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –≤ RAG —Å–µ—Ä–≤–∏—Å
        await self.rag_service.index_document(document_id, chunks)
```

### 2. RAG Service - –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫

```python
# rag_service/services/rag_service.py
class RAGService:
    def __init__(self):
        self.embedding_model = SentenceTransformer('BAAI/bge-m3')
        self.qdrant_client = QdrantClient("http://qdrant:6333")
        self.db_manager = DatabaseManager()
    
    def index_document_chunks(self, document_id: int, chunks: List[Dict]) -> bool:
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —á–∞–Ω–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Qdrant"""
        try:
            points = []
            
            for chunk in chunks:
                # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
                embedding = self.embedding_model.encode(chunk['content'])
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID –¥–ª—è Qdrant
                qdrant_id = hash(f"{document_id}_{chunk['chunk_id']}") % (2**63 - 1)
                
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ—á–∫–∏
                point = {
                    'id': qdrant_id,
                    'vector': embedding.tolist(),
                    'payload': {
                        'document_id': document_id,
                        'code': self.extract_document_code(chunk.get('document_title', '')),
                        'title': chunk.get('document_title', ''),
                        'section_title': chunk.get('section_title', ''),
                        'content': chunk.get('content', ''),
                        'chunk_type': chunk.get('chunk_type', 'paragraph'),
                        'page': chunk.get('page', 1),
                        'section': chunk.get('section', ''),
                        'metadata': chunk.get('metadata', {})
                    }
                }
                points.append(point)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant
            if points:
                self.qdrant_client.upsert(
                    collection_name="normative_documents",
                    points=points
                )
                
                logger.info(f"‚úÖ Indexed {len(points)} chunks for document {document_id}")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è No valid chunks to index for document {document_id}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Indexing error: {e}")
            return False
    
    def hybrid_search(self, query: str, k: int = 8) -> List[Dict]:
        """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
        try:
            # –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
            query_embedding = self.embedding_model.encode(query)
            vector_results = self.qdrant_client.search(
                collection_name="normative_documents",
                query_vector=query_embedding.tolist(),
                limit=k * 2
            )
            
            # BM25 –ø–æ–∏—Å–∫ (–µ—Å–ª–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω)
            bm25_results = []
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            combined_results = self.combine_search_results(
                vector_results, bm25_results, k
            )
            
            return combined_results
            
        except Exception as e:
            logger.error(f"‚ùå Search error: {e}")
            return []
```

## üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥—É–ª—è—Ö

### 1. –ù–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

```mermaid
graph TD
    A[–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞] --> B[–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞]
    B --> C[–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤]
    C --> D[–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞]
    D --> E[LLM –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ VLLM]
    E --> F[–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞]
    F --> G[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
    G --> H[–í–æ–∑–≤—Ä–∞—Ç –æ—Ç—á–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é]
```

### 2. –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ù–¢–î

```mermaid
graph TD
    A[–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è] --> B[–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤–æ–ø—Ä–æ—Å–∞]
    B --> C[–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ Qdrant]
    C --> D[–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤]
    D --> E[–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞]
    E --> F[LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞]
    F --> G[–í–æ–∑–≤—Ä–∞—Ç –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é]
```

### 3. –ò–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã

```mermaid
graph TD
    A[–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[–ü–æ–∏—Å–∫ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π]
    B --> C[–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤]
    C --> D[–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–æ—Ä–º–∞–º]
    D --> E[–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞]
    E --> F[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏

### 1. Prometheus –º–µ—Ç—Ä–∏–∫–∏

```python
# –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
document_uploads_total = Counter('document_uploads_total', 'Total document uploads', ['file_type', 'status'])
document_processing_duration = Histogram('document_processing_duration_seconds', 'Document processing time')
chunks_created_total = Counter('chunks_created_total', 'Total chunks created', ['document_id'])
embeddings_created_total = Counter('embeddings_created_total', 'Total embeddings created')
search_requests_total = Counter('search_requests_total', 'Total search requests', ['service'])
search_duration = Histogram('search_duration_seconds', 'Search response time')
```

### 2. Health Checks

```python
# Health check –¥–ª—è –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
@app.get("/health/normative-documents")
async def health_normative_documents():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ PostgreSQL
        with db_connection.cursor() as cursor:
            cursor.execute("SELECT COUNT(*) FROM uploaded_documents")
            doc_count = cursor.fetchone()[0]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ Qdrant
        collection_info = qdrant_client.get_collection("normative_documents")
        vector_count = collection_info.points_count
        
        return {
            "status": "healthy",
            "documents": {
                "postgresql_count": doc_count,
                "qdrant_count": vector_count,
                "sync_status": "ok" if doc_count > 0 and vector_count > 0 else "warning"
            }
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }
```

## üîÑ –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º–æ–π

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant G as Gateway
    participant DP as Document Parser
    participant RS as RAG Service
    participant DB as PostgreSQL
    participant Q as Qdrant
    participant V as VLLM

    Note over U,V: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    U->>F: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    F->>G: POST /api/upload
    G->>DP: –ü—Ä–æ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
    DP->>DP: –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    DP->>DB: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    DP->>DB: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    DP->>RS: –ó–∞–ø—Ä–æ—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    RS->>RS: –ß–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    RS->>RS: –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    RS->>Q: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤
    RS->>DB: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤
    RS->>DP: –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    DP->>G: –£—Å–ø–µ—à–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
    G->>F: –î–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤
    F->>U: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ

    Note over U,V: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–µ
    U->>F: –ó–∞–ø—É—Å–∫ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è
    F->>G: POST /api/checkable-documents/{id}/check
    G->>DP: –ó–∞–ø—Ä–æ—Å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è
    DP->>RS: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    RS->>Q: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
    RS->>DP: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
    DP->>V: LLM –∞–Ω–∞–ª–∏–∑
    V->>DP: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    DP->>DB: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    DP->>G: –û—Ç—á–µ—Ç –æ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–µ
    G->>F: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏
    F->>U: –û—Ç—á–µ—Ç –≥–æ—Ç–æ–≤

    Note over U,V: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è—Ö
    U->>F: –í–æ–ø—Ä–æ—Å –æ –ù–¢–î
    F->>G: POST /api/ntd-consultation/chat
    G->>RS: –ó–∞–ø—Ä–æ—Å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏
    RS->>Q: –ü–æ–∏—Å–∫ –ø–æ –≤–æ–ø—Ä–æ—Å—É
    RS->>V: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    V->>RS: –û—Ç–≤–µ—Ç –ò–ò
    RS->>G: –û—Ç–≤–µ—Ç –Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é
    G->>F: –û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    F->>U: –û—Ç–≤–µ—Ç –≥–æ—Ç–æ–≤
```

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –æ—Ç—á–µ—Ç—ã

### 1. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

```sql
-- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º
SELECT file_type, COUNT(*) as count 
FROM uploaded_documents 
GROUP BY file_type;

-- –†–∞–∑–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
SELECT 
    AVG(file_size) as avg_size,
    MAX(file_size) as max_size,
    MIN(file_size) as min_size
FROM uploaded_documents;

-- –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏
SELECT 
    DATE(upload_date) as date,
    COUNT(*) as uploads
FROM uploaded_documents 
GROUP BY DATE(upload_date)
ORDER BY date DESC;
```

### 2. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```sql
-- –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –ø–æ–∏—Å–∫–µ
SELECT 
    nc.document_id,
    ud.original_filename,
    COUNT(*) as search_count
FROM normative_chunks nc
JOIN uploaded_documents ud ON nc.document_id = ud.id
GROUP BY nc.document_id, ud.original_filename
ORDER BY search_count DESC;
```

## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–î–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:

1. **–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏** - –æ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
2. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
3. **–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å** - —Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
4. **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
5. **–ì–∏–±–∫–æ—Å—Ç—å** - –º–æ–¥—É–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

–°–∏—Å—Ç–µ–º–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é —Ä–∞–±–æ—Ç—É —Å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ò–ò.
