"""
–ú–æ–¥—É–ª—å –¥–ª—è OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º —Ç–∞–±–ª–∏—Ü –∏ —á–µ—Ä—Ç–µ–∂–µ–π
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç pytesseract, opencv –∏ pdf2image –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
"""

import logging
import os
import tempfile
import cv2
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import json

# OCR –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
try:
    import pytesseract
    from PIL import Image, ImageEnhance, ImageFilter
    import pdf2image
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False

logger = logging.getLogger(__name__)


class OCRProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, 
                 tesseract_path: Optional[str] = None,
                 languages: List[str] = None,
                 dpi: int = 300):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OCR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        
        Args:
            tesseract_path: –ü—É—Ç—å –∫ tesseract (–µ—Å–ª–∏ –Ω–µ –≤ PATH)
            languages: –Ø–∑—ã–∫–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: rus+eng)
            dpi: DPI –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        if not OCR_AVAILABLE:
            raise ImportError("OCR –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pytesseract pillow pdf2image opencv-python")
        
        self.languages = languages or ["rus", "eng"]
        self.dpi = dpi
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ tesseract
        if tesseract_path:
            pytesseract.pytesseract.tesseract_cmd = tesseract_path
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è tesseract –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        self.tesseract_config = {
            'table': '--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è.,:;()[]{}"\\/-+=*%‚Ññ',
            'text': '--oem 3 --psm 6',
            'drawing': '--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è.,:;()[]{}"\\/-+=*%‚Ññ¬∞√òR'
        }
    
    def process_pdf_with_ocr(self, pdf_path: str) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF —Å OCR –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü –∏ —á–µ—Ä—Ç–µ–∂–µ–π
        
        Args:
            pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            logger.info(f"üîç [OCR] –ù–∞—á–∏–Ω–∞–µ–º OCR –æ–±—Ä–∞–±–æ—Ç–∫—É PDF: {pdf_path}")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            images = self._pdf_to_images(pdf_path)
            
            result = {
                'success': True,
                'pages': [],
                'tables': [],
                'drawings': [],
                'total_pages': len(images),
                'processing_time': 0
            }
            
            import time
            start_time = time.time()
            
            for page_num, image in enumerate(images, 1):
                logger.info(f"üîç [OCR] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}/{len(images)}")
                
                page_result = self._process_page_with_ocr(image, page_num)
                result['pages'].append(page_result)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –∏ —á–µ—Ä—Ç–µ–∂–∏
                if page_result.get('tables'):
                    result['tables'].extend(page_result['tables'])
                if page_result.get('drawings'):
                    result['drawings'].extend(page_result['drawings'])
            
            result['processing_time'] = time.time() - start_time
            logger.info(f"‚úÖ [OCR] OCR –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {result['processing_time']:.2f} —Å–µ–∫")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return {
                'success': False,
                'error': str(e),
                'pages': [],
                'tables': [],
                'drawings': []
            }
    
    def _pdf_to_images(self, pdf_path: str) -> List[Image.Image]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –≤—ã—Å–æ–∫–∏–º DPI
            images = pdf2image.convert_from_path(
                pdf_path,
                dpi=self.dpi,
                fmt='RGB',
                thread_count=2
            )
            
            logger.info(f"üìÑ [OCR] PDF –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            return images
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF: {e}")
            return []
    
    def _process_page_with_ocr(self, image: Image.Image, page_num: int) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å OCR"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL Image –≤ OpenCV —Ñ–æ—Ä–º–∞—Ç
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            processed_image = self._preprocess_image(cv_image)
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            text_result = self._extract_text_with_ocr(processed_image)
            
            # –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü
            tables = self._detect_and_extract_tables(cv_image, processed_image, page_num)
            
            # –ü–æ–∏—Å–∫ —á–µ—Ä—Ç–µ–∂–µ–π
            drawings = self._detect_and_extract_drawings(cv_image, processed_image, page_num)
            
            return {
                'page_number': page_num,
                'text': text_result['text'],
                'confidence': text_result['confidence'],
                'tables': tables,
                'drawings': drawings,
                'processing_success': True
            }
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
            return {
                'page_number': page_num,
                'text': '',
                'confidence': 0.0,
                'tables': [],
                'drawings': [],
                'processing_success': False,
                'error': str(e)
            }
    
    def _preprocess_image(self, cv_image: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ OCR"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # –£–±–∏—Ä–∞–µ–º —à—É–º
            denoised = cv2.medianBlur(enhanced, 3)
            
            # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
            _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            kernel = np.ones((1,1), np.uint8)
            processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            
            return processed
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return cv_image
    
    def _extract_text_with_ocr(self, image: np.ndarray) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OCR"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ PIL Image
            pil_image = Image.fromarray(image)
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            text = pytesseract.image_to_string(
                pil_image,
                lang='+'.join(self.languages),
                config=self.tesseract_config['text']
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            data = pytesseract.image_to_data(
                pil_image,
                lang='+'.join(self.languages),
                config=self.tesseract_config['text'],
                output_type=pytesseract.Output.DICT
            )
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            
            return {
                'text': text.strip(),
                'confidence': avg_confidence / 100.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ 0-1
            }
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
            return {'text': '', 'confidence': 0.0}
    
    def _detect_and_extract_tables(self, original_image: np.ndarray, processed_image: np.ndarray, page_num: int) -> List[Dict[str, Any]]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü"""
        try:
            tables = []
            
            # –ü–æ–∏—Å–∫ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –∏ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
            
            # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
            horizontal_lines = cv2.morphologyEx(processed_image, cv2.MORPH_OPEN, horizontal_kernel)
            
            # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
            vertical_lines = cv2.morphologyEx(processed_image, cv2.MORPH_OPEN, vertical_kernel)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª–∏–Ω–∏–∏
            table_mask = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0.0)
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü
            contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for i, contour in enumerate(contours):
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
                area = cv2.contourArea(contour)
                if area < 1000:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Ç–∞–±–ª–∏—Ü—ã
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
                x, y, w, h = cv2.boundingRect(contour)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–ª–∞—Å—Ç—å —Ç–∞–±–ª–∏—Ü—ã
                table_roi = original_image[y:y+h, x:x+w]
                
                # OCR –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
                table_text = self._extract_table_text(table_roi)
                
                if table_text and len(table_text.strip()) > 10:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
                    tables.append({
                        'table_number': i + 1,
                        'page_number': page_num,
                        'bbox': [x, y, x+w, y+h],
                        'text': table_text,
                        'area': area,
                        'confidence': 0.8  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
                    })
            
            logger.info(f"üìä [OCR] –ù–∞–π–¥–µ–Ω–æ {len(tables)} —Ç–∞–±–ª–∏—Ü –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
            return tables
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {e}")
            return []
    
    def _extract_table_text(self, table_image: np.ndarray) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –æ–±–ª–∞—Å—Ç–∏ —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
            processed = self._preprocess_image(table_image)
            
            # OCR —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –¥–ª—è —Ç–∞–±–ª–∏—Ü
            pil_image = Image.fromarray(processed)
            text = pytesseract.image_to_string(
                pil_image,
                lang='+'.join(self.languages),
                config=self.tesseract_config['table']
            )
            
            return text.strip()
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return ""
    
    def _detect_and_extract_drawings(self, original_image: np.ndarray, processed_image: np.ndarray, page_num: int) -> List[Dict[str, Any]]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–µ—Ä—Ç–µ–∂–µ–π"""
        try:
            drawings = []
            
            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤ (—á–µ—Ä—Ç–µ–∂–∏ –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç —á–µ—Ç–∫–∏–µ –∫–æ–Ω—Ç—É—Ä—ã)
            contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏ —Ñ–æ—Ä–º–µ (—á–µ—Ä—Ç–µ–∂–∏ –æ–±—ã—á–Ω–æ –±–æ–ª—å—à–∏–µ –∏ —Å–ª–æ–∂–Ω—ã–µ)
                if area < 5000:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å —á–µ—Ä—Ç–µ–∂–∞
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç—É—Ä–∞ (—á–µ—Ä—Ç–µ–∂–∏ –∏–º–µ—é—Ç –º–Ω–æ–≥–æ —Ç–æ—á–µ–∫)
                if len(contour) < 50:
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
                x, y, w, h = cv2.boundingRect(contour)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω (—á–µ—Ä—Ç–µ–∂–∏ –æ–±—ã—á–Ω–æ –Ω–µ –æ—á–µ–Ω—å –≤—ã—Ç—è–Ω—É—Ç—ã–µ)
                aspect_ratio = w / h
                if aspect_ratio < 0.3 or aspect_ratio > 3.0:
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–ª–∞—Å—Ç—å —á–µ—Ä—Ç–µ–∂–∞
                drawing_roi = original_image[y:y+h, x:x+w]
                
                # OCR –¥–ª—è —á–µ—Ä—Ç–µ–∂–∞ (–ø–æ–∏—Å–∫ —Ä–∞–∑–º–µ—Ä–æ–≤, –º–∞—Ä–∫–∏—Ä–æ–≤–æ–∫ –∏ —Ç.–¥.)
                drawing_text = self._extract_drawing_text(drawing_roi)
                
                drawings.append({
                    'drawing_number': i + 1,
                    'page_number': page_num,
                    'bbox': [x, y, x+w, y+h],
                    'text': drawing_text,
                    'area': area,
                    'aspect_ratio': aspect_ratio,
                    'contour_points': len(contour),
                    'confidence': 0.7  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —á–µ—Ä—Ç–µ–∂–µ–π
                })
            
            logger.info(f"üìê [OCR] –ù–∞–π–¥–µ–Ω–æ {len(drawings)} —á–µ—Ä—Ç–µ–∂–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
            return drawings
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —á–µ—Ä—Ç–µ–∂–µ–π: {e}")
            return []
    
    def _extract_drawing_text(self, drawing_image: np.ndarray) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –æ–±–ª–∞—Å—Ç–∏ —á–µ—Ä—Ç–µ–∂–∞"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —á–µ—Ä—Ç–µ–∂–∞
            processed = self._preprocess_image(drawing_image)
            
            # OCR —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –¥–ª—è —á–µ—Ä—Ç–µ–∂–µ–π
            pil_image = Image.fromarray(processed)
            text = pytesseract.image_to_string(
                pil_image,
                lang='+'.join(self.languages),
                config=self.tesseract_config['drawing']
            )
            
            return text.strip()
            
        except Exception as e:
            logger.error(f"‚ùå [OCR] –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä—Ç–µ–∂–∞: {e}")
            return ""


class AdvancedTableExtractor:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ç–∞–±–ª–∏—Ü —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è"""
    
    def __init__(self):
        self.min_table_area = 1000
        self.min_cell_area = 100
    
    def extract_tables_from_image(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
            # –ü–æ–∏—Å–∫ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
            horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)
            
            # –ü–æ–∏—Å–∫ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))
            vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª–∏–Ω–∏–∏
            table_mask = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0.0)
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã
            contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            tables = []
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                if area > self.min_table_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —è—á–µ–π–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
                    cells = self._extract_table_cells(image[y:y+h, x:x+w])
                    
                    tables.append({
                        'table_id': i + 1,
                        'bbox': [x, y, x+w, y+h],
                        'area': area,
                        'cells': cells,
                        'rows': len(cells),
                        'columns': len(cells[0]) if cells else 0
                    })
            
            return tables
            
        except Exception as e:
            logger.error(f"‚ùå [TABLE_EXTRACTOR] –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {e}")
            return []
    
    def _extract_table_cells(self, table_roi: np.ndarray) -> List[List[str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —è—á–µ–µ–∫ —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
            gray = cv2.cvtColor(table_roi, cv2.COLOR_BGR2GRAY)
            
            # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
            # –ü–æ–∏—Å–∫ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –∏ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))
            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 15))
            
            horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)
            vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –ª–∏–Ω–∏–π
            intersections = cv2.bitwise_and(horizontal_lines, vertical_lines)
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã —è—á–µ–µ–∫
            contours, _ = cv2.findContours(intersections, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            cells = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > self.min_cell_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    cell_roi = table_roi[y:y+h, x:x+w]
                    
                    # OCR –¥–ª—è —è—á–µ–π–∫–∏
                    cell_text = self._extract_cell_text(cell_roi)
                    cells.append(cell_text)
            
            # –û—Ä–≥–∞–Ω–∏–∑—É–µ–º —è—á–µ–π–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç–æ–ª–±—Ü—ã
            return self._organize_cells_into_table(cells, table_roi.shape)
            
        except Exception as e:
            logger.error(f"‚ùå [TABLE_EXTRACTOR] –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —è—á–µ–µ–∫: {e}")
            return []
    
    def _extract_cell_text(self, cell_image: np.ndarray) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —è—á–µ–π–∫–∏ —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            if not OCR_AVAILABLE:
                return ""
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            gray = cv2.cvtColor(cell_image, cv2.COLOR_BGR2GRAY)
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # OCR
            pil_image = Image.fromarray(binary)
            text = pytesseract.image_to_string(
                pil_image,
                lang='rus+eng',
                config='--oem 3 --psm 8'
            )
            
            return text.strip()
            
        except Exception as e:
            logger.error(f"‚ùå [TABLE_EXTRACTOR] –û—à–∏–±–∫–∞ OCR —è—á–µ–π–∫–∏: {e}")
            return ""
    
    def _organize_cells_into_table(self, cells: List[str], image_shape: Tuple[int, int, int]) -> List[List[str]]:
        """–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —è—á–µ–µ–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–µ–Ω –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
        # –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ –∏ —Å—Ç–æ–ª–±—Ü–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∑–∏—Ü–∏–π —è—á–µ–µ–∫
        if not cells:
            return []
        
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Ç–∞–±–ª–∏—Ü—É —Å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º
        estimated_rows = max(1, int(len(cells) ** 0.5))
        estimated_cols = max(1, len(cells) // estimated_rows)
        
        table = []
        for i in range(estimated_rows):
            row = []
            for j in range(estimated_cols):
                cell_index = i * estimated_cols + j
                if cell_index < len(cells):
                    row.append(cells[cell_index])
                else:
                    row.append("")
            table.append(row)
        
        return table
