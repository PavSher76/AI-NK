"""
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è —Å —É–ª—å—Ç–∏–º–∞—Ç–∏–≤–Ω—ã–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª–Ω–æ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª–µ–º
"""

import logging
import os
import json
import time
from typing import Dict, Any, List, Optional
from pathlib import Path
from enhanced_normcontrol_analyzer import EnhancedNormControlAnalyzer

logger = logging.getLogger(__name__)


class IntegratedNormControlSystem:
    """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è"""
    
    def __init__(self):
        self.analyzer = EnhancedNormControlAnalyzer()
        self.results_cache = {}
        self.batch_results = []
    
    def process_document(self, file_path: str) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {file_path}")
            
            # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            result = self.analyzer.analyze_document_for_normcontrol(file_path)
            
            # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if result['success']:
                file_hash = result['document_analysis']['file_hash']
                self.results_cache[file_hash] = result
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file_path}: {e}")
            return {
                'success': False,
                'error': str(e),
                'file_path': file_path
            }
    
    def process_batch(self, file_paths: List[str]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        start_time = time.time()
        batch_results = []
        
        logger.info(f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–∫–µ—Ç–∞ –∏–∑ {len(file_paths)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        for file_path in file_paths:
            result = self.process_document(file_path)
            batch_results.append(result)
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞–∫–µ—Ç–∞
        batch_analysis = self._analyze_batch_results(batch_results)
        
        batch_summary = {
            'success': True,
            'total_documents': len(file_paths),
            'processed_documents': len([r for r in batch_results if r['success']]),
            'failed_documents': len([r for r in batch_results if not r['success']]),
            'processing_time': time.time() - start_time,
            'results': batch_results,
            'batch_analysis': batch_analysis
        }
        
        self.batch_results.append(batch_summary)
        return batch_summary
    
    def _analyze_batch_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        successful_results = [r for r in results if r['success']]
        
        if not successful_results:
            return {
                'total_issues': 0,
                'critical_issues': 0,
                'warning_issues': 0,
                'info_issues': 0,
                'average_compliance': 0.0,
                'status_distribution': {},
                'recommendations': []
            }
        
        # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–æ–±–ª–µ–º
        total_issues = 0
        critical_issues = 0
        warning_issues = 0
        info_issues = 0
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤
        status_distribution = {}
        
        # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        compliance_scores = []
        
        for result in successful_results:
            onk_compliance = result['onk_compliance']
            total_issues += onk_compliance['total_issues']
            critical_issues += onk_compliance['critical_issues']
            warning_issues += onk_compliance['warning_issues']
            info_issues += onk_compliance['info_issues']
            
            status = result['normcontrol_report']['status']
            status_distribution[status] = status_distribution.get(status, 0) + 1
            
            compliance_scores.append(onk_compliance['overall_score'])
        
        average_compliance = sum(compliance_scores) / len(compliance_scores) if compliance_scores else 0.0
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = []
        if critical_issues > 0:
            recommendations.append(f"–£—Å—Ç—Ä–∞–Ω–∏—Ç—å {critical_issues} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Ä—É—à–µ–Ω–∏–π")
        if warning_issues > 0:
            recommendations.append(f"–ò—Å–ø—Ä–∞–≤–∏—Ç—å {warning_issues} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π")
        if average_compliance < 80:
            recommendations.append("–ü–æ–≤—ã—Å–∏—Ç—å –æ–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        return {
            'total_issues': total_issues,
            'critical_issues': critical_issues,
            'warning_issues': warning_issues,
            'info_issues': info_issues,
            'average_compliance': average_compliance,
            'status_distribution': status_distribution,
            'recommendations': recommendations
        }
    
    def generate_batch_report(self, batch_id: int = None) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ –ø–∞–∫–µ—Ç—É"""
        if batch_id is None:
            batch_id = len(self.batch_results) - 1
        
        if batch_id >= len(self.batch_results):
            return {'error': 'Batch not found'}
        
        batch = self.batch_results[batch_id]
        
        report = {
            'batch_id': batch_id,
            'generated_at': time.time(),
            'summary': {
                'total_documents': batch['total_documents'],
                'processed_documents': batch['processed_documents'],
                'failed_documents': batch['failed_documents'],
                'processing_time': batch['processing_time'],
                'success_rate': (batch['processed_documents'] / batch['total_documents']) * 100
            },
            'analysis': batch['batch_analysis'],
            'documents': []
        }
        
        # –î–µ—Ç–∞–ª–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É
        for result in batch['results']:
            if result['success']:
                doc_info = {
                    'file_name': result['normcontrol_report']['document_info']['file_name'],
                    'project_number': result['normcontrol_report']['document_analysis']['project_number'],
                    'mark': result['normcontrol_report']['document_analysis']['mark'],
                    'status': result['normcontrol_report']['status'],
                    'compliance_score': result['onk_compliance']['overall_score'],
                    'total_issues': result['onk_compliance']['total_issues'],
                    'critical_issues': result['onk_compliance']['critical_issues']
                }
                report['documents'].append(doc_info)
        
        return report
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
        total_documents = sum(batch['total_documents'] for batch in self.batch_results)
        processed_documents = sum(batch['processed_documents'] for batch in self.batch_results)
        total_issues = sum(
            batch['batch_analysis']['total_issues'] 
            for batch in self.batch_results
        )
        
        return {
            'total_batches': len(self.batch_results),
            'total_documents': total_documents,
            'processed_documents': processed_documents,
            'success_rate': (processed_documents / total_documents) * 100 if total_documents > 0 else 0,
            'total_issues_found': total_issues,
            'cache_size': len(self.results_cache)
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã"""
    print("üöÄ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ù–û–†–ú–û–ö–û–ù–¢–†–û–õ–Ø")
    print("=" * 80)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
    system = IntegratedNormControlSystem()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    test_documents = [
        "tests/TestDocs/for_check/3401-21089-–†–î-01-220-221-–ê–†_4_0_RU_IFC (1).pdf",
        "tests/TestDocs/Norms/–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ/–ü–µ—Ä–µ—á–µ–Ω—å –ù–¢–î –¥–ª—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –≤–Ω—É—Ç—Ä–∏ –û–ù–ö –ø–æ –º–∞—Ä–∫–∞–º.pdf",
        "tests/TestDocs/Norms/–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ/–ß–µ–∫-–ª–∏—Å—Ç –ø–µ—Ä–µ–¥ –ù–ö –ü–¢–ò.pdf"
    ]
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ –∏–∑ {len(test_documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    batch_result = system.process_batch(test_documents)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò:")
    print(f"  –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {batch_result['total_documents']}")
    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ: {batch_result['processed_documents']}")
    print(f"  –û—à–∏–±–æ–∫: {batch_result['failed_documents']}")
    print(f"  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {batch_result['processing_time']:.2f} —Å–µ–∫")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–∞–∫–µ—Ç–∞
    analysis = batch_result['batch_analysis']
    print(f"\nüìà –ê–ù–ê–õ–ò–ó –ü–ê–ö–ï–¢–ê:")
    print(f"  –í—Å–µ–≥–æ –ø—Ä–æ–±–ª–µ–º: {analysis['total_issues']}")
    print(f"  –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö: {analysis['critical_issues']}")
    print(f"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {analysis['warning_issues']}")
    print(f"  –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö: {analysis['info_issues']}")
    print(f"  –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {analysis['average_compliance']:.1f}%")
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤
    print(f"\nüìã –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–¢–ê–¢–£–°–û–í:")
    for status, count in analysis['status_distribution'].items():
        print(f"  {status}: {count}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if analysis['recommendations']:
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        for i, rec in enumerate(analysis['recommendations'], 1):
            print(f"  {i}. {rec}")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    report = system.generate_batch_report()
    print(f"\nüìã –û–¢–ß–ï–¢ –ü–û –ü–ê–ö–ï–¢–£:")
    print(f"  ID –ø–∞–∫–µ—Ç–∞: {report['batch_id']}")
    print(f"  –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {report['summary']['success_rate']:.1f}%")
    print(f"  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {report['summary']['processing_time']:.2f} —Å–µ–∫")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã
    stats = system.get_statistics()
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´:")
    print(f"  –í—Å–µ–≥–æ –ø–∞–∫–µ—Ç–æ–≤: {stats['total_batches']}")
    print(f"  –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['total_documents']}")
    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed_documents']}")
    print(f"  –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {stats['success_rate']:.1f}%")
    print(f"  –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {stats['total_issues_found']}")
    print(f"  –†–∞–∑–º–µ—Ä –∫—ç—à–∞: {stats['cache_size']}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_file = f"integrated_normcontrol_results_{int(time.time())}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(batch_result, f, ensure_ascii=False, indent=2)
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")


if __name__ == "__main__":
    main()
