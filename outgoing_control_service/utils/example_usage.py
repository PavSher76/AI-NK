#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ –º–æ–¥—É–ª—è utils –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é utils
sys.path.append(os.path.dirname(__file__))

from utils import (
    parse_document,
    parse_document_from_bytes,
    UniversalDocumentParser,
    PDFTextExtractor,
    DOCXTextExtractor,
    TextProcessor
)


def example_basic_usage():
    """–ü—Ä–∏–º–µ—Ä –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    print("=== –ü—Ä–∏–º–µ—Ä –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ===")
    
    # –ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –ø—É—Ç—å)
    test_file = "test_document.pdf"
    
    if not os.path.exists(test_file):
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª {test_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    result = parse_document(test_file)
    
    if result["success"]:
        print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
        print(f"üìÑ –ú–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {result['method']}")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {result['total_pages']}")
        print(f"üìù –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {len(result['text'])} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üî§ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {len(result['text'].split())}")
        print(f"üì¶ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤: {len(result.get('chunks', []))}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞
        print(f"\nüìñ –ù–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞:\n{result['text'][:200]}...")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {result['error']}")


def example_advanced_usage():
    """–ü—Ä–∏–º–µ—Ä –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    print("\n=== –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ===")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    parser = UniversalDocumentParser(
        prefer_pdfminer=True,      # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pdfminer –¥–ª—è PDF
        extract_tables=True,       # –ò–∑–≤–ª–µ–∫–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã –∏–∑ DOCX
        extract_headers=True,      # –ò–∑–≤–ª–µ–∫–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
        create_hierarchical_chunks=True  # –°–æ–∑–¥–∞–≤–∞—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏
    )
    
    test_file = "test_document.docx"
    
    if not os.path.exists(test_file):
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª {test_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    result = parser.parse_document(test_file)
    
    if result["success"]:
        print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
        print(f"üìÑ –ú–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {result['method']}")
        print(f"üìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {result['metadata']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞—Ö (–¥–ª—è DOCX)
        if "paragraphs" in result:
            print(f"üìù –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {len(result['paragraphs'])}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
            for i, para in enumerate(result["paragraphs"][:3], 1):
                print(f"  {i}. {para['text'][:100]}...")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∞–±–ª–∏—Ü–∞—Ö (–¥–ª—è DOCX)
        if "tables" in result:
            print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–±–ª–∏—Ü: {len(result['tables'])}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö (–¥–ª—è DOCX)
        if "headers" in result:
            print(f"üìã –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: {len(result['headers'])}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            for i, header in enumerate(result["headers"][:5], 1):
                print(f"  {i}. {header['text']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞–Ω–∫–∞—Ö
        if "chunks" in result:
            print(f"üì¶ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤: {len(result['chunks'])}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —á–∞–Ω–∫–∞ —Å –∏–µ—Ä–∞—Ä—Ö–∏–µ–π
            for i, chunk in enumerate(result["chunks"][:3], 1):
                hierarchy = chunk.get("hierarchy", {})
                print(f"  {i}. –ß–∞–Ω–∫ {chunk['chunk_id']}:")
                print(f"     –†–∞–∑–¥–µ–ª: {hierarchy.get('section_title', 'N/A')}")
                print(f"     –ê–±–∑–∞—Ü: {hierarchy.get('paragraph_number', 'N/A')}")
                print(f"     –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {hierarchy.get('sentence_number', 'N/A')}")
                print(f"     –¢–µ–∫—Å—Ç: {chunk['text'][:100]}...")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {result['error']}")


def example_text_processing():
    """–ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
    print("\n=== –ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ ===")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Ç–µ–∫—Å—Ç–∞
    processor = TextProcessor()
    
    # –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    messy_text = """
    –≠—Ç–æ   –ø—Ä–∏–º–µ—Ä   —Ç–µ–∫—Å—Ç–∞   —Å   –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏   –ø—Ä–æ–±–µ–ª–∞–º–∏.
    
    –ò   —Ä–∞–∑—Ä—ã–≤–∞–º–∏   —Å–ª–æ–≤   –≤   PDF:   –ø—Ä–æ\s+–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ,
    —Ç—Ä–µ\s+–±–æ–≤–∞–Ω–∏—è–º,   —Å–º–µ–∂–Ω—ã\s+—Ö   –∏   —Ç.–¥.
    
    –¢–∞–∫–∂–µ   –µ—Å—Ç—å   –ª–∏—à–Ω–∏–µ   –ø–µ—Ä–µ–Ω–æ—Å—ã   —Å—Ç—Ä–æ–∫.
    
    
    
    –ò   –Ω–µ–≤–∏–¥–∏–º—ã–µ   —Å–∏–º–≤–æ–ª—ã.
    """
    
    print("üìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:")
    print(repr(messy_text))
    
    # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
    # cleaned_text = processor.clean_text(messy_text)
    
    print("\n‚ú® –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:")
    print(repr(messy_text))  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = processor.get_text_statistics(messy_text)
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # –°–æ–∑–¥–∞–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏
    chunks = processor.hierarchical_chunking(cleaned_text)
    print(f"\nüì¶ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
    
    for i, chunk in enumerate(chunks[:3], 1):
        print(f"  {i}. {chunk.content[:50]}...")


def example_pdf_specific():
    """–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å PDF"""
    print("\n=== –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å PDF ===")
    
    # –°–æ–∑–¥–∞–µ–º PDF —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    pdf_extractor = PDFTextExtractor(prefer_pdfminer=True)
    
    test_file = "test_document.pdf"
    
    if not os.path.exists(test_file):
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª {test_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ PDF
    result = pdf_extractor.extract_text_from_file(test_file)
    
    if result["success"]:
        print(f"‚úÖ PDF —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
        print(f"üìÑ –ú–µ—Ç–æ–¥: {result['method']}")
        print(f"üìä –°—Ç—Ä–∞–Ω–∏—Ü: {result['total_pages']}")
        print(f"üìù –°–∏–º–≤–æ–ª–æ–≤: {result['metadata']['total_chars']}")
        print(f"üî§ –°–ª–æ–≤: {result['metadata']['total_words']}")
        print(f"üìÑ –°—Ä–µ–¥–Ω–µ–µ —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {result['metadata']['avg_chars_per_page']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö
        for page in result["pages"][:3]:  # –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            print(f"\nüìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page['page_number']}:")
            print(f"  –°–∏–º–≤–æ–ª–æ–≤: {page['char_count']}")
            print(f"  –°–ª–æ–≤: {page['word_count']}")
            print(f"  –¢–µ–∫—Å—Ç: {page['text'][:100]}...")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {result['error']}")


def example_docx_specific():
    """–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å DOCX"""
    print("\n=== –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å DOCX ===")
    
    # –°–æ–∑–¥–∞–µ–º DOCX —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    docx_extractor = DOCXTextExtractor(extract_tables=True, extract_headers=True)
    
    test_file = "test_document.docx"
    
    if not os.path.exists(test_file):
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª {test_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ DOCX
    result = docx_extractor.extract_text_from_file(test_file)
    
    if result["success"]:
        print(f"‚úÖ DOCX —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
        print(f"üìÑ –ú–µ—Ç–æ–¥: {result['method']}")
        print(f"üìù –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {result['metadata']['total_paragraphs']}")
        print(f"üìã –ó–∞–≥–æ–ª–æ–≤–∫–æ–≤: {result['metadata']['total_headers']}")
        print(f"üìä –¢–∞–±–ª–∏—Ü: {result['metadata']['total_tables']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        if result["headers"]:
            print(f"\nüìã –ó–∞–≥–æ–ª–æ–≤–∫–∏:")
            for i, header in enumerate(result["headers"][:5], 1):
                print(f"  {i}. {header['text']} (—Å—Ç–∏–ª—å: {header['style']})")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        if result["tables"]:
            print(f"\nüìä –¢–∞–±–ª–∏—Ü—ã:")
            for i, table in enumerate(result["tables"][:2], 1):
                print(f"  {i}. –°—Ç—Ä–æ–∫: {table['row_count']}, –°—Ç–æ–ª–±—Ü–æ–≤: {table['col_count']}")
                print(f"     –¢–µ–∫—Å—Ç: {table['text'][:100]}...")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX: {result['error']}")


def example_from_bytes():
    """–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å –±–∞–π—Ç–∞–º–∏"""
    print("\n=== –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å –±–∞–π—Ç–∞–º–∏ ===")
    
    test_file = "test_document.pdf"
    
    if not os.path.exists(test_file):
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª {test_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –≤ –±–∞–π—Ç—ã
    with open(test_file, 'rb') as f:
        file_content = f.read()
    
    # –ü–∞—Ä—Å–∏–º –∏–∑ –±–∞–π—Ç–æ–≤
    result = parse_document_from_bytes(file_content, "test_document.pdf")
    
    if result["success"]:
        print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏–∑ –±–∞–π—Ç–æ–≤")
        print(f"üìÑ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {result['file_size']} –±–∞–π—Ç")
        print(f"üìÑ –ú–µ—Ç–æ–¥: {result['method']}")
        print(f"üìù –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞: {len(result['text'])} —Å–∏–º–≤–æ–ª–æ–≤")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑ –±–∞–π—Ç–æ–≤: {result['error']}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏"""
    print("üöÄ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª—è utils –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("=" * 80)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    example_basic_usage()
    example_advanced_usage()
    example_text_processing()
    example_pdf_specific()
    example_docx_specific()
    example_from_bytes()
    
    print("\n‚úÖ –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!")
    print("\nüìö –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–º. README.md")


if __name__ == "__main__":
    main()
