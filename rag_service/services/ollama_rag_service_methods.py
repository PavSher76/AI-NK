import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class OllamaRAGServiceMethods:
    """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è OllamaRAGService"""
    
    def __init__(self, rag_service):
        self.rag_service = rag_service
    
    def hybrid_search(self, query: str, k: int = 8, document_filter: Optional[str] = None, 
                     chapter_filter: Optional[str] = None, chunk_type_filter: Optional[str] = None, 
                     use_reranker: bool = True, fast_mode: bool = False, use_mmr: bool = True, 
                     use_intent_classification: bool = True) -> List[Dict[str, Any]]:
        """
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º
        """
        try:
            logger.info(f"üîç [HYBRID_SEARCH] Performing advanced hybrid search for query: '{query}' with k={k}")
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è –∏ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
            intent_classification = None
            query_rewriting = None
            enhanced_queries = [query]
            enhanced_filters = {
                'document_filter': document_filter,
                'chapter_filter': chapter_filter,
                'chunk_type_filter': chunk_type_filter
            }
            
            if use_intent_classification and not fast_mode:
                try:
                    logger.info(f"üéØ [HYBRID_SEARCH] Classifying intent for query: '{query[:50]}...'")
                    intent_classification = self.rag_service.intent_classifier.classify_intent(query)
                    query_rewriting = self.rag_service.intent_classifier.rewrite_query(query, intent_classification)
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                    enhanced_queries = query_rewriting.rewritten_queries
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
                    if query_rewriting.section_filters:
                        enhanced_filters['chapter_filter'] = query_rewriting.section_filters[0]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∏–ª—å—Ç—Ä
                    if query_rewriting.chunk_type_filters:
                        enhanced_filters['chunk_type_filter'] = query_rewriting.chunk_type_filters[0]
                    
                    logger.info(f"‚úÖ [HYBRID_SEARCH] Intent classified as: {intent_classification.intent_type.value} "
                              f"(confidence: {intent_classification.confidence:.3f})")
                    logger.info(f"üîÑ [HYBRID_SEARCH] Generated {len(enhanced_queries)} enhanced queries")
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [HYBRID_SEARCH] Intent classification failed: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –∏—Å—Ö–æ–¥–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫
            # –ò—â–µ–º –±–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞ –∏ MMR
            search_k = 50 if use_reranker else (k * 2 if use_mmr else k)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å –ª—É—á—à–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
            best_query = enhanced_queries[0]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π (–ª—É—á—à–∏–π) –∑–∞–ø—Ä–æ—Å
            search_results = self.rag_service.hybrid_search_service.search(
                query=best_query,
                k=search_k,
                document_filter=enhanced_filters['document_filter'],
                chapter_filter=enhanced_filters['chapter_filter'],
                chunk_type_filter=enhanced_filters['chunk_type_filter'],
                use_alpha_blending=True,
                use_rrf=True
            )
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º SearchResult –≤ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
            results = []
            for result in search_results:
                formatted_result = {
                    'id': result.id,
                    'score': result.score,
                    'document_id': result.document_id,
                    'chunk_id': result.chunk_id,
                    'code': result.code,
                    'document_title': result.document_title,
                    'section_title': result.section_title,
                    'content': result.content,
                    'chunk_type': result.chunk_type,
                    'page': result.page,
                    'section': result.section,
                    'metadata': result.metadata,
                    'search_type': result.search_type,
                    'rank': result.rank
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–º–µ—Ä–µ–Ω–∏–∏
                if intent_classification:
                    formatted_result['intent_type'] = intent_classification.intent_type.value
                    formatted_result['intent_confidence'] = intent_classification.confidence
                    formatted_result['intent_keywords'] = intent_classification.keywords
                    formatted_result['intent_reasoning'] = intent_classification.reasoning
                
                if query_rewriting:
                    formatted_result['enhanced_queries'] = query_rewriting.rewritten_queries
                    formatted_result['section_filters'] = query_rewriting.section_filters
                    formatted_result['chunk_type_filters'] = query_rewriting.chunk_type_filters
                
                results.append(formatted_result)
            
            logger.info(f"‚úÖ [HYBRID_SEARCH] Found {len(results)} hybrid results")
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω –∏ –Ω–µ –±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º
            if use_reranker and not fast_mode and len(results) > k:
                logger.info(f"üîÑ [HYBRID_SEARCH] Applying BGE reranking to {len(results)} results ‚Üí {k} final results")
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π BGE —Ä–µ—Ä–∞–Ω–∫–µ—Ä —Å fallback
                    reranked_results = self.rag_service.bge_reranker_service.rerank_with_fallback(
                        query=query,
                        search_results=results,
                        top_k=k,
                        initial_top_k=len(results)
                    )
                    
                    if reranked_results:
                        logger.info(f"‚úÖ [HYBRID_SEARCH] BGE reranking completed successfully")
                        final_results = reranked_results
                    else:
                        logger.warning("‚ö†Ô∏è [HYBRID_SEARCH] BGE reranking failed, trying fallback")
                        # Fallback –∫ —Å—Ç–∞—Ä–æ–º—É —Ä–µ—Ä–∞–Ω–∫–µ—Ä—É
                        reranked_results = self.rag_service.reranker_service.rerank_search_results(
                            query=query,
                            search_results=results,
                            top_k=k,
                            initial_top_k=len(results)
                        )
                        if reranked_results:
                            logger.info(f"‚úÖ [HYBRID_SEARCH] Fallback reranking completed")
                            final_results = reranked_results
                        else:
                            logger.warning("‚ö†Ô∏è [HYBRID_SEARCH] All reranking failed, using original results")
                            final_results = results[:k]
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º MMR –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
                    if use_mmr and not fast_mode and len(final_results) > k:
                        logger.info(f"üîÑ [HYBRID_SEARCH] Applying MMR diversification to {len(final_results)} results ‚Üí {k}")
                        try:
                            mmr_results = self.rag_service.mmr_service.diversify_results(
                                results=final_results,
                                k=k,
                                query=query,
                                use_semantic_similarity=True
                            )
                            
                            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º MMR —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
                            diversified_results = []
                            for mmr_result in mmr_results:
                                formatted_result = {
                                    'id': mmr_result.id,
                                    'score': mmr_result.mmr_score,
                                    'document_id': mmr_result.document_id,
                                    'chunk_id': mmr_result.chunk_id,
                                    'code': mmr_result.code,
                                    'document_title': mmr_result.document_title,
                                    'section_title': mmr_result.section_title,
                                    'content': mmr_result.content,
                                    'chunk_type': mmr_result.chunk_type,
                                    'page': mmr_result.page,
                                    'section': mmr_result.section,
                                    'metadata': mmr_result.metadata,
                                    'search_type': mmr_result.search_type,
                                    'rank': mmr_result.rank,
                                    'mmr_score': mmr_result.mmr_score,
                                    'relevance_score': mmr_result.relevance_score,
                                    'diversity_score': mmr_result.diversity_score
                                }
                                diversified_results.append(formatted_result)
                            
                            logger.info(f"‚úÖ [HYBRID_SEARCH] MMR diversification completed")
                            return diversified_results
                            
                        except Exception as e:
                            logger.error(f"‚ùå [HYBRID_SEARCH] Error during MMR diversification: {e}")
                            logger.info("üîÑ [HYBRID_SEARCH] Falling back to reranked results")
                            return final_results[:k]
                    else:
                        return final_results[:k]
                        
                except Exception as e:
                    logger.error(f"‚ùå [HYBRID_SEARCH] Error during BGE reranking: {e}")
                    logger.info("üîÑ [HYBRID_SEARCH] Falling back to original results")
                    return results[:k]
            else:
                # –ï—Å–ª–∏ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º –∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–∞–ª–æ
                if fast_mode:
                    logger.info(f"‚ö° [HYBRID_SEARCH] Fast mode: returning top {k} results without reranking")
                return results[:k]
            
        except Exception as e:
            logger.error(f"‚ùå [HYBRID_SEARCH] Error during hybrid search: {e}")
            # Fallback –∫ —Å—Ç–∞—Ä–æ–º—É –º–µ—Ç–æ–¥—É –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return self._fallback_hybrid_search(query, k, document_filter, chapter_filter, chunk_type_filter)
    
    def _fallback_hybrid_search(self, query: str, k: int, document_filter: Optional[str] = None, 
                               chapter_filter: Optional[str] = None, chunk_type_filter: Optional[str] = None) -> List[Dict[str, Any]]:
        """Fallback –º–µ—Ç–æ–¥ –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (—Å—Ç–∞—Ä–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)"""
        try:
            logger.info(f"üîÑ [FALLBACK] Using fallback hybrid search for query: '{query}'")
            
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self.rag_service.embedding_service.create_embedding(query)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
            must_conditions = []
            
            if document_filter and document_filter != 'all':
                must_conditions.append({
                    "key": "code",
                    "match": {"value": document_filter}
                })
            
            if chapter_filter:
                must_conditions.append({
                    "key": "section",
                    "match": {"value": chapter_filter}
                })
            
            if chunk_type_filter:
                must_conditions.append({
                    "key": "chunk_type",
                    "match": {"value": chunk_type_filter}
                })
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –≤ Qdrant
            search_result = self.rag_service.qdrant_service.search_similar(
                query_vector=query_embedding,
                limit=k,
                filters={"must": must_conditions} if must_conditions else None
            )
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for point in search_result:
                result = {
                    'id': point['id'],
                    'score': point['score'],
                    'document_id': point['payload'].get('document_id'),
                    'chunk_id': point['payload'].get('chunk_id'),
                    'code': point['payload'].get('code'),
                    'document_title': point['payload'].get('title'),
                    'section_title': point['payload'].get('section_title'),
                    'content': point['payload'].get('content'),
                    'chunk_type': point['payload'].get('chunk_type'),
                    'page': point['payload'].get('page'),
                    'section': point['payload'].get('section'),
                    'metadata': point['payload'].get('metadata', {}),
                    'search_type': 'fallback'
                }
                results.append(result)
            
            logger.info(f"‚úÖ [FALLBACK] Found {len(results)} fallback results")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå [FALLBACK] Error during fallback search: {e}")
            return []
    
    def get_ntd_consultation(self, message: str, user_id: str, history: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ø–æ –ù–¢–î —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        try:
            logger.info(f"üí¨ [NTD_CONSULTATION] Processing consultation request: '{message[:100]}...'")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
            document_code = self.rag_service.document_parser.extract_document_code_from_query(message)
            logger.info(f"üîç [NTD_CONSULTATION] Extracted document code: {document_code}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞, –µ—Å–ª–∏ –æ–Ω –Ω–∞–π–¥–µ–Ω
            search_query = document_code if document_code else message
            logger.info(f"üîç [NTD_CONSULTATION] Using search query: {search_query}")
            
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Ä–≤–∏—Å–∞—Ö
            logger.info(f"üîç [NTD_CONSULTATION] RAG service instance: {id(self.rag_service)}")
            logger.info(f"üîç [NTD_CONSULTATION] Hybrid search service instance: {id(self.rag_service.hybrid_search_service)}")
            logger.info(f"üîç [NTD_CONSULTATION] Qdrant service instance: {id(self.rag_service.hybrid_search_service.qdrant_service)}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            structured_context = self.rag_service.get_structured_context(search_query, k=10)
            
            if not structured_context.get('context'):
                return {
                    "status": "success",
                    "response": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.",
                    "sources": [],
                    "confidence": 0.0,
                    "documents_used": 0,
                    "structured_context": structured_context,
                    "timestamp": datetime.now().isoformat()
                }
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            search_results = []
            for context_item in structured_context['context']:
                search_results.append({
                    'code': context_item['doc'],
                    'document_title': context_item['document_title'],
                    'section': context_item['section'],
                    'page': context_item['page'],
                    'content': context_item.get('snippet', ''),
                    'score': context_item['score'],
                    'chunk_type': context_item.get('chunk_type', ''),
                    'metadata': context_item.get('metadata', {})
                })
            
            if not search_results:
                return {
                    "status": "success",
                    "response": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.",
                    "sources": [],
                    "confidence": 0.0,
                    "documents_used": 0,
                    "timestamp": datetime.now().isoformat()
                }
            
            # –ï—Å–ª–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–≥–æ –Ω–∞–ª–∏—á–∏–µ
            if document_code:
                # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –∫–æ–¥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
                exact_match = None
                for result in search_results:
                    if result.get('code') == document_code:
                        exact_match = result
                        break
                
                if exact_match:
                    logger.info(f"‚úÖ [NTD_CONSULTATION] Found exact match for {document_code}")
                    top_result = exact_match
                    confidence = 1.0  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                else:
                    logger.warning(f"‚ö†Ô∏è [NTD_CONSULTATION] Document {document_code} not found in system")
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Ç–æ–º, —á—Ç–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                    return {
                        "status": "warning",
                        "response": f"‚ö†Ô∏è **–í–Ω–∏–º–∞–Ω–∏–µ!** –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π –¥–æ–∫—É–º–µ–Ω—Ç **{document_code}** –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Å–∏—Å—Ç–µ–º–µ.\n\n"
                                  f"–í–æ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\n\n"
                                  f"**{search_results[0]['document_title']}**\n"
                                  f"–†–∞–∑–¥–µ–ª: {search_results[0]['section']}\n\n"
                                  f"{search_results[0]['content'][:500]}...\n\n"
                                  f"**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç {document_code} –≤ —Å–∏—Å—Ç–µ–º—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ—á–Ω–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏.",
                        "sources": [{
                            'document_code': search_results[0]['code'],
                            'document_title': search_results[0]['document_title'],
                            'section': search_results[0]['section'],
                            'page': search_results[0]['page'],
                            'content_preview': search_results[0]['content'][:200] + "..." if len(search_results[0]['content']) > 200 else search_results[0]['content'],
                            'relevance_score': search_results[0]['score'],
                            'note': '–î–æ–∫—É–º–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É –ø–æ–∏—Å–∫—É, –Ω–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–º'
                        }],
                        "confidence": 0.5,
                        "documents_used": 1,
                        "missing_document": document_code,
                        "timestamp": datetime.now().isoformat()
                    }
            else:
                # –ï—Å–ª–∏ –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫
                top_result = search_results[0]
                confidence = min(top_result['score'], 1.0) if top_result['score'] > 0 else 0.0
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            sources = []
            for result in search_results[:3]:  # –¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                source = {
                    'title': result['document_title'],
                    'filename': result['document_title'],
                    'page': result.get('page', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
                    'section': result.get('section', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                    'document_code': result.get('code', ''),
                    'content_preview': result['content'][:200] + "..." if len(result['content']) > 200 else result['content'],
                    'relevance_score': result['score']
                }
                sources.append(source)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            response = self._format_consultation_response_with_context(message, structured_context, top_result)
            
            return {
                "status": "success",
                "response": response,
                "sources": sources,
                "confidence": confidence,
                "documents_used": len(search_results),
                "structured_context": structured_context,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå [NTD_CONSULTATION] Error during consultation: {e}")
            return {
                "status": "error",
                "response": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}",
                "sources": [],
                "confidence": 0.0,
                "documents_used": 0,
                "timestamp": datetime.now().isoformat()
            }
    
    def _format_consultation_response_with_context(self, message: str, structured_context: Dict[str, Any], top_result: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –æ—Ç–≤–µ—Ç–∞
            query_lower = message.lower()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—Ç–≤–µ—Ç–∞
            if any(word in query_lower for word in ['–∫–∞–∫–æ–π', '—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞']):
                response_type = "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π"
            elif any(word in query_lower for word in ['—Ä–µ–≥–ª–∞–º–µ–Ω—Ç–∏—Ä—É–µ—Ç', '–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç', '—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç']):
                response_type = "–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π"
            else:
                response_type = "–æ–±—â–∏–π"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
            response_parts = []
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç–≤–µ—Ç–∞
            if response_type == "–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π":
                response_parts.append("## üìã –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ")
            elif response_type == "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π":
                response_parts.append("## üí° –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É")
            else:
                response_parts.append("## üìñ –û—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            
            # –ú–µ—Ç–∞-—Å–≤–æ–¥–∫–∞
            meta_summary = structured_context.get('meta_summary', {})
            if meta_summary:
                response_parts.append("")
                response_parts.append(f"**üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞:** {meta_summary.get('query_type', '–æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è')}")
                response_parts.append(f"**üìö –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {meta_summary.get('documents_found', 0)}")
                response_parts.append(f"**üìë –†–∞–∑–¥–µ–ª–æ–≤:** {meta_summary.get('sections_covered', 0)}")
                response_parts.append(f"**‚≠ê –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∫—Ä—ã—Ç–∏—è:** {meta_summary.get('coverage_quality', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
                
                if meta_summary.get('key_documents'):
                    response_parts.append(f"**üîë –ö–ª—é—á–µ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:** {', '.join(meta_summary['key_documents'][:3])}")
            
            response_parts.append("")
            response_parts.append("---")
            response_parts.append("")
            
            # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context_items = structured_context.get('context', [])
            
            for i, item in enumerate(context_items[:3], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3
                response_parts.append(f"### {i}. {item['doc']} - {item['document_title']}")
                response_parts.append(f"**–†–∞–∑–¥–µ–ª:** {item['section']} - {item['section_title']}")
                response_parts.append(f"**–°—Ç—Ä–∞–Ω–∏—Ü–∞:** {item['page']}")
                response_parts.append(f"**–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å:** {item['score']:.2f} ({item['why']})")
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤–æ–¥–∫—É, –µ—Å–ª–∏ –µ—Å—Ç—å
                if 'summary' in item:
                    summary = item['summary']
                    response_parts.append("")
                    response_parts.append(f"**üìù –û —Ä–∞–∑–¥–µ–ª–µ:** {summary['topic']}")
                    response_parts.append(f"**‚öñÔ∏è –¢–∏–ø –Ω–æ—Ä–º—ã:** {summary['norm_type']}")
                    
                    if summary['key_points']:
                        response_parts.append("**üîë –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**")
                        for point in summary['key_points'][:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ 3 –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤
                            response_parts.append(f"‚Ä¢ {point}")
                    
                    response_parts.append(f"**üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å:** {summary['relevance_reason']}")
                
                response_parts.append("")
                response_parts.append(f"**–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:**")
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ –∞–±–∑–∞—Ü—ã
                content = item.get('snippet', '')
                if content:
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –≤ –∞–±–∑–∞—Ü—ã
                    sentences = content.split('. ')
                    paragraphs = []
                    current_paragraph = []
                    
                    for sentence in sentences:
                        if sentence.strip():
                            current_paragraph.append(sentence.strip())
                            # –ï—Å–ª–∏ –∞–±–∑–∞—Ü —Å—Ç–∞–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–º, –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π
                            if len(' '.join(current_paragraph)) > 200:
                                paragraphs.append(' '.join(current_paragraph))
                                current_paragraph = []
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–±–∑–∞—Ü
                    if current_paragraph:
                        paragraphs.append(' '.join(current_paragraph))
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∞–±–∑–∞—Ü—ã –≤ –æ—Ç–≤–µ—Ç
                    for paragraph in paragraphs:
                        response_parts.append(paragraph)
                        response_parts.append("")
                else:
                    response_parts.append("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
                
                response_parts.append("---")
                response_parts.append("")
            
            # –ò—Ç–æ–≥–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            response_parts.append(f"**üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∏—Å–∫–∞:**")
            response_parts.append(f"‚Ä¢ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {structured_context.get('total_candidates', 0)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            response_parts.append(f"‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {structured_context.get('avg_score', 0):.2f}")
            response_parts.append(f"‚Ä¢ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {structured_context.get('timestamp', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            
            return "\n".join(response_parts)
            
        except Exception as e:
            logger.error(f"‚ùå [CONSULTATION_FORMAT] Error formatting response: {e}")
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é
            return f"**{top_result['document_title']}**\n\n{top_result['content']}"
    
    def _get_document_metadata(self, document_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            with self.rag_service.db_manager.get_cursor() as cursor:
                cursor.execute("""
                    SELECT id, filename, original_filename, file_path, document_hash, document_type
                    FROM uploaded_documents 
                    WHERE id = %s
                """, (document_id,))
                
                result = cursor.fetchone()
                if result:
                    logger.info(f"üîç [GET_DOCUMENT_METADATA] Raw result: {result}")
                    logger.info(f"üîç [GET_DOCUMENT_METADATA] Result type: {type(result)}")
                    logger.info(f"üîç [GET_DOCUMENT_METADATA] Result length: {len(result) if result else 0}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ result - —ç—Ç–æ –∫–æ—Ä—Ç–µ–∂
                    if isinstance(result, tuple) and len(result) >= 6:
                        doc_id, filename, original_filename, file_path, document_hash, document_type = result
                        logger.info(f"üîç [GET_DOCUMENT_METADATA] Retrieved from DB: doc_id={doc_id}, filename={filename}, original_filename={original_filename}, file_path={file_path}")
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º original_filename –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                        return self.rag_service.metadata_extractor.extract_document_metadata(original_filename, doc_id, file_path)
                    else:
                        logger.error(f"‚ùå [GET_DOCUMENT_METADATA] Invalid result format: {result}")
                        return self.rag_service.metadata_extractor.extract_document_metadata(f"error_doc_{document_id}", document_id)
                else:
                    logger.warning(f"‚ö†Ô∏è [GET_DOCUMENT_METADATA] Document {document_id} not found")
                    return self.rag_service.metadata_extractor.extract_document_metadata(f"unknown_doc_{document_id}", document_id)
                    
        except Exception as e:
            logger.error(f"‚ùå [GET_DOCUMENT_METADATA] Error getting document metadata: {e}")
            return self.rag_service.metadata_extractor.extract_document_metadata(f"error_doc_{document_id}", document_id)
