import logging
from typing import Dict, Any, List, Optional, Union
from contextlib import contextmanager
import psycopg2
from psycopg2.extras import RealDictCursor
from psycopg2.pool import SimpleConnectionPool

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

class DatabaseManager:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö PostgreSQL —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —á—Ç–µ–Ω–∏–µ –∏ –∑–∞–ø–∏—Å—å"""
    
    def __init__(self, connection_string: str, min_connections: int = 1, max_connections: int = 10):
        self.connection_string = connection_string
        self.min_connections = min_connections
        self.max_connections = max_connections
        
        # –°–æ–∑–¥–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è –∑–∞–ø–∏—Å–∏
        self._write_pool = None
        # –°–æ–∑–¥–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è —á—Ç–µ–Ω–∏—è (read-only)
        self._read_pool = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É–ª—ã —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        self._init_connection_pools()
    
    def _init_connection_pools(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–ª–æ–≤ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        try:
            # –ü—É–ª –¥–ª—è –∑–∞–ø–∏—Å–∏
            self._write_pool = SimpleConnectionPool(
                self.min_connections,
                self.max_connections,
                self.connection_string
            )
            
            # –ü—É–ª –¥–ª—è —á—Ç–µ–Ω–∏—è (–æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—É–ª –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π —á—Ç–µ–Ω–∏—è)
            self._read_pool = SimpleConnectionPool(
                self.min_connections,
                self.max_connections,
                self.connection_string
            )
            
            logger.info(f"‚úÖ [DB_MANAGER] Connection pools initialized (read: {self.min_connections}-{self.max_connections}, write: {self.min_connections}-{self.max_connections})")
            
        except Exception as e:
            logger.error(f"‚ùå [DB_MANAGER] Error initializing connection pools: {e}")
            raise
    
    @contextmanager
    def get_read_connection(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–∞ —á—Ç–µ–Ω–∏–µ"""
        connection = None
        try:
            connection = self._read_pool.getconn()
            yield connection
        except Exception as e:
            logger.error(f"‚ùå [DB_MANAGER] Error in read connection: {e}")
            if connection:
                try:
                    connection.rollback()
                except Exception as rollback_error:
                    logger.error(f"‚ùå [DB_MANAGER] Error during read rollback: {rollback_error}")
            raise
        finally:
            if connection:
                self._read_pool.putconn(connection)
    
    @contextmanager
    def get_write_connection(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–∞ –∑–∞–ø–∏—Å—å"""
        connection = None
        try:
            connection = self._write_pool.getconn()
            yield connection
        except Exception as e:
            logger.error(f"‚ùå [DB_MANAGER] Error in write connection: {e}")
            if connection:
                try:
                    connection.rollback()
                except Exception as rollback_error:
                    logger.error(f"‚ùå [DB_MANAGER] Error during write rollback: {rollback_error}")
            raise
        finally:
            if connection:
                self._write_pool.putconn(connection)
    
    @contextmanager
    def get_read_cursor(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫—É—Ä—Å–æ—Ä–∞ –Ω–∞ —á—Ç–µ–Ω–∏–µ"""
        with self.get_read_connection() as connection:
            cursor = None
            try:
                cursor = connection.cursor(cursor_factory=RealDictCursor)
                yield cursor
            except Exception as e:
                logger.error(f"‚ùå [DB_MANAGER] Error in read cursor: {e}")
                if connection:
                    try:
                        connection.rollback()
                    except Exception as rollback_error:
                        logger.error(f"‚ùå [DB_MANAGER] Error during read cursor rollback: {rollback_error}")
                raise
            finally:
                if cursor:
                    cursor.close()
    
    @contextmanager
    def get_write_cursor(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫—É—Ä—Å–æ—Ä–∞ –Ω–∞ –∑–∞–ø–∏—Å—å"""
        with self.get_write_connection() as connection:
            cursor = None
            try:
                cursor = connection.cursor(cursor_factory=RealDictCursor)
                yield cursor, connection
            except Exception as e:
                logger.error(f"‚ùå [DB_MANAGER] Error in write cursor: {e}")
                if connection:
                    try:
                        connection.rollback()
                    except Exception as rollback_error:
                        logger.error(f"‚ùå [DB_MANAGER] Error during write cursor rollback: {rollback_error}")
                raise
            finally:
                if cursor:
                    cursor.close()
    
    def execute_read_query(self, query: str, params: Optional[tuple] = None) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —á—Ç–µ–Ω–∏–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            with self.get_read_cursor() as cursor:
                cursor.execute(query, params or ())
                results = cursor.fetchall()
                return [dict(row) for row in results]
        except Exception as e:
            logger.error(f"‚ùå [DB_MANAGER] Error executing read query: {e}")
            logger.error(f"‚ùå [DB_MANAGER] Query: {query}")
            logger.error(f"‚ùå [DB_MANAGER] Params: {params}")
            return []
    
    def execute_write_query(self, query: str, params: Optional[tuple] = None, commit: bool = True) -> Optional[Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∑–∞–ø–∏—Å—å —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            with self.get_write_cursor() as (cursor, connection):
                cursor.execute(query, params or ())
                if commit:
                    connection.commit()
                return cursor.fetchone() if cursor.description else None
        except Exception as e:
            logger.error(f"‚ùå [DB_MANAGER] Error executing write query: {e}")
            logger.error(f"‚ùå [DB_MANAGER] Query: {query}")
            logger.error(f"‚ùå [DB_MANAGER] Params: {params}")
            raise
    
    def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ —á—Ç–µ–Ω–∏–µ
            with self.get_read_connection() as read_conn:
                with read_conn.cursor() as cursor:
                    cursor.execute("SELECT 1")
                    read_ok = cursor.fetchone()[0] == 1
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ –∑–∞–ø–∏—Å—å
            with self.get_write_connection() as write_conn:
                with write_conn.cursor() as cursor:
                    cursor.execute("SELECT 1")
                    write_ok = cursor.fetchone()[0] == 1
            
            return {
                "status": "healthy" if read_ok and write_ok else "unhealthy",
                "read_connection": "ok" if read_ok else "error",
                "write_connection": "ok" if write_ok else "error",
                "read_pool_size": len(self._read_pool._pool) if self._read_pool else 0,
                "write_pool_size": len(self._write_pool._pool) if self._write_pool else 0
            }
        except Exception as e:
            logger.error(f"‚ùå [DB_MANAGER] Health check failed: {e}")
            return {
                "status": "unhealthy",
                "error": str(e)
            }
    
    def close_all_connections(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        try:
            if self._read_pool:
                self._read_pool.closeall()
            if self._write_pool:
                self._write_pool.closeall()
            logger.info("‚úÖ [DB_MANAGER] All connections closed")
        except Exception as e:
            logger.error(f"‚ùå [DB_MANAGER] Error closing connections: {e}")
    
    # –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
    def get_connection(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        logger.warning("‚ö†Ô∏è [DB_MANAGER] Using deprecated get_connection() method. Use get_read_connection() or get_write_connection() instead.")
        return self._write_pool.getconn() if self._write_pool else None
    
    def get_cursor(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—É—Ä—Å–æ—Ä–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        logger.warning("‚ö†Ô∏è [DB_MANAGER] Using deprecated get_cursor() method. Use get_read_cursor() or get_write_cursor() instead.")
        connection = self.get_connection()
        if connection:
            return connection.cursor(cursor_factory=RealDictCursor)
        return None
    
    def save_document_to_db(self, document_id: int, filename: str, original_filename: str, 
                           file_type: str, file_size: int, document_hash: str, 
                           category: str, document_type: str) -> int:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω –ª–∏ —É–∂–µ –¥–æ–∫—É–º–µ–Ω—Ç —Å —Ç–∞–∫–∏–º —Ö–µ—à–µ–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ —á—Ç–µ–Ω–∏–µ)
            existing_docs = self.execute_read_query("""
                SELECT id FROM uploaded_documents 
                WHERE document_hash = %s
            """, (document_hash,))
            
            if existing_docs:
                raise Exception("Document with this content already exists")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ –∑–∞–ø–∏—Å—å)
            result = self.execute_write_query("""
                INSERT INTO uploaded_documents 
                (id, filename, original_filename, file_type, file_size, document_hash, 
                 category, document_type, processing_status)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, 'pending')
                RETURNING id
            """, (
                document_id,
                filename,
                original_filename,
                file_type,
                file_size,
                document_hash,
                category,
                document_type
            ))
            
            saved_id = result[0] if result else document_id
            logger.info(f"‚úÖ [SAVE_DOCUMENT] Document saved with ID: {saved_id}")
            return saved_id
            
        except Exception as e:
            logger.error(f"‚ùå [SAVE_DOCUMENT] Error saving document: {e}")
            raise

    def update_document_status(self, document_id: int, status: str, error_message: str = None):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            if error_message:
                self.execute_write_query("""
                    UPDATE uploaded_documents 
                    SET processing_status = %s, processing_error = %s
                    WHERE id = %s
                """, (status, error_message, document_id))
            else:
                self.execute_write_query("""
                    UPDATE uploaded_documents 
                    SET processing_status = %s, processing_error = NULL
                    WHERE id = %s
                """, (status, document_id))
            
            logger.info(f"‚úÖ [UPDATE_STATUS] Document {document_id} status updated to: {status}")
            
        except Exception as e:
            logger.error(f"‚ùå [UPDATE_STATUS] Error updating document {document_id} status: {e}")
            raise

    def get_documents(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ —á—Ç–µ–Ω–∏–µ)"""
        try:
            documents = self.execute_read_query("""
                SELECT ud.id, ud.original_filename, ud.category, ud.processing_status, ud.upload_date, 
                       ud.file_size, COALESCE(ud.token_count, 0) as token_count,
                       COALESCE(chunk_counts.chunks_count, 0) as chunks_count
                FROM uploaded_documents ud
                LEFT JOIN (
                    SELECT document_id, COUNT(*) as chunks_count 
                    FROM normative_chunks 
                    GROUP BY document_id
                ) chunk_counts ON ud.id = chunk_counts.document_id
                ORDER BY ud.upload_date DESC
            """)
            
            result = []
            for doc in documents:
                result.append({
                    'id': doc['id'],
                    'title': doc['original_filename'],
                    'original_filename': doc['original_filename'],
                    'filename': doc['original_filename'],
                    'category': doc['category'],
                    'status': doc['processing_status'],
                    'processing_status': doc['processing_status'],
                    'upload_date': doc['upload_date'].isoformat() if doc['upload_date'] else None,
                    'file_size': doc['file_size'],
                    'token_count': doc['token_count'],
                    'vector_indexed': doc['processing_status'] == 'completed',
                    'chunks_count': doc['chunks_count']
                })
            
            logger.info(f"üìã [GET_DOCUMENTS] Retrieved {len(result)} documents")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [GET_DOCUMENTS] Error getting documents: {e}")
            return []

    def get_documents_from_uploaded(self, document_type: str = 'all') -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã uploaded_documents (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ —á—Ç–µ–Ω–∏–µ)"""
        try:
            documents = self.execute_read_query("""
                SELECT ud.id, ud.original_filename, ud.category, ud.processing_status, ud.upload_date, 
                       ud.file_size, COALESCE(ud.token_count, 0) as token_count,
                       COALESCE(chunk_counts.chunks_count, 0) as chunks_count
                FROM uploaded_documents ud
                LEFT JOIN (
                    SELECT document_id, COUNT(*) as chunks_count 
                    FROM normative_chunks 
                    GROUP BY document_id
                ) chunk_counts ON ud.id = chunk_counts.document_id
                WHERE ud.category = %s OR %s = 'all'
                ORDER BY ud.upload_date DESC
            """, (document_type, document_type))
            
            result = []
            for doc in documents:
                result.append({
                    'id': doc['id'],
                    'title': doc['original_filename'],
                    'original_filename': doc['original_filename'],
                    'filename': doc['original_filename'],
                    'category': doc['category'],
                    'status': doc['processing_status'],
                    'processing_status': doc['processing_status'],
                    'upload_date': doc['upload_date'].isoformat() if doc['upload_date'] else None,
                    'file_size': doc['file_size'],
                    'token_count': doc['token_count'],
                    'vector_indexed': doc['processing_status'] == 'completed',
                    'chunks_count': doc['chunks_count']
                })
            
            logger.info(f"üìã [GET_DOCUMENTS_FROM_UPLOADED] Retrieved {len(result)} documents of type '{document_type}'")
            return result
                
        except Exception as e:
            logger.error(f"‚ùå [GET_DOCUMENTS_FROM_UPLOADED] Error getting documents: {e}")
            return []

    def get_document_chunks(self, document_id: int) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ —á—Ç–µ–Ω–∏–µ)"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            document_results = self.execute_read_query("""
                SELECT original_filename 
                FROM uploaded_documents 
                WHERE id = %s
            """, (document_id,))
            
            # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
            import re
            original_filename = document_results[0]['original_filename'] if document_results else f"Document_{document_id}"
            document_title = re.sub(r'\.(pdf|txt|doc|docx)$', '', original_filename, flags=re.IGNORECASE)
            logger.info(f"üîç [GET_DOCUMENT_CHUNKS] Document title: {document_title}")
            
            # –ü–æ–ª—É—á–∞–µ–º —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            chunks = self.execute_read_query("""
                SELECT chunk_id, content, chapter as section_title, chunk_type, page_number as page, section
                FROM normative_chunks
                WHERE document_id = %s
                ORDER BY page_number, chunk_id
            """, (document_id,))
            
            result = []
            for chunk in chunks:
                result.append({
                    'chunk_id': chunk['chunk_id'],
                    'content': chunk['content'],
                    'section_title': chunk['section_title'],
                    'chunk_type': chunk['chunk_type'],
                    'page': chunk['page'],
                    'section': chunk['section'],
                    'document_title': document_title  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                })
            
            logger.info(f"üìã [GET_DOCUMENT_CHUNKS] Retrieved {len(result)} chunks for document {document_id} ({document_title})")
            return result
                
        except Exception as e:
            logger.error(f"‚ùå [GET_DOCUMENT_CHUNKS] Error getting chunks for document {document_id}: {e}")
            return []

    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ —á—Ç–µ–Ω–∏–µ)"""
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —á–µ—Ä–µ–∑ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞ —á—Ç–µ–Ω–∏–µ
            total_docs_result = self.execute_read_query("SELECT COUNT(*) as total_documents FROM uploaded_documents")
            total_docs = total_docs_result[0]['total_documents'] if total_docs_result else 0
            
            total_chunks_result = self.execute_read_query("SELECT COUNT(*) as total_chunks FROM normative_chunks")
            total_chunks = total_chunks_result[0]['total_chunks'] if total_chunks_result else 0
            
            pending_docs_result = self.execute_read_query("SELECT COUNT(*) as pending_docs FROM uploaded_documents WHERE processing_status = 'pending'")
            pending_docs = pending_docs_result[0]['pending_docs'] if pending_docs_result else 0
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            total_tokens_result = self.execute_read_query("SELECT COALESCE(SUM(token_count), 0) as total_tokens FROM uploaded_documents")
            total_tokens = total_tokens_result[0]['total_tokens'] if total_tokens_result else 0
            
            stats = {
                'total_documents': total_docs,
                'total_chunks': total_chunks,
                'pending_documents': pending_docs,
                'total_tokens': total_tokens
            }
            
            logger.info(f"üìä [GET_STATS] Retrieved stats: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå [GET_STATS] Error getting stats: {e}")
            return {
                'total_documents': 0,
                'total_chunks': 0,
                'pending_documents': 0,
                'total_tokens': 0
            }
