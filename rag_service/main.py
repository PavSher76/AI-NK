from fastapi import FastAPI, HTTPException, Request, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import uvicorn
import hashlib
import time
import asyncio
import json
import logging
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor
import qdrant_client
from qdrant_client.models import Distance, VectorParams, PointStruct
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
model_logger = logging.getLogger("model")

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –º–æ–¥—É–ª–µ–π
from api.endpoints import (
    get_documents,
    get_stats,
    get_document_chunks,
    get_documents_stats,
    delete_document,
    delete_document_indexes,
    reindex_documents,
    start_async_reindex,
    get_reindex_status,
    ntd_consultation_chat,
    ntd_consultation_stats,
    clear_consultation_cache,
    get_consultation_cache_stats,
    health_check,
    get_metrics
)

# –ò–º–ø–æ—Ä—Ç RAG —Å–µ—Ä–≤–∏—Å–∞
from services.rag_service import RAGService

# –ú–æ–¥–µ–ª–∏ Pydantic
class NTDConsultationRequest(BaseModel):
    message: str
    user_id: str

class NTDConsultationResponse(BaseModel):
    status: str
    response: str
    sources: List[Dict[str, Any]]
    confidence: float
    documents_used: int
    timestamp: str

class SearchRequest(BaseModel):
    query: str
    k: int = 8
    document_filter: Optional[str] = None
    chapter_filter: Optional[str] = None
    chunk_type_filter: Optional[str] = None

# –°–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(
    title="RAG Service",
    description="–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏ RAG-—Å–∏—Å—Ç–µ–º–æ–π",
    version="1.0.0"
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–µ—Ä–≤–∏—Å–∞ (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)
rag_service = None

def get_rag_service():
    """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–µ—Ä–≤–∏—Å–∞"""
    global rag_service
    if rag_service is None:
        rag_service = RAGService()
    return rag_service

# ============================================================================
# API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
# ============================================================================

@app.get("/documents")
async def documents_endpoint():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    return get_documents()

@app.get("/stats")
async def stats_endpoint():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ RAG-—Å–∏—Å—Ç–µ–º—ã"""
    return get_stats()

@app.get("/documents/{document_id}/chunks")
async def document_chunks_endpoint(document_id: int):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —á–∞–Ω–∫–∞—Ö –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    return get_document_chunks(document_id)

@app.get("/documents/stats")
async def documents_stats_endpoint():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞"""
    return get_documents_stats()

@app.delete("/documents/{document_id}")
async def delete_document_endpoint(document_id: int):
    """–£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –µ–≥–æ –∏–Ω–¥–µ–∫—Å–æ–≤"""
    return delete_document(document_id)

@app.delete("/indexes/document/{document_id}")
async def delete_document_indexes_endpoint(document_id: int):
    """–£–¥–∞–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    return delete_document_indexes(document_id)

@app.post("/reindex-documents")
async def reindex_documents_endpoint():
    """–†–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è)"""
    return reindex_documents()

@app.post("/reindex-documents/async")
async def start_async_reindex_endpoint():
    """–ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    return start_async_reindex()

@app.get("/reindex-documents/status/{task_id}")
async def get_reindex_status_endpoint(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    return get_reindex_status(task_id)

@app.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    category: str = Form("other"),
    description: str = Form("")
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
        if not file.filename.lower().endswith(('.pdf', '.docx', '.txt')):
            raise HTTPException(status_code=400, detail="Unsupported file type. Only PDF, DOCX, and TXT files are allowed.")
        
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        content = await file.read()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
        hash_part = int(hashlib.md5(f"{file.filename}_{content[:100]}".encode()).hexdigest()[:3], 16)
        time_part = int(time.time()) % 100000
        document_id = time_part * 1000 + hash_part
        
        # –ü–æ–ª—É—á–∞–µ–º RAG —Å–µ—Ä–≤–∏—Å
        rag_service_instance = get_rag_service()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        try:
            with rag_service_instance.db_manager.get_cursor() as cursor:
                cursor.execute("""
                    INSERT INTO uploaded_documents 
                    (id, original_filename, file_content, file_size, category, processing_status, created_at)
                    VALUES (%s, %s, %s, %s, %s, %s, NOW())
                """, (document_id, file.filename, content, len(content), category, 'processing'))
                cursor.connection.commit()
        except Exception as e:
            logger.error(f"‚ùå [UPLOAD] Database error: {e}")
            raise HTTPException(status_code=500, detail="Database error")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
        asyncio.create_task(process_normative_document_async(document_id, content, file.filename, category))
        
        return {
            "status": "success",
            "document_id": document_id,
            "filename": file.filename,
            "message": f"Document uploaded successfully. Processing started in background."
        }
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå [UPLOAD] Upload error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def process_normative_document_async(document_id: int, content: bytes, filename: str, category: str):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        logger.info(f"üîÑ [ASYNC_PROCESS] Starting normative document processing for {document_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º RAG —Å–µ—Ä–≤–∏—Å
        rag_service_instance = get_rag_service()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
        if filename.lower().endswith('.txt'):
            text_content = content.decode('utf-8', errors='ignore')
        elif filename.lower().endswith('.pdf'):
            # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            text_content = f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞ {filename}"
        else:
            text_content = f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {filename}"
        
        # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏
        chunks = create_document_chunks(text_content, document_id, filename)
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —á–∞–Ω–∫–∏
        success = rag_service_instance.index_document_chunks(document_id, chunks)
        
        if success:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "completed"
            with rag_service_instance.db_manager.get_cursor() as cursor:
                cursor.execute("""
                    UPDATE uploaded_documents 
                    SET processing_status = 'completed'
                    WHERE id = %s
                """, (document_id,))
                cursor.connection.commit()
            
            logger.info(f"‚úÖ [ASYNC_PROCESS] Document {document_id} processed successfully")
        else:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "error"
            with rag_service_instance.db_manager.get_cursor() as cursor:
                cursor.execute("""
                    UPDATE uploaded_documents 
                    SET processing_status = 'error'
                    WHERE id = %s
                """, (document_id,))
                cursor.connection.commit()
            
            logger.error(f"‚ùå [ASYNC_PROCESS] Document {document_id} processing failed")
            
    except Exception as e:
        logger.error(f"‚ùå [ASYNC_PROCESS] Async processing failed for document {document_id}: {e}")
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "error"
        try:
            rag_service_instance = get_rag_service()
            with rag_service_instance.db_manager.get_cursor() as cursor:
                cursor.execute("""
                    UPDATE uploaded_documents 
                    SET processing_status = 'error'
                    WHERE id = %s
                """, (document_id,))
                cursor.connection.commit()
        except Exception:
            pass

def create_document_chunks(text_content: str, document_id: int, filename: str) -> List[Dict[str, Any]]:
    """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    chunks = []
    
    # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ –∞–±–∑–∞—Ü–∞–º
    paragraphs = text_content.split('\n\n')
    
    for i, paragraph in enumerate(paragraphs):
        if paragraph.strip():
            chunk = {
                'id': f"doc_{document_id}_chunk_{i}",
                'document_id': document_id,
                'content': paragraph.strip(),
                'page': 1,  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
                'section_title': '',
                'section': '',
                'document_title': filename,
                'category': 'normative',
                'chunk_type': 'paragraph'
            }
            chunks.append(chunk)
    
    return chunks

# ============================================================================
# API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
# ============================================================================

@app.post("/search")
async def search_norms(
    query: str = Form(...),
    k: int = Form(8),
    document_filter: Optional[str] = Form(None),
    chapter_filter: Optional[str] = Form(None),
    chunk_type_filter: Optional[str] = Form(None)
):
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
    start_time = datetime.now()
    logger.info(f"üîç [SEARCH_NORM] Performing hybrid search for query: '{query}' with k={k}")
    logger.info(f"üîç [SEARCH_NORM] Filters: document={document_filter}, chapter={chapter_filter}, chunk_type={chunk_type_filter}")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º RAG —Å–µ—Ä–≤–∏—Å
        rag_service_instance = get_rag_service()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        model_logger.info(f"ü§ñ [EMBEDDING_REQUEST] Generating embeddings for query: '{query[:100]}...'")
        
        results = rag_service_instance.hybrid_search(
            query=query,
            k=k,
            document_filter=document_filter,
            chapter_filter=chapter_filter,
            chunk_type_filter=chunk_type_filter
        )
        
        execution_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"‚úÖ [SEARCH_NORM] Hybrid search completed in {execution_time:.2f}s. Found {len(results)} results.")
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
        if results:
            top_result = results[0]
            model_logger.info(f"üìä [SEARCH_RESULTS] Top result: {top_result.get('document_title', 'Unknown')} - Score: {top_result.get('score', 0):.3f}")
            model_logger.debug(f"üìä [SEARCH_RESULTS] Top result content preview: {top_result.get('content', '')[:200]}...")
        
        return {
            "query": query,
            "results_count": len(results),
            "execution_time": execution_time,
            "results": results
        }
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"‚ùå [SEARCH_NORM] Search error after {execution_time:.2f}s: {type(e).__name__}: {str(e)}")
        model_logger.error(f"‚ùå [EMBEDDING_ERROR] Failed to process query: '{query[:100]}...' - {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ù–¢–î
# ============================================================================

@app.post("/ntd-consultation/chat")
async def ntd_consultation_chat_endpoint(request: NTDConsultationRequest):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ù–¢–î"""
    return ntd_consultation_chat(request.message, request.user_id)

@app.get("/ntd-consultation/stats")
async def ntd_consultation_stats_endpoint():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –ù–¢–î"""
    return ntd_consultation_stats()

@app.delete("/ntd-consultation/cache")
async def clear_consultation_cache_endpoint():
    """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –ù–¢–î"""
    return clear_consultation_cache()

@app.get("/ntd-consultation/cache/stats")
async def get_consultation_cache_stats_endpoint():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –ù–¢–î"""
    try:
        result = await get_consultation_cache_stats()
        return {
            "status": "success",
            "cache_stats": result,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# –°–∏—Å—Ç–µ–º–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
# ============================================================================

@app.get("/health")
async def health_endpoint():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return health_check()

@app.get("/metrics")
async def metrics_endpoint():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ Prometheus"""
    return get_metrics()

# ============================================================================
# –ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç
# ============================================================================

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    return {
        "service": "RAG Service",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "documents": "/documents",
            "search": "/search",
            "stats": "/stats",
            "health": "/health",
            "metrics": "/metrics",
            "ntd_consultation": "/ntd-consultation/chat"
        }
    }

# ============================================================================
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
# ============================================================================

@app.exception_handler(404)
async def not_found_handler(request: Request, exc: HTTPException):
    return {"error": "Endpoint not found", "path": request.url.path}

@app.exception_handler(500)
async def internal_error_handler(request: Request, exc: Exception):
    return {"error": "Internal server error", "detail": str(exc)}

# ============================================================================
# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# ============================================================================

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8003,
        reload=True,
        log_level="info"
    )
