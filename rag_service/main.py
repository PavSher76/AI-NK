#!/usr/bin/env python3
"""
–û—Å–Ω–æ–≤–Ω–æ–π RAG —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import uvicorn
import logging
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ú–æ–¥–µ–ª–∏ Pydantic –¥–ª—è —á–∞—Ç–∞
class ChatRequest(BaseModel):
    message: str
    model: str = "llama3.1:8b"
    history: Optional[List[Dict[str, str]]] = None
    max_tokens: Optional[int] = None
    turbo_mode: bool = False  # –¢—É—Ä–±–æ —Ä–µ–∂–∏–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
    reasoning_depth: str = "balanced"  # –ì–ª—É–±–∏–Ω–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è: "fast", "balanced", "deep"

class ChatResponse(BaseModel):
    status: str
    response: str
    model: str
    timestamp: str
    tokens_used: int
    generation_time_ms: int
    turbo_mode: bool
    reasoning_depth: str
    reasoning_steps: int

# –ò–º–ø–æ—Ä—Ç —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
from api.endpoints import (
    get_documents,
    get_stats,
    get_document_chunks,
    get_documents_stats,
    reindex_documents,
    start_async_reindex,
    get_reindex_status,
    delete_document,
    delete_document_indexes,
    ntd_consultation_chat,
    ntd_consultation_stats,
    clear_consultation_cache,
    get_consultation_cache_stats,
    health_check,
    get_metrics
)

# –°–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(
    title="RAG Service",
    description="–û—Å–Ω–æ–≤–Ω–æ–π RAG —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏",
    version="1.0.0"
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
# ============================================================================

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    return {
        "service": "RAG Service",
        "version": "1.0.0",
        "description": "–û—Å–Ω–æ–≤–Ω–æ–π RAG —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏",
        "endpoints": {
            "documents": "/documents",
            "stats": "/stats",
            "documents_stats": "/documents/stats",
            "document_chunks": "/documents/{document_id}/chunks",
            "reindex": "/reindex",
            "async_reindex": "/reindex/async",
            "reindex_status": "/reindex/status/{task_id}",
            "delete_document": "/documents/{document_id}",
            "delete_indexes": "/documents/{document_id}/indexes",
            "chat": "/chat",
            "models": "/models",
            "ntd_consultation": "/ntd-consultation/chat",
            "ntd_consultation_stats": "/ntd-consultation/stats",
            "clear_cache": "/ntd-consultation/cache/clear",
            "cache_stats": "/ntd-consultation/cache/stats",
            "health": "/health",
            "metrics": "/metrics"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/documents")
async def documents():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    return get_documents()

@app.get("/stats")
async def stats():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ RAG-—Å–∏—Å—Ç–µ–º—ã"""
    return get_stats()

@app.get("/documents/stats")
async def documents_stats():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    return get_documents_stats()

@app.get("/documents/{document_id}/chunks")
async def document_chunks(document_id: int):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    return get_document_chunks(document_id)

@app.post("/reindex")
async def reindex():
    """–†–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    return reindex_documents()

@app.post("/reindex/async")
async def async_reindex():
    """–ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    return start_async_reindex()

@app.get("/reindex/status/{task_id}")
async def reindex_status(task_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    return get_reindex_status(task_id)

@app.delete("/documents/{document_id}")
async def delete_doc(document_id: int):
    """–£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    return delete_document(document_id)

@app.delete("/documents/{document_id}/indexes")
async def delete_indexes(document_id: int):
    """–£–¥–∞–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    return delete_document_indexes(document_id)

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """–ß–∞—Ç —Å –ò–ò —á–µ—Ä–µ–∑ Ollama —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç—É—Ä–±–æ —Ä–µ–∂–∏–º–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è"""
    try:
        logger.info(f"üí¨ [CHAT] Processing chat request with model: {request.model}, turbo_mode: {request.turbo_mode}, reasoning_depth: {request.reasoning_depth}")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å —Ç—É—Ä–±–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
        from services.turbo_reasoning_service import TurboReasoningService
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–≤–∏—Å —Ç—É—Ä–±–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
        turbo_service = TurboReasoningService()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ä–µ–∂–∏–º–æ–º
        result = turbo_service.generate_response(
            message=request.message,
            history=request.history,
            turbo_mode=request.turbo_mode,
            reasoning_depth=request.reasoning_depth,
            max_tokens=request.max_tokens
        )
        
        return ChatResponse(
            status="success",
            response=result["response"],
            model=result["model"],
            timestamp=datetime.now().isoformat(),
            tokens_used=result["tokens_used"],
            generation_time_ms=result["generation_time_ms"],
            turbo_mode=result["turbo_mode"],
            reasoning_depth=result["reasoning_depth"],
            reasoning_steps=result["reasoning_steps"]
        )
            
    except Exception as e:
        logger.error(f"‚ùå [CHAT] Error in chat endpoint: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ntd-consultation/chat")
async def ntd_chat(message: str, user_id: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ù–¢–î"""
    return ntd_consultation_chat(message, user_id)

@app.get("/ntd-consultation/stats")
async def ntd_stats():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –ù–¢–î"""
    return ntd_consultation_stats()

@app.post("/ntd-consultation/cache/clear")
async def clear_cache():
    """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π"""
    return clear_consultation_cache()

@app.get("/ntd-consultation/cache/stats")
async def cache_stats():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞"""
    return get_consultation_cache_stats()

@app.get("/health")
async def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return health_check()

@app.get("/models")
async def models_endpoint():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama"""
    try:
        logger.info("üîç [MODELS] Getting available Ollama models")
        
        import requests
        
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –æ—Ç Ollama
        ollama_url = "http://ollama:11434"
        response = requests.get(f"{ollama_url}/api/tags", timeout=10)
        
        if response.status_code == 200:
            models_data = response.json()
            models = models_data.get("models", [])
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ –¥–ª—è —á–∞—Ç–∞ (–∏—Å–∫–ª—é—á–∞–µ–º bge-m3)
            chat_models = [
                {
                    "name": model.get("name", ""),
                    "model": model.get("model", ""),
                    "size": model.get("size", 0),
                    "details": {
                        "family": model.get("details", {}).get("family", "unknown"),
                        "parameter_size": model.get("details", {}).get("parameter_size", "unknown")
                    }
                }
                for model in models
                if not model.get("name", "").startswith("bge-m3")
            ]
            
            return {
                "status": "success",
                "models": chat_models,
                "total_count": len(chat_models),
                "ollama_status": "healthy",
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"‚ùå [MODELS] Ollama API error: {response.status_code}")
            return {
                "status": "error",
                "models": [],
                "total_count": 0,
                "ollama_status": "unhealthy",
                "error": f"Ollama API error: {response.status_code}",
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"‚ùå [MODELS] Error getting models: {e}")
        return {
            "status": "error",
            "models": [],
            "total_count": 0,
            "ollama_status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/metrics")
async def metrics():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ Prometheus"""
    return get_metrics()

# ============================================================================
# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞
# ============================================================================

if __name__ == "__main__":
    logger.info("üöÄ [RAG_SERVICE] Starting RAG Service...")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–∏—Å
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8003,
        reload=True,
        log_level="info"
    )
