"""
–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å —Å–µ—Ä–≤–∏—Å–∞ –∞—Ä—Ö–∏–≤–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
"""

import logging
import os
import sys
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Depends
from fastapi.responses import JSONResponse
from typing import List, Optional, Dict, Any
from datetime import datetime
import asyncio
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from .models import (
    BatchUploadRequest, BatchUploadResponse, DocumentSearchRequest, 
    DocumentSearchResponse, ProjectStats, ArchiveDocument, DocumentType
)
from .database_manager import ArchiveDatabaseManager
from .batch_upload_service import BatchUploadService
from .vector_indexer import ArchiveVectorIndexer
from .config import get_config

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–µ–º FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="Archive Service - –ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏",
    description="–°–µ—Ä–≤–∏—Å –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–ü–î, –†–î, –¢–≠–û) —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ –®–ò–§–† –ø—Ä–æ–µ–∫—Ç–∞",
    version="1.0.0"
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã —Å–µ—Ä–≤–∏—Å–æ–≤
db_manager = None
batch_upload_service = None
vector_indexer = None

def get_db_manager() -> ArchiveDatabaseManager:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    global db_manager
    if db_manager is None:
        config = get_config()
        db_manager = ArchiveDatabaseManager(connection_string=config['database_url'])
    return db_manager

def get_batch_upload_service() -> BatchUploadService:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏"""
    global batch_upload_service
    if batch_upload_service is None:
        batch_upload_service = BatchUploadService(get_db_manager())
    return batch_upload_service

def get_vector_indexer() -> ArchiveVectorIndexer:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞"""
    global vector_indexer
    if vector_indexer is None:
        vector_indexer = ArchiveVectorIndexer()
    return vector_indexer

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    try:
        logger.info("üöÄ [STARTUP] Starting Archive Service...")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã
        db_manager = get_db_manager()
        batch_upload_service = get_batch_upload_service()
        vector_indexer = get_vector_indexer()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ —Å–µ—Ä–≤–∏—Å–æ–≤
        db_health = db_manager.health_check()
        vector_health = await vector_indexer.health_check()
        
        logger.info(f"‚úÖ [STARTUP] Database health: {db_health['status']}")
        logger.info(f"‚úÖ [STARTUP] Vector indexer health: {vector_health['status']}")
        
        logger.info("‚úÖ [STARTUP] Archive Service started successfully")
        
    except Exception as e:
        logger.error(f"‚ùå [STARTUP] Error during startup: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    try:
        logger.info("üõë [SHUTDOWN] Shutting down Archive Service...")
        
        if db_manager:
            db_manager.close_all_connections()
        
        logger.info("‚úÖ [SHUTDOWN] Archive Service shut down successfully")
        
    except Exception as e:
        logger.error(f"‚ùå [SHUTDOWN] Error during shutdown: {e}")

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    return {
        "service": "Archive Service",
        "description": "–ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        db_manager = get_db_manager()
        vector_indexer = get_vector_indexer()
        
        db_health = db_manager.health_check()
        vector_health = await vector_indexer.health_check()
        
        overall_status = "healthy" if (
            db_health['status'] == 'healthy' and 
            vector_health['status'] == 'healthy'
        ) else "unhealthy"
        
        return {
            "status": overall_status,
            "timestamp": datetime.now().isoformat(),
            "services": {
                "database": db_health,
                "vector_indexer": vector_health
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå [HEALTH] Health check error: {e}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.post("/upload/batch", response_model=BatchUploadResponse)
async def upload_documents_batch(request: BatchUploadRequest):
    """–ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        logger.info(f"üì§ [BATCH_UPLOAD] Starting batch upload for project {request.project_code}")
        
        batch_service = get_batch_upload_service()
        response = await batch_service.upload_documents_batch(request)
        
        logger.info(f"‚úÖ [BATCH_UPLOAD] Batch upload completed: {response.status}")
        return response
        
    except Exception as e:
        logger.error(f"‚ùå [BATCH_UPLOAD] Error in batch upload: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload/single")
async def upload_single_document(
    file: UploadFile = File(...),
    project_code: str = Form(...),
    document_type: str = Form("OTHER"),
    document_name: Optional[str] = Form(None),
    document_number: Optional[str] = Form(None),
    author: Optional[str] = Form(None),
    department: Optional[str] = Form(None)
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        logger.info(f"üì§ [SINGLE_UPLOAD] Uploading single document: {file.filename}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        temp_dir = "/tmp/archive_uploads"
        os.makedirs(temp_dir, exist_ok=True)
        
        temp_file_path = os.path.join(temp_dir, file.filename)
        with open(temp_file_path, "wb") as temp_file:
            content = await file.read()
            temp_file.write(content)
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –ø–∞–∫–µ—Ç–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        request = BatchUploadRequest(
            project_code=project_code,
            documents=[{
                'file_path': temp_file_path,
                'document_type': document_type,
                'document_name': document_name or file.filename,
                'document_number': document_number,
                'author': author,
                'department': department
            }],
            auto_extract_sections=True,
            create_relations=False
        )
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–≥—Ä—É–∑–∫—É
        batch_service = get_batch_upload_service()
        response = await batch_service.upload_documents_batch(request)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.remove(temp_file_path)
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå [SINGLE_UPLOAD] Error uploading single document: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/projects/{project_code}/documents")
async def get_project_documents(project_code: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        logger.info(f"üìã [GET_PROJECT_DOCUMENTS] Getting documents for project {project_code}")
        
        db_manager = get_db_manager()
        documents = db_manager.get_documents_by_project(project_code)
        
        return {
            "project_code": project_code,
            "documents": [
                {
                    "id": doc.id,
                    "document_type": doc.document_type.value,
                    "document_name": doc.document_name,
                    "document_number": doc.document_number,
                    "original_filename": doc.original_filename,
                    "file_type": doc.file_type,
                    "file_size": doc.file_size,
                    "upload_date": doc.upload_date.isoformat() if doc.upload_date else None,
                    "processing_status": doc.processing_status.value,
                    "author": doc.author,
                    "department": doc.department,
                    "version": doc.version
                }
                for doc in documents
            ],
            "total_count": len(documents)
        }
        
    except Exception as e:
        logger.error(f"‚ùå [GET_PROJECT_DOCUMENTS] Error getting project documents: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/projects/{project_code}/stats")
async def get_project_stats(project_code: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        logger.info(f"üìä [GET_PROJECT_STATS] Getting stats for project {project_code}")
        
        db_manager = get_db_manager()
        stats = db_manager.get_project_stats(project_code)
        
        if not stats:
            raise HTTPException(status_code=404, detail="Project not found")
        
        return {
            "project_code": stats.project_code,
            "project_name": stats.project_name,
            "total_documents": stats.total_documents,
            "documents_by_type": stats.documents_by_type,
            "total_sections": stats.total_sections,
            "total_size": stats.total_size,
            "last_upload": stats.last_upload.isoformat() if stats.last_upload else None,
            "processing_status": stats.processing_status
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå [GET_PROJECT_STATS] Error getting project stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/search", response_model=DocumentSearchResponse)
async def search_documents(request: DocumentSearchRequest):
    """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        logger.info(f"üîç [SEARCH] Searching documents with query: {request.search_query}")
        
        db_manager = get_db_manager()
        response = db_manager.search_documents(request)
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå [SEARCH] Error searching documents: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/search/similar")
async def search_similar_sections(
    query: str,
    project_code: Optional[str] = None,
    limit: int = 10,
    score_threshold: float = 0.7
):
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤"""
    try:
        logger.info(f"üîç [SEARCH_SIMILAR] Searching similar sections for query: {query}")
        
        vector_indexer = get_vector_indexer()
        results = await vector_indexer.search_similar_sections(
            query=query,
            project_code=project_code,
            limit=limit,
            score_threshold=score_threshold
        )
        
        return {
            "query": query,
            "project_code": project_code,
            "results": results,
            "total_found": len(results)
        }
        
    except Exception as e:
        logger.error(f"‚ùå [SEARCH_SIMILAR] Error searching similar sections: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/projects/{project_code}/progress")
async def get_upload_progress(project_code: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        logger.info(f"üìà [GET_PROGRESS] Getting upload progress for project {project_code}")
        
        batch_service = get_batch_upload_service()
        progress = await batch_service.get_upload_progress(project_code)
        
        return progress
        
    except Exception as e:
        logger.error(f"‚ùå [GET_PROGRESS] Error getting upload progress: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/projects/{project_code}/cancel")
async def cancel_upload(project_code: str):
    """–û—Ç–º–µ–Ω–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        logger.info(f"üõë [CANCEL_UPLOAD] Cancelling upload for project {project_code}")
        
        batch_service = get_batch_upload_service()
        success = await batch_service.cancel_upload(project_code)
        
        if success:
            return {"status": "success", "message": f"Upload cancelled for project {project_code}"}
        else:
            raise HTTPException(status_code=500, detail="Failed to cancel upload")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå [CANCEL_UPLOAD] Error cancelling upload: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/config")
async def get_service_config():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        config = get_config()
        return {
            "status": "success",
            "config": config
        }
    except Exception as e:
        logger.error(f"‚ùå [GET_CONFIG] Error getting config: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/vector/stats")
async def get_vector_stats():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã"""
    try:
        vector_indexer = get_vector_indexer()
        stats = await vector_indexer.get_collection_stats()
        
        return {
            "status": "success",
            "vector_stats": stats
        }
        
    except Exception as e:
        logger.error(f"‚ùå [GET_VECTOR_STATS] Error getting vector stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
