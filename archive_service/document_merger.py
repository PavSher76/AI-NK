"""
–ú–æ–¥—É–ª—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –æ–±—â–µ–º—É –®–ò–§–† –ø—Ä–æ–µ–∫—Ç–∞
"""

import logging
import os
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
import fitz  # PyMuPDF
import docx
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
from reportlab.lib.units import inch

from .models import ArchiveDocument, DocumentSection, DocumentType
from .database_manager import ArchiveDatabaseManager

logger = logging.getLogger(__name__)

class DocumentMerger:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –®–ò–§–† –ø—Ä–æ–µ–∫—Ç–∞"""
    
    def __init__(self, db_manager: ArchiveDatabaseManager):
        self.db_manager = db_manager
    
    async def merge_project_documents(self, project_code: str, output_format: str = "pdf") -> Dict[str, Any]:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª"""
        try:
            logger.info(f"üîÑ [MERGE_DOCUMENTS] Starting merge for project {project_code}")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
            documents = self.db_manager.get_documents_by_project(project_code)
            if not documents:
                raise Exception(f"No documents found for project {project_code}")
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —Ç–∏–ø—É –∏ –¥–∞—Ç–µ –∑–∞–≥—Ä—É–∑–∫–∏
            sorted_documents = self._sort_documents_for_merge(documents)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            if output_format.lower() == "pdf":
                output_path = await self._merge_to_pdf(project_code, sorted_documents)
            elif output_format.lower() == "docx":
                output_path = await self._merge_to_docx(project_code, sorted_documents)
            else:
                raise Exception(f"Unsupported output format: {output_format}")
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ–± –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ
            merged_document = await self._create_merged_document_record(
                project_code, output_path, sorted_documents
            )
            
            logger.info(f"‚úÖ [MERGE_DOCUMENTS] Merge completed for project {project_code}")
            
            return {
                "status": "success",
                "project_code": project_code,
                "merged_document_id": merged_document.id,
                "output_path": output_path,
                "total_documents": len(sorted_documents),
                "output_format": output_format
            }
            
        except Exception as e:
            logger.error(f"‚ùå [MERGE_DOCUMENTS] Error merging documents: {e}")
            raise
    
    def _sort_documents_for_merge(self, documents: List[ArchiveDocument]) -> List[ArchiveDocument]:
        """–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è"""
        # –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        type_priority = {
            DocumentType.TEO: 1,
            DocumentType.PD: 2,
            DocumentType.RD: 3,
            DocumentType.SPECIFICATION: 4,
            DocumentType.CALCULATION: 5,
            DocumentType.REPORT: 6,
            DocumentType.DRAWING: 7,
            DocumentType.OTHER: 8
        }
        
        def sort_key(doc):
            priority = type_priority.get(doc.document_type, 9)
            return (priority, doc.upload_date or datetime.min)
        
        return sorted(documents, key=sort_key)
    
    async def _merge_to_pdf(self, project_code: str, documents: List[ArchiveDocument]) -> str:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ PDF"""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            merge_dir = f"/app/uploads/merged/{project_code}"
            os.makedirs(merge_dir, exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"{project_code}_merged_{timestamp}.pdf"
            output_path = os.path.join(merge_dir, output_filename)
            
            # –°–æ–∑–¥–∞–µ–º PDF –¥–æ–∫—É–º–µ–Ω—Ç
            doc = SimpleDocTemplate(output_path, pagesize=A4)
            story = []
            
            # –°—Ç–∏–ª–∏ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            styles = getSampleStyleSheet()
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontSize=16,
                spaceAfter=30,
                alignment=1  # –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
            )
            
            heading_style = ParagraphStyle(
                'CustomHeading',
                parent=styles['Heading2'],
                fontSize=14,
                spaceAfter=12,
                spaceBefore=20
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏—Ç—É–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            story.append(Paragraph(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞", title_style))
            story.append(Paragraph(f"–®–ò–§–† –ø—Ä–æ–µ–∫—Ç–∞: {project_code}", styles['Heading2']))
            story.append(Paragraph(f"–î–∞—Ç–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {datetime.now().strftime('%d.%m.%Y %H:%M')}", styles['Normal']))
            story.append(Spacer(1, 20))
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ
            story.append(Paragraph("–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", heading_style))
            story.append(Spacer(1, 10))
            
            for i, doc in enumerate(documents, 1):
                doc_title = f"{i}. {doc.document_name} ({doc.document_type.value})"
                story.append(Paragraph(doc_title, styles['Normal']))
            
            story.append(PageBreak())
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            for i, doc in enumerate(documents, 1):
                logger.info(f"üìÑ [MERGE_PDF] Processing document {i}/{len(documents)}: {doc.document_name}")
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                story.append(Paragraph(f"{i}. {doc.document_name}", heading_style))
                story.append(Paragraph(f"–¢–∏–ø: {doc.document_type.value}", styles['Normal']))
                if doc.document_number:
                    story.append(Paragraph(f"–ù–æ–º–µ—Ä: {doc.document_number}", styles['Normal']))
                if doc.author:
                    story.append(Paragraph(f"–ê–≤—Ç–æ—Ä: {doc.author}", styles['Normal']))
                if doc.version:
                    story.append(Paragraph(f"–í–µ—Ä—Å–∏—è: {doc.version}", styles['Normal']))
                story.append(Spacer(1, 20))
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                if doc.file_path and os.path.exists(doc.file_path):
                    content = await self._extract_document_content(doc)
                    if content:
                        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã
                        paragraphs = content.split('\n\n')
                        for para in paragraphs:
                            if para.strip():
                                story.append(Paragraph(para.strip(), styles['Normal']))
                                story.append(Spacer(1, 6))
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
                sections = self.db_manager.get_document_sections(doc.id)
                if sections:
                    story.append(Paragraph("–†–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞:", styles['Heading3']))
                    for section in sections:
                        if section.section_title:
                            story.append(Paragraph(f"‚Ä¢ {section.section_title}", styles['Normal']))
                        if section.section_content:
                            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
                            content = section.section_content[:500] + "..." if len(section.section_content) > 500 else section.section_content
                            story.append(Paragraph(content, styles['Normal']))
                            story.append(Spacer(1, 6))
                
                story.append(PageBreak())
            
            # –°–æ–∑–¥–∞–µ–º PDF
            doc.build(story)
            
            logger.info(f"‚úÖ [MERGE_PDF] PDF created: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå [MERGE_PDF] Error creating PDF: {e}")
            raise
    
    async def _merge_to_docx(self, project_code: str, documents: List[ArchiveDocument]) -> str:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ DOCX"""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            merge_dir = f"/app/uploads/merged/{project_code}"
            os.makedirs(merge_dir, exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"{project_code}_merged_{timestamp}.docx"
            output_path = os.path.join(merge_dir, output_filename)
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DOCX –¥–æ–∫—É–º–µ–Ω—Ç
            doc = docx.Document()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏—Ç—É–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            title = doc.add_heading('–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞', 0)
            doc.add_heading(f'–®–ò–§–† –ø—Ä–æ–µ–∫—Ç–∞: {project_code}', level=1)
            doc.add_paragraph(f'–î–∞—Ç–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {datetime.now().strftime("%d.%m.%Y %H:%M")}')
            doc.add_page_break()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ
            doc.add_heading('–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', level=1)
            
            for i, document in enumerate(documents, 1):
                doc.add_paragraph(f'{i}. {document.document_name} ({document.document_type.value})')
            
            doc.add_page_break()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            for i, document in enumerate(documents, 1):
                logger.info(f"üìÑ [MERGE_DOCX] Processing document {i}/{len(documents)}: {document.document_name}")
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                doc.add_heading(f'{i}. {document.document_name}', level=1)
                doc.add_paragraph(f'–¢–∏–ø: {document.document_type.value}')
                if document.document_number:
                    doc.add_paragraph(f'–ù–æ–º–µ—Ä: {document.document_number}')
                if document.author:
                    doc.add_paragraph(f'–ê–≤—Ç–æ—Ä: {document.author}')
                if document.version:
                    doc.add_paragraph(f'–í–µ—Ä—Å–∏—è: {document.version}')
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                if document.file_path and os.path.exists(document.file_path):
                    content = await self._extract_document_content(document)
                    if content:
                        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã
                        paragraphs = content.split('\n\n')
                        for para in paragraphs:
                            if para.strip():
                                doc.add_paragraph(para.strip())
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
                sections = self.db_manager.get_document_sections(document.id)
                if sections:
                    doc.add_heading('–†–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞:', level=2)
                    for section in sections:
                        if section.section_title:
                            doc.add_paragraph(f'‚Ä¢ {section.section_title}')
                        if section.section_content:
                            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
                            content = section.section_content[:500] + "..." if len(section.section_content) > 500 else section.section_content
                            doc.add_paragraph(content)
                
                doc.add_page_break()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            doc.save(output_path)
            
            logger.info(f"‚úÖ [MERGE_DOCX] DOCX created: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå [MERGE_DOCX] Error creating DOCX: {e}")
            raise
    
    async def _extract_document_content(self, document: ArchiveDocument) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            if not document.file_path or not os.path.exists(document.file_path):
                return ""
            
            file_ext = Path(document.file_path).suffix.lower()
            
            if file_ext == '.pdf':
                return await self._extract_pdf_content(document.file_path)
            elif file_ext == '.docx':
                return await self._extract_docx_content(document.file_path)
            elif file_ext == '.txt':
                with open(document.file_path, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                logger.warning(f"‚ö†Ô∏è [EXTRACT_CONTENT] Unsupported file type: {file_ext}")
                return ""
                
        except Exception as e:
            logger.error(f"‚ùå [EXTRACT_CONTENT] Error extracting content: {e}")
            return ""
    
    async def _extract_pdf_content(self, file_path: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑ PDF"""
        try:
            doc = fitz.open(file_path)
            text_content = ""
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text_content += page.get_text()
            
            doc.close()
            return text_content
            
        except Exception as e:
            logger.error(f"‚ùå [EXTRACT_PDF] Error extracting PDF content: {e}")
            return ""
    
    async def _extract_docx_content(self, file_path: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑ DOCX"""
        try:
            doc = docx.Document(file_path)
            text_content = ""
            
            for paragraph in doc.paragraphs:
                text_content += paragraph.text + "\n"
            
            return text_content
            
        except Exception as e:
            logger.error(f"‚ùå [EXTRACT_DOCX] Error extracting DOCX content: {e}")
            return ""
    
    async def _create_merged_document_record(self, project_code: str, output_path: str, 
                                           source_documents: List[ArchiveDocument]) -> ArchiveDocument:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –æ–± –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ"""
        try:
            # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            metadata = {
                "merged_document": True,
                "source_documents": [doc.id for doc in source_documents],
                "merge_date": datetime.now().isoformat(),
                "total_source_documents": len(source_documents)
            }
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            merged_document = ArchiveDocument(
                project_code=project_code,
                document_type=DocumentType.REPORT,
                document_name=f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ {project_code}",
                document_number=f"MERGED-{project_code}-{datetime.now().strftime('%Y%m%d')}",
                original_filename=os.path.basename(output_path),
                file_type=Path(output_path).suffix.lower(),
                file_size=os.path.getsize(output_path),
                file_path=output_path,
                document_hash=self._calculate_file_hash(output_path),
                token_count=0,  # –ë—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ
                upload_date=datetime.now(),
                processing_status=ProcessingStatus.PENDING,
                author="System",
                department="Archive Service",
                version="1.0",
                status="active",
                metadata=metadata
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            document_id = self.db_manager.save_document(merged_document)
            merged_document.id = document_id
            
            logger.info(f"‚úÖ [CREATE_MERGED_RECORD] Merged document record created: {document_id}")
            return merged_document
            
        except Exception as e:
            logger.error(f"‚ùå [CREATE_MERGED_RECORD] Error creating merged document record: {e}")
            raise
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö–µ—à–∞ —Ñ–∞–π–ª–∞"""
        import hashlib
        try:
            hash_sha256 = hashlib.sha256()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except Exception as e:
            logger.error(f"‚ùå [CALCULATE_HASH] Error calculating file hash: {e}")
            return ""
    
    async def get_merge_options(self, project_code: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ü–∏–π –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
            documents = self.db_manager.get_documents_by_project(project_code)
            
            if not documents:
                return {
                    "can_merge": False,
                    "reason": "No documents found for project"
                }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            document_types = {}
            total_size = 0
            
            for doc in documents:
                doc_type = doc.document_type.value
                if doc_type not in document_types:
                    document_types[doc_type] = 0
                document_types[doc_type] += 1
                total_size += doc.file_size or 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å
            can_merge = len(documents) > 1
            
            return {
                "can_merge": can_merge,
                "project_code": project_code,
                "total_documents": len(documents),
                "document_types": document_types,
                "total_size": total_size,
                "supported_formats": ["pdf", "docx"],
                "estimated_merge_time": len(documents) * 2  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            }
            
        except Exception as e:
            logger.error(f"‚ùå [GET_MERGE_OPTIONS] Error getting merge options: {e}")
            return {
                "can_merge": False,
                "reason": f"Error: {str(e)}"
            }
