"""
–í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –¥–ª—è –∞—Ä—Ö–∏–≤–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
"""

import logging
import asyncio
from typing import List, Dict, Any, Optional
import numpy as np
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from qdrant_client.http.exceptions import UnexpectedResponse

from .models import DocumentSection
from .config import QDRANT_URL, QDRANT_COLLECTION_NAME, EMBEDDING_DIMENSION

logger = logging.getLogger(__name__)

class ArchiveVectorIndexer:
    """–í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –¥–ª—è –∞—Ä—Ö–∏–≤–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    
    def __init__(self, qdrant_url: str = QDRANT_URL):
        self.qdrant_url = qdrant_url
        self.collection_name = QDRANT_COLLECTION_NAME
        self.client = None
        self._init_client()
    
    def _init_client(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Qdrant"""
        try:
            self.client = QdrantClient(url=self.qdrant_url)
            logger.info(f"‚úÖ [VECTOR_INDEXER] Qdrant client initialized: {self.qdrant_url}")
        except Exception as e:
            logger.error(f"‚ùå [VECTOR_INDEXER] Error initializing Qdrant client: {e}")
            raise
    
    async def ensure_collection_exists(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è
            collections = self.client.get_collections()
            collection_names = [col.name for col in collections.collections]
            
            if self.collection_name not in collection_names:
                # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
                self.client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(
                        size=EMBEDDING_DIMENSION,
                        distance=Distance.COSINE
                    )
                )
                logger.info(f"‚úÖ [VECTOR_INDEXER] Collection created: {self.collection_name}")
            else:
                logger.info(f"‚ÑπÔ∏è [VECTOR_INDEXER] Collection already exists: {self.collection_name}")
                
        except Exception as e:
            logger.error(f"‚ùå [VECTOR_INDEXER] Error ensuring collection exists: {e}")
            raise
    
    async def generate_embedding(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –º–æ–¥–µ–ª—å—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é —Ö–µ—à-—Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            import hashlib
            
            # –°–æ–∑–¥–∞–µ–º —Ö–µ—à –æ—Ç —Ç–µ–∫—Å—Ç–∞
            text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ö–µ—à –≤ –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            # –≠—Ç–æ –Ω–µ –Ω–∞—Å—Ç–æ—è—â–∏–π —ç–º–±–µ–¥–¥–∏–Ω–≥, –Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            vector = []
            for i in range(0, len(text_hash), 2):
                hex_pair = text_hash[i:i+2]
                value = int(hex_pair, 16) / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ [0, 1]
                vector.append(value)
            
            # –î–æ–ø–æ–ª–Ω—è–µ–º –¥–æ –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            while len(vector) < EMBEDDING_DIMENSION:
                vector.append(0.0)
            
            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            vector = vector[:EMBEDDING_DIMENSION]
            
            logger.debug(f"üîç [GENERATE_EMBEDDING] Generated embedding for text: {len(text)} chars")
            return vector
            
        except Exception as e:
            logger.error(f"‚ùå [GENERATE_EMBEDDING] Error generating embedding: {e}")
            return [0.0] * EMBEDDING_DIMENSION
    
    async def index_document_sections(self, document_id: int, sections: List[DocumentSection]) -> bool:
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É"""
        try:
            await self.ensure_collection_exists()
            
            points = []
            
            for section in sections:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
                embedding = await self.generate_embedding(section.section_content)
                
                # –°–æ–∑–¥–∞–µ–º —Ç–æ—á–∫—É –¥–ª—è Qdrant
                point_id = f"{document_id}_{section.id}" if section.id else f"{document_id}_{hash(section.section_content)}"
                
                point = PointStruct(
                    id=point_id,
                    vector=embedding,
                    payload={
                        'document_id': document_id,
                        'section_id': section.id,
                        'section_number': section.section_number,
                        'section_title': section.section_title,
                        'section_content': section.section_content,
                        'page_number': section.page_number,
                        'section_type': section.section_type,
                        'importance_level': section.importance_level,
                        'created_at': section.created_at.isoformat() if section.created_at else None
                    }
                )
                points.append(point)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ—á–∫–∏ –≤ Qdrant
            if points:
                self.client.upsert(
                    collection_name=self.collection_name,
                    points=points
                )
                
                logger.info(f"‚úÖ [INDEX_SECTIONS] Indexed {len(points)} sections for document {document_id}")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è [INDEX_SECTIONS] No sections to index for document {document_id}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå [INDEX_SECTIONS] Error indexing sections: {e}")
            return False
    
    async def search_similar_sections(self, query: str, project_code: str = None, 
                                    limit: int = 10, score_threshold: float = 0.7) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤"""
        try:
            await self.ensure_collection_exists()
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = await self.generate_embedding(query)
            
            # –°—Ç—Ä–æ–∏–º —Ñ–∏–ª—å—Ç—Ä
            filter_conditions = {}
            if project_code:
                # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä –ø–æ project_code
                # –ü–æ–∫–∞ —á—Ç–æ –∏—â–µ–º –ø–æ –≤—Å–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
                pass
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                limit=limit,
                score_threshold=score_threshold,
                with_payload=True
            )
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for result in search_results:
                results.append({
                    'id': result.id,
                    'score': result.score,
                    'document_id': result.payload.get('document_id'),
                    'section_id': result.payload.get('section_id'),
                    'section_number': result.payload.get('section_number'),
                    'section_title': result.payload.get('section_title'),
                    'section_content': result.payload.get('section_content'),
                    'page_number': result.payload.get('page_number'),
                    'section_type': result.payload.get('section_type'),
                    'importance_level': result.payload.get('importance_level')
                })
            
            logger.info(f"üîç [SEARCH_SECTIONS] Found {len(results)} similar sections for query")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå [SEARCH_SECTIONS] Error searching sections: {e}")
            return []
    
    async def delete_document_sections(self, document_id: int) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã"""
        try:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ —Å document_id –≤ payload
            self.client.delete(
                collection_name=self.collection_name,
                points_selector={
                    "filter": {
                        "must": [
                            {
                                "key": "document_id",
                                "match": {"value": document_id}
                            }
                        ]
                    }
                }
            )
            
            logger.info(f"‚úÖ [DELETE_SECTIONS] Deleted sections for document {document_id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå [DELETE_SECTIONS] Error deleting sections: {e}")
            return False
    
    async def get_collection_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            collection_info = self.client.get_collection(self.collection_name)
            
            stats = {
                'collection_name': self.collection_name,
                'vectors_count': collection_info.vectors_count,
                'indexed_vectors_count': collection_info.indexed_vectors_count,
                'points_count': collection_info.points_count,
                'segments_count': collection_info.segments_count,
                'status': collection_info.status,
                'optimizer_status': collection_info.optimizer_status,
                'payload_schema': collection_info.payload_schema
            }
            
            logger.info(f"üìä [COLLECTION_STATS] Retrieved stats for collection {self.collection_name}")
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå [COLLECTION_STATS] Error getting collection stats: {e}")
            return {
                'collection_name': self.collection_name,
                'error': str(e)
            }
    
    async def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant
            collections = self.client.get_collections()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_exists = self.collection_name in [col.name for col in collections.collections]
            
            return {
                'status': 'healthy' if collection_exists else 'unhealthy',
                'qdrant_connected': True,
                'collection_exists': collection_exists,
                'collection_name': self.collection_name,
                'total_collections': len(collections.collections)
            }
            
        except Exception as e:
            logger.error(f"‚ùå [VECTOR_INDEXER] Health check failed: {e}")
            return {
                'status': 'unhealthy',
                'error': str(e),
                'qdrant_connected': False,
                'collection_exists': False
            }
