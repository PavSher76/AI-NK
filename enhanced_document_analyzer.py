"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —á—Ç–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —á–µ—Ä—Ç–µ–∂–µ–π
–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
"""

import logging
import os
import json
import time
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import re

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PDF
try:
    import PyPDF2
    PDF2_AVAILABLE = True
except ImportError:
    PDF2_AVAILABLE = False

try:
    from pdfminer.high_level import extract_text, extract_pages
    from pdfminer.layout import LAParams, LTTextContainer, LTTextBox, LTTextLine
    from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
    from pdfminer.converter import TextConverter
    from pdfminer.pdfpage import PDFPage
    PDFMINER_AVAILABLE = True
except ImportError:
    PDFMINER_AVAILABLE = False

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False

logger = logging.getLogger(__name__)


class DrawingMetadataExtractor:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ —á–µ—Ä—Ç–µ–∂–µ–π –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self):
        self.stamp_patterns = [
            r'–õ–ò–°–¢\s+\d+',
            r'–ò–ó–ú\.\s*\d+',
            r'–ò–ù–í\.\s*‚Ññ\s*\d+',
            r'–ü–û–î–ü\.\s*–ò\s*–î–ê–¢–ê',
            r'–°–¢\.\s*–ò–ù–ñ\.',
            r'–ù\.\s*–ö–û–ù–¢–†\.',
            r'–£–¢–í–ï–†–ñ–î\.'
        ]
        
        self.drawing_elements = [
            '–ª–∏–Ω–∏–∏', '–æ–∫—Ä—É–∂–Ω–æ—Å—Ç–∏', '–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏', '—Ä–∞–∑–º–µ—Ä—ã', '–æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è',
            '—à—Ç—Ä–∏—Ö–æ–≤–∫–∞', '–≤—ã–Ω–æ—Å–∫–∏', '–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã–µ –æ—Å–∏', '–º–∞—Å—à—Ç–∞–±'
        ]
    
    def extract_stamp_info(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —à—Ç–∞–º–ø–∞ —á–µ—Ä—Ç–µ–∂–∞"""
        stamp_info = {
            'sheet_number': None,
            'revision': None,
            'inventory_number': None,
            'scale': None,
            'project_info': {},
            'approval_info': {}
        }
        
        # –ü–æ–∏—Å–∫ –Ω–æ–º–µ—Ä–∞ –ª–∏—Å—Ç–∞
        sheet_match = re.search(r'–õ–ò–°–¢\s+(\d+)', text, re.IGNORECASE)
        if sheet_match:
            stamp_info['sheet_number'] = int(sheet_match.group(1))
        
        # –ü–æ–∏—Å–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        revision_match = re.search(r'–ò–ó–ú\.\s*(\d+)', text, re.IGNORECASE)
        if revision_match:
            stamp_info['revision'] = int(revision_match.group(1))
        
        # –ü–æ–∏—Å–∫ –∏–Ω–≤–µ–Ω—Ç–∞—Ä–Ω–æ–≥–æ –Ω–æ–º–µ—Ä–∞
        inv_match = re.search(r'–ò–ù–í\.\s*‚Ññ\s*(\d+)', text, re.IGNORECASE)
        if inv_match:
            stamp_info['inventory_number'] = inv_match.group(1)
        
        # –ü–æ–∏—Å–∫ –º–∞—Å—à—Ç–∞–±–∞
        scale_match = re.search(r'–ú\s*(\d+:\d+)', text, re.IGNORECASE)
        if scale_match:
            stamp_info['scale'] = scale_match.group(1)
        
        return stamp_info
    
    def extract_drawing_elements(self, text: str) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ—Ä—Ç–µ–∂–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        elements = []
        
        # –ü–æ–∏—Å–∫ —Ä–∞–∑–º–µ—Ä–æ–≤
        dimensions = re.findall(r'(\d+(?:\.\d+)?)\s*–º–º', text)
        for dim in dimensions:
            elements.append({
                'type': 'dimension',
                'value': float(dim),
                'unit': '–º–º',
                'confidence': 0.9
            })
        
        # –ü–æ–∏—Å–∫ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
        materials = re.findall(r'–ú–ê–¢–ï–†–ò–ê–õ[:\s]+([–ê-–Ø–∞-—è\s\d]+)', text, re.IGNORECASE)
        for material in materials:
            elements.append({
                'type': 'material',
                'value': material.strip(),
                'confidence': 0.8
            })
        
        # –ü–æ–∏—Å–∫ –º–∞—Ä–∫–∏—Ä–æ–≤–æ–∫
        markings = re.findall(r'–ú–ê–†–ö–ê[:\s]+([–ê-–Ø–∞-—è\d\-\.]+)', text, re.IGNORECASE)
        for marking in markings:
            elements.append({
                'type': 'marking',
                'value': marking.strip(),
                'confidence': 0.9
            })
        
        return elements


class ProjectDocumentAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–µ–∫—Ç–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    
    def __init__(self):
        self.drawing_extractor = DrawingMetadataExtractor()
        self.supported_formats = ['.pdf', '.docx', '.txt']
    
    def analyze_document(self, file_path: str) -> Dict[str, Any]:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        start_time = time.time()
        
        try:
            file_path = Path(file_path)
            if not file_path.exists():
                raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
            file_extension = file_path.suffix.lower()
            
            if file_extension == '.pdf':
                result = self._analyze_pdf(file_path)
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_extension}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            result.update({
                'file_path': str(file_path),
                'file_name': file_path.name,
                'file_size': file_path.stat().st_size,
                'analysis_time': time.time() - start_time,
                'success': True
            })
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file_path}: {e}")
            return {
                'success': False,
                'error': str(e),
                'file_path': str(file_path),
                'analysis_time': time.time() - start_time
            }
    
    def _analyze_pdf(self, file_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            if PDFPLUMBER_AVAILABLE:
                return self._analyze_with_pdfplumber(file_path)
            elif PDFMINER_AVAILABLE:
                return self._analyze_with_pdfminer(file_path)
            elif PDF2_AVAILABLE:
                return self._analyze_with_pypdf2(file_path)
            else:
                raise Exception("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PDF")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ PDF {file_path}: {e}")
            raise
    
    def _analyze_with_pdfplumber(self, file_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é pdfplumber (–ª—É—á—à–∏–π –¥–ª—è —Ç–∞–±–ª–∏—Ü –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã)"""
        pages_data = []
        full_text = ""
        all_tables = []
        all_images = []
        
        with pdfplumber.open(file_path) as pdf:
            total_pages = len(pdf.pages)
            
            for page_num, page in enumerate(pdf.pages, 1):
                logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}/{total_pages}")
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
                page_text = page.extract_text() or ""
                full_text += page_text + "\n"
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
                page_tables = page.extract_tables()
                for table_num, table in enumerate(page_tables, 1):
                    if table and len(table) > 1:
                        all_tables.append({
                            'page_number': page_num,
                            'table_number': table_num,
                            'data': table,
                            'rows': len(table),
                            'columns': len(table[0]) if table else 0
                        })
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                page_images = page.images
                for img_num, img in enumerate(page_images, 1):
                    all_images.append({
                        'page_number': page_num,
                        'image_number': img_num,
                        'bbox': img['bbox'],
                        'width': img['width'],
                        'height': img['height']
                    })
                
                # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                page_analysis = self._analyze_page_content(page_text, page_num)
                
                pages_data.append({
                    'page_number': page_num,
                    'text': page_text,
                    'char_count': len(page_text),
                    'word_count': len(page_text.split()),
                    'analysis': page_analysis,
                    'tables_count': len(page_tables),
                    'images_count': len(page_images)
                })
        
        # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        document_analysis = self._analyze_document_structure(full_text, pages_data)
        
        return {
            'method': 'pdfplumber',
            'total_pages': total_pages,
            'pages': pages_data,
            'full_text': full_text,
            'tables': all_tables,
            'images': all_images,
            'document_analysis': document_analysis,
            'metadata': {
                'total_chars': len(full_text),
                'total_words': len(full_text.split()),
                'total_tables': len(all_tables),
                'total_images': len(all_images)
            }
        }
    
    def _analyze_with_pdfminer(self, file_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é pdfminer (–ª—É—á—à–∏–π –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞)"""
        pages_data = []
        full_text = ""
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        laparams = LAParams(
            word_margin=0.1,
            char_margin=2.0,
            line_margin=0.5,
            boxes_flow=0.5,
            all_texts=True
        )
        
        for page_num, page_layout in enumerate(extract_pages(str(file_path), laparams=laparams), 1):
            page_text = ""
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            for element in page_layout:
                if isinstance(element, LTTextContainer):
                    page_text += element.get_text()
            
            full_text += page_text + "\n"
            
            # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_analysis = self._analyze_page_content(page_text, page_num)
            
            pages_data.append({
                'page_number': page_num,
                'text': page_text,
                'char_count': len(page_text),
                'word_count': len(page_text.split()),
                'analysis': page_analysis
            })
        
        # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        document_analysis = self._analyze_document_structure(full_text, pages_data)
        
        return {
            'method': 'pdfminer',
            'total_pages': len(pages_data),
            'pages': pages_data,
            'full_text': full_text,
            'document_analysis': document_analysis,
            'metadata': {
                'total_chars': len(full_text),
                'total_words': len(full_text.split())
            }
        }
    
    def _analyze_with_pypdf2(self, file_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é PyPDF2 (–±–∞–∑–æ–≤—ã–π)"""
        pages_data = []
        full_text = ""
        
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_pages = len(pdf_reader.pages)
            
            for page_num in range(total_pages):
                page = pdf_reader.pages[page_num]
                page_text = page.extract_text()
                
                full_text += page_text + "\n"
                
                # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                page_analysis = self._analyze_page_content(page_text, page_num + 1)
                
                pages_data.append({
                    'page_number': page_num + 1,
                    'text': page_text,
                    'char_count': len(page_text),
                    'word_count': len(page_text.split()),
                    'analysis': page_analysis
                })
        
        # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        document_analysis = self._analyze_document_structure(full_text, pages_data)
        
        return {
            'method': 'pypdf2',
            'total_pages': total_pages,
            'pages': pages_data,
            'full_text': full_text,
            'document_analysis': document_analysis,
            'metadata': {
                'total_chars': len(full_text),
                'total_words': len(full_text.split())
            }
        }
    
    def _analyze_page_content(self, text: str, page_num: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        analysis = {
            'page_type': 'unknown',
            'stamp_info': {},
            'drawing_elements': [],
            'technical_info': {},
            'compliance_issues': []
        }
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if self._is_title_page(text):
            analysis['page_type'] = 'title_page'
        elif self._is_drawing_page(text):
            analysis['page_type'] = 'drawing_page'
        elif self._is_specification_page(text):
            analysis['page_type'] = 'specification_page'
        elif self._is_general_data_page(text):
            analysis['page_type'] = 'general_data_page'
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —à—Ç–∞–º–ø–∞
        analysis['stamp_info'] = self.drawing_extractor.extract_stamp_info(text)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ—Ä—Ç–µ–∂–∞
        analysis['drawing_elements'] = self.drawing_extractor.extract_drawing_elements(text)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        analysis['technical_info'] = self._extract_technical_info(text)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º
        analysis['compliance_issues'] = self._check_compliance_issues(text, page_num)
        
        return analysis
    
    def _is_title_page(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç–∏—Ç—É–ª—å–Ω–æ–π"""
        title_indicators = [
            '–¢–ò–¢–£–õ–¨–ù–´–ô –õ–ò–°–¢',
            '–ü–û–Ø–°–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ó–ê–ü–ò–°–ö–ê',
            '–û–ë–©–ò–ï –î–ê–ù–ù–´–ï',
            '–°–û–î–ï–†–ñ–ê–ù–ò–ï'
        ]
        return any(indicator in text.upper() for indicator in title_indicators)
    
    def _is_drawing_page(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —á–µ—Ä—Ç–µ–∂–æ–º"""
        drawing_indicators = [
            '–ú–ê–°–®–¢–ê–ë',
            '–õ–ò–°–¢',
            '–ò–ó–ú.',
            '–ò–ù–í.',
            '–ü–û–î–ü.',
            '–°–¢. –ò–ù–ñ.',
            '–ù. –ö–û–ù–¢–†.',
            '–£–¢–í–ï–†–ñ–î.'
        ]
        return any(indicator in text.upper() for indicator in drawing_indicators)
    
    def _is_specification_page(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–µ–π"""
        spec_indicators = [
            '–°–ü–ï–¶–ò–§–ò–ö–ê–¶–ò–Ø',
            '–í–ï–î–û–ú–û–°–¢–¨',
            '–ü–û–ó–ò–¶–ò–Ø',
            '–û–ë–û–ó–ù–ê–ß–ï–ù–ò–ï',
            '–ù–ê–ò–ú–ï–ù–û–í–ê–ù–ò–ï',
            '–ö–û–õ.',
            '–ú–ê–°–°–ê'
        ]
        return any(indicator in text.upper() for indicator in spec_indicators)
    
    def _is_general_data_page(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –æ–±—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        general_indicators = [
            '–û–ë–©–ò–ï –î–ê–ù–ù–´–ï',
            '–ü–†–û–ï–ö–¢',
            '–û–ë–™–ï–ö–¢',
            '–°–¢–ê–î–ò–Ø',
            '–ö–û–ú–ü–õ–ï–ö–¢'
        ]
        return any(indicator in text.upper() for indicator in general_indicators)
    
    def _extract_technical_info(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        tech_info = {
            'project_number': None,
            'object_name': None,
            'stage': None,
            'document_set': None,
            'materials': [],
            'dimensions': []
        }
        
        # –ü–æ–∏—Å–∫ –Ω–æ–º–µ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
        project_match = re.search(r'–ü–†–û–ï–ö–¢[:\s]+([–ê-–Ø–∞-—è\d\-\.]+)', text, re.IGNORECASE)
        if project_match:
            tech_info['project_number'] = project_match.group(1).strip()
        
        # –ü–æ–∏—Å–∫ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞
        object_match = re.search(r'–û–ë–™–ï–ö–¢[:\s]+([–ê-–Ø–∞-—è\s\d\-\.]+)', text, re.IGNORECASE)
        if object_match:
            tech_info['object_name'] = object_match.group(1).strip()
        
        # –ü–æ–∏—Å–∫ —Å—Ç–∞–¥–∏–∏
        stage_match = re.search(r'–°–¢–ê–î–ò–Ø[:\s]+([–ê-–Ø–∞-—è\s\d\-\.]+)', text, re.IGNORECASE)
        if stage_match:
            tech_info['stage'] = stage_match.group(1).strip()
        
        # –ü–æ–∏—Å–∫ –∫–æ–º–ø–ª–µ–∫—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        set_match = re.search(r'–ö–û–ú–ü–õ–ï–ö–¢[:\s]+([–ê-–Ø–∞-—è\s\d\-\.]+)', text, re.IGNORECASE)
        if set_match:
            tech_info['document_set'] = set_match.group(1).strip()
        
        return tech_info
    
    def _check_compliance_issues(self, text: str, page_num: int) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º"""
        issues = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —à—Ç–∞–º–ø–∞ –Ω–∞ —á–µ—Ä—Ç–µ–∂–µ
        if self._is_drawing_page(text) and not self._has_stamp(text):
            issues.append({
                'type': 'missing_stamp',
                'severity': 'critical',
                'description': '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —à—Ç–∞–º–ø —á–µ—Ä—Ç–µ–∂–∞',
                'page': page_num
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞—Å—à—Ç–∞–±–∞
        if self._is_drawing_page(text) and not re.search(r'–ú\s*\d+:\d+', text, re.IGNORECASE):
            issues.append({
                'type': 'missing_scale',
                'severity': 'warning',
                'description': '–ù–µ —É–∫–∞–∑–∞–Ω –º–∞—Å—à—Ç–∞–± —á–µ—Ä—Ç–µ–∂–∞',
                'page': page_num
            })
        
        return issues
    
    def _has_stamp(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —à—Ç–∞–º–ø–∞"""
        stamp_indicators = ['–õ–ò–°–¢', '–ò–ó–ú.', '–ò–ù–í.', '–ü–û–î–ü.', '–°–¢. –ò–ù–ñ.']
        return any(indicator in text.upper() for indicator in stamp_indicators)
    
    def _analyze_document_structure(self, full_text: str, pages_data: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        structure = {
            'document_type': 'unknown',
            'total_pages': len(pages_data),
            'page_types': {},
            'compliance_score': 0.0,
            'recommendations': []
        }
        
        # –ü–æ–¥—Å—á–µ—Ç —Ç–∏–ø–æ–≤ —Å—Ç—Ä–∞–Ω–∏—Ü
        for page in pages_data:
            page_type = page['analysis']['page_type']
            structure['page_types'][page_type] = structure['page_types'].get(page_type, 0) + 1
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        if structure['page_types'].get('drawing_page', 0) > 0:
            structure['document_type'] = 'drawing_document'
        elif structure['page_types'].get('specification_page', 0) > 0:
            structure['document_type'] = 'specification_document'
        elif structure['page_types'].get('general_data_page', 0) > 0:
            structure['document_type'] = 'general_data_document'
        
        # –†–∞—Å—á–µ—Ç –æ—Ü–µ–Ω–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        total_issues = sum(len(page['analysis']['compliance_issues']) for page in pages_data)
        structure['compliance_score'] = max(0, 100 - total_issues * 10)
        
        return structure


def analyze_project_document(file_path: str) -> Dict[str, Any]:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    analyzer = ProjectDocumentAnalyzer()
    return analyzer.analyze_document(file_path)


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ
    file_path = "tests/TestDocs/for_check/3401-21089-–†–î-01-220-221-–ê–†_4_0_RU_IFC (1).pdf"
    
    print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç: {file_path}")
    print("=" * 80)
    
    result = analyze_project_document(file_path)
    
    if result['success']:
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        print(f"üìÑ –ú–µ—Ç–æ–¥: {result.get('method', 'unknown')}")
        print(f"üìä –°—Ç—Ä–∞–Ω–∏—Ü: {result.get('total_pages', 0)}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {result.get('analysis_time', 0):.2f} —Å–µ–∫")
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        doc_analysis = result.get('document_analysis', {})
        print(f"\nüìã –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞: {doc_analysis.get('document_type', 'unknown')}")
        print(f"üìà –û—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {doc_analysis.get('compliance_score', 0)}%")
        
        # –¢–∏–ø—ã —Å—Ç—Ä–∞–Ω–∏—Ü
        page_types = doc_analysis.get('page_types', {})
        print(f"\nüìÑ –¢–∏–ø—ã —Å—Ç—Ä–∞–Ω–∏—Ü:")
        for page_type, count in page_types.items():
            print(f"  - {page_type}: {count}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        pages = result.get('pages', [])
        print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö 3 —Å—Ç—Ä–∞–Ω–∏—Ü:")
        for i, page in enumerate(pages[:3]):
            print(f"\n–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page['page_number']}:")
            print(f"  –¢–∏–ø: {page['analysis']['page_type']}")
            print(f"  –°–∏–º–≤–æ–ª–æ–≤: {page['char_count']}")
            print(f"  –°–ª–æ–≤: {page['word_count']}")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ —à—Ç–∞–º–ø–∞
            stamp_info = page['analysis']['stamp_info']
            if stamp_info.get('sheet_number'):
                print(f"  –ù–æ–º–µ—Ä –ª–∏—Å—Ç–∞: {stamp_info['sheet_number']}")
            if stamp_info.get('revision'):
                print(f"  –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {stamp_info['revision']}")
            if stamp_info.get('scale'):
                print(f"  –ú–∞—Å—à—Ç–∞–±: {stamp_info['scale']}")
            
            # –ü—Ä–æ–±–ª–µ–º—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
            issues = page['analysis']['compliance_issues']
            if issues:
                print(f"  ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã: {len(issues)}")
                for issue in issues:
                    print(f"    - {issue['description']} ({issue['severity']})")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output_file = f"analysis_result_{int(time.time())}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {result.get('error', 'Unknown error')}")
